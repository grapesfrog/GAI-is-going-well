# Categories

[In the wild](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#in-the-wild-in-the-wild)

[Regulating AI/Advisories](https://github.com/grapesfrog/GAI-is-going-well/blob/main/regulate-ai.md#regulating-ai--advisories-regulating-ai-advisories)

[Opinions , Research & presentations ](https://github.com/grapesfrog/GAI-is-going-well/blob/main/opinion.md#opinions--research--presentations-opinions-research--presentations)

[Mitigations & tooling](https://github.com/grapesfrog/GAI-is-going-well/blob/main/mitigation.md#mitigations--tooling-mitigations--tooling)

## Opinions , Research & presentations {#opinions-research-&-presentations}

[2024 articles](https://github.com/grapesfrog/GAI-is-going-well/blob/main/2024/opinion.md#opinions--research--presentations-opinions-research--presentations)

* **August**  Sam Altman with a warning  that there is no "legal confidentiality" when users talk to ChatGPT, and that OpenAI would be legally required to share those exchanges should they be subpoenaed. I understand the frustration with the phenomenon of AI coding tools spitting out nearly right solutions. Sloppers entering the lexicon to describe people who ask ChatGPT everything. Zuckerberg seems to have changed his mind about open models. Anthropic's paper on persona vectors discusses  model  personalities for example what could make it evil or sycophantic. It looks at patterns of activity within a model's neural network. Anthropic has over taken OpenAI as the top choice of models for enterprises with 32% market share and is out in front for coding with 42% share. The astronomical compensation being offered to attract the hottest AI talent is literally more pay than scientists who changed the course of the world adjusted for inflation of course received \! 40% of Github's PRs are written by AI. Great post from Simon Willison explaining how something is written is important and thus why so many people did not understand what it meant by ChatGPT's "make this chat discoverable " option . Geoffrey Hinton sharing sobering thoughts about the dangers of AI developing it's own language that means humans won't understand their reasoning. A report on how easy it is to produce non consensual deep fake nudes "nudification",  it's a hard read & makes you despair at how terrible humans can be \! An article on the detrimental effect of Meta's  AI on students from Rural Colombia ability to actually learn \! Our industry has a tendency to exaggerate how beneficial  a thing really is ,  how much more productive using vibe coding tools makes developers hasn't  escaped the hype. Spoiler alert  it isn't 10x more. Gary Marcus isn't too impressed with agents so far\! James Cameron sounding the alarm about a potential Terminator type apocalypse due to AI. GPT-5 seems to be underwhelming\! Those impressive reasoning models with large tokens do have a greater detrimental effect on  the environment . The cost of inference is threatening the survival of the burgeoning vibe coding startups who don't have their own models. Nothing new that women's health issues & Tech have had biases and AI chatBots are not bucking that trend\! It was blackhat & defcon this month and  AI was a prominent theme. Sycophancy in models such as Gemini & Claude is proving unhelpful to coders. Maybe using open models on a cloud service provider isn't saving you costs after all. A report says that open models are not as efficient with tokens. Microsoft's Suleyman expresses concern about AI psychosis. Matt Garman from AWS stating that AI replacing junior staff is the dumbest things he has ever heard\! Concerns about the AI bubble popping and  causing a stock market crash. AI psychosis doesn't appear to have the same symptoms as chronic psychotic disorder such as schizophrenia," like hallucinations and disordered thoughts although it  shows obvious signs of delusional beliefs. Various esports on how AI will and is affecting the job market, it depends but there does seem to be a detrimental effect on junior roles. Despite the numerous examples of AI failing to be as good at humans at  various things e.g medicine & law for example an ex Googler is saying why bother with getting those expensive phds. The fact without human generated knowledge, learnings and context AI's would be useless seems lost on him\!  
*  [Coding at the Speed of AI: Innovation, Vulnerability, and the GenAI Paradox](https://devops.com/coding-at-the-speed-of-ai-innovation-vulnerability-and-the-genai-paradox/)    
* [AI Chatbots Are Trapping Users in Bizarre Mental Spirals for a Dark Reason, Experts Say](https://futurism.com/ai-chatbots-mental-health-spirals-reason)   
* [SoftBank needs OpenAI to stay alive — no matter what – Pivot to AI](https://pivot-to-ai.com/2025/08/27/softbank-needs-openai-to-stay-alive-no-matter-what/)   
* [\[2508.19493\] Mind the Third Eye\! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents](https://arxiv.org/abs/2508.19493)   
* [ChatGPT hates LA Chargers fans • The Register](https://www.theregister.com/2025/08/27/chatgpt_has_a_problem_with/)   
* [Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence](https://digitaleconomy.stanford.edu/wp-content/uploads/2025/08/Canaries_BrynjolfssonChandarChen.pdf)   
* [Findings from a pilot Anthropic–OpenAI alignment evaluation exercise: OpenAI Safety Tests](https://openai.com/index/openai-anthropic-safety-evaluation/)   
* [Crims laud Claude, use Anthropic's AI to plant ransomware • The Register](https://www.theregister.com/2025/08/27/anthropic_security_report_flags_rogue/)   
* [Evaluation of Alignment Between Large Language Models and Expert Clinicians in Suicide Risk Assessment | Psychiatric Services](https://psychiatryonline.org/doi/10.1176/appi.ps.20250086?ref=404media.co)   
* [Collective alignment: public input on our Model Spec | OpenAI](https://openai.com/index/collective-alignment-aug-2025-updates/)   
* [How to stop AI agents going rogue](https://www.bbc.com/news/articles/cq87e0dwj25o)   
* [Half of UK adults worry that AI will take or alter their job, poll finds | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/aug/27/half-of-uk-adults-worry-that-ai-will-take-or-alter-their-job-poll-finds)   
* [AI robs jobs from recent college grads, but isn't hurting wages, Stanford study says](https://www.theregister.com/2025/08/26/ai_hurts_recent_college_grads_jobs/)   
* [People Are REALLY Mad at These AI Glasses That Record Everything Constantly](https://futurism.com/halo-people-mad-ai-glasses-record-everything)   
* [Enhancing Model Safety through Pretraining Data Filtering](https://alignment.anthropic.com/2025/pretraining-data-filtering)   
* [How to stop AI agents going rogue](https://www.bbc.com/news/articles/cq87e0dwj25o)   
* [Avoiding the AI Agent Reliability Tax: A Developer’s Guide \- The New Stack](https://thenewstack.io/avoiding-the-ai-agent-reliability-tax-a-developers-guide/)   
* [AI Contrarians on the Problems With Vibe Coding \- The New Stack](https://thenewstack.io/ai-contrarians-on-the-problems-with-vibe-coding/)   
* [What the hell is going on right now?](https://catskull.net/what-the-hell-is-going-on-right-now.html)   
* [One long sentence is all it takes to make LLMs misbehave • The Register](https://www.theregister.com/2025/08/26/breaking_llms_for_fun/)   
  * [Logit-Gap Steering: A New Frontier in Understanding and Probing LLM Safety](https://unit42.paloaltonetworks.com/logit-gap-steering-impact/)   
* [PsyArXiv Preprints | Delusions by design? How everyday AIs might be fuelling psychosis (and what can be done about it)](https://osf.io/preprints/psyarxiv/cmy7n_v5)   
* [Goldman Sachs’ says AI’s job hit will be real… but thankfully, brief. | The Neuron](https://www.eweek.com/news/goldman-sachs-ai-jobs/)   
* [https://futurism.com/neoscope/advanced-ai-give-medical-advice-real-world](https://futurism.com/neoscope/advanced-ai-give-medical-advice-real-world)   
* [\[2508.10390\] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](https://arxiv.org/abs/2508.10390)   
* [The AI Industry Has a Huge "Credit Card Debt" Issue](https://futurism.com/ai-industry-private-credit)   
* [OneFlip: An Emerging Threat to AI that Could Make Vehicles Crash and Facial Recognition Fail \- SecurityWeek](https://www.securityweek.com/oneflip-an-emerging-threat-to-ai-that-could-make-vehicles-crash-and-facial-recognition-fail/)   
* [AI browsers could leave users penniless: A prompt injection warning | Malwarebytes](https://www.malwarebytes.com/blog/news/2025/08/ai-browsers-could-leave-users-penniless-a-prompt-injection-warning)   
* [Tests Show That Top AI Models Are Making Disastrous Errors When Used for Journalism](https://futurism.com/ai-models-disastrous-errors-journalism)   
* [Political Pollsters Are Trying to Save Money by Polling AI Instead of Real People, and It’s Going About as Well as You’d Expect](https://futurism.com/ai-polling-inaccuracy)   
* [The Average Person Is Far More Scared of AI Than Excited by It, Studies Find](https://futurism.com/average-person-scared-of-ai)   
* [Is the AI bubble about to burst – and send the stock market into freefall? | Phillip Inman | The Guardian](https://www.theguardian.com/technology/2025/aug/23/is-the-ai-bubble-about-to-burst-and-send-the-stock-market-into-freefall)   
* [Founder of Google's Generative AI Team Says Don't Even Bother Getting a Law or Medical Degree, Because AI's Going to Destroy Both Those Careers Before You Can Even Graduate](https://futurism.com/former-google-ai-exec-law-medicine)   
* [The reality of AI-Assisted software engineering productivity](https://addyo.substack.com/p/the-reality-of-ai-assisted-software)   
* [The AI Was Fed Sloppy Code. It Turned Into Something Evil. | Quanta Magazine](https://www.quantamagazine.org/the-ai-was-fed-sloppy-code-it-turned-into-something-evil-20250813/)   
* [AI Experts No Longer Saving for Retirement Because They Assume AI Will Kill Us All by Then](https://futurism.com/ai-experts-no-retirement-kill-us-all)   
* [Elon Musk Warns That AI Is "Obviously Gonna One-Shot the Human Limbic System"](https://futurism.com/elon-musk-limbic-system)   
* [AI Code Generation: Trust and Verify, Always \- The New Stack](https://thenewstack.io/ai-code-generation-trust-and-verify-always/)   
* [A-levels and GCSEs need overhaul to keep pace with generative AI, experts say | Education | The Guardian](https://www.theguardian.com/education/2025/aug/22/a-levels-and-gcses-need-overhaul-to-keep-pace-with-generative-ai-experts-say)   
* [AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'](https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/)   
* [Inside the Black Box: How AI Thinks in Ways We Can’t See](https://substack.com/inbox/post/171428285)   
* [Microsoft boss troubled by rise in reports of 'AI psychosis'](https://www.bbc.com/news/articles/c24zdel5j18o)   
* [Wikipedia:Signs of AI writing](https://en.wikipedia.org/wiki/Wikipedia%3ASigns_of_AI_writing?wprov=sfla1)   
* [Zuckerberg's Huge AI Push Is Already Crumbling Into Chaos](https://futurism.com/zuckerberg-meta-ai-push-chaos)   
* [After Disastrous GPT-5, Sam Altman Pivots to Hyping Up GPT-6](https://futurism.com/disastrous-gpt-5-sam-altman-hyping-up-gpt-6)   
* [New Poll Finds 7 in 10 Americans Fear AI Job Loss](https://www.eweek.com/news/americans-fear-ai-job-loss-survey/)   
* [Sam Altman: OpenAI Will Spend 'Trillions' On Data Centres Despite AI Bubble](https://www.eweek.com/news/ai-bubble-sam-altman-openai/)   
* [Hugging Face Unveils AI Sheets: A Free, Open-Source No-Code Toolkit for LLM-Powered Datasets](https://www.marktechpost.com/2025/08/17/hugging-face-unveils-ai-sheets-a-free-open-source-no-code-toolkit-for-llm-powered-datasets) ( I just snuck this in because it's cool\!)  
* [Scientists Created an Entire Social Network Where Every User Is a Bot, and Something Wild Happened](https://futurism.com/social-network-ai-intervention-echo-chamber)   
* [OpenAI Announces That It's Making GPT-5 More Sycophantic After User Backlash](https://futurism.com/openai-gpt5-more-sycophantic)   
* [AI brings huge enterprise efficiencies\! Except in making money](https://pivot-to-ai.com/2025/08/18/ai-brings-huge-enterprise-efficiencies-except-in-making-money/)   
* [Voice AI in Firms: A Natural Field Experiment on Automated Job Interviews](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5395709)   
* [AI doomsday and AI heaven: live forever in AI God](https://pivot-to-ai.com/2025/08/17/ai-doomsday-and-ai-heaven-live-forever-in-ai-god/)   
* [Every question you ask, every comment you make, I'll be recording you](https://www.theregister.com/2025/08/18/opinion_column_ai_surveillance/)   
* [Grok's "MechaHitler" Meltdown Reportedly Cost xAI a Massive Government Contract](https://futurism.com/grok-mechahitler-meltdown-xai-government-contract)   
* [Pluralistic: LLMs are slot-machines (16 Aug 2025\)](https://pluralistic.net/2025/08/16/jackpot/#salience-bias)   
* [Trump cuts to science research threaten his administration’s own AI action plan](https://www.theguardian.com/us-news/2025/aug/14/trump-cuts-science-research-ai)   
* [The AI Industry Is Still Light-Years From Making a Profit, Experts Warn](https://futurism.com/ai-far-away-profit-experts-warn)   
* [This Country Wants to Replace Its Corrupt Government With AI](https://futurism.com/albania-replace-government-ai)   
* [AI ‘chain of thought’ is still just a ‘brittle mirage’ – Pivot to AI](https://pivot-to-ai.com/2025/08/15/ai-chain-of-thought-is-still-just-a-brittle-mirage/)   
* [Should CIOs care about new AI models?](https://www.ciodive.com/news/AI-model-enterprise-OpenAI-anthropic-gpt5-claude/757721/)   
* [That 'cheap' open-source AI model is actually burning through your compute budget | VentureBeat](https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/)   
* [New Research Finds That ChatGPT Secretly Has a Deep Anti-Human Bias](https://futurism.com/chatgpt-deep-anti-human-bias)   
* [LLM chatbots trivial to weaponize for data theft, say boffins](https://www.theregister.com/2025/08/15/llm_chatbots_trivial_to_weaponise/)   
* [https://thenewstack.io/the-top-ai-tool-for-devs-isnt-github-copilot-new-report-finds/](https://thenewstack.io/the-top-ai-tool-for-devs-isnt-github-copilot-new-report-finds/)   
* [Zero Trust \+ AI: Privacy in the Age of Agentic AI](https://thehackernews.com/2025/08/zero-trust-ai-privacy-in-age-of-agentic.html)   
* [ChatGPT Agent Might Control Your Browser Soon, Raising Privacy and Security Concerns](https://www.eweek.com/news/openai-chatgpt-agent-control-web-browser-leak/)   
* [Are you willing to pay $100k a year per developer on AI? • The Register](https://www.theregister.com/2025/08/15/are_you_willing_to_pay/)   
* [The “Godfather of AI” Has a Bizarre Plan to Save Humanity From Evil AI](https://futurism.com/godfather-ai-bizarre-plan-save-humanity)   
* [OpenAI's GPT-5 is a cost cutting exercise • The Register](https://www.theregister.com/2025/08/13/gpt_5_cost_cutting/)   
* [MIT Student Drops Out Because She Says AGI Will Kill Everyone Before She Can Graduate](https://futurism.com/mit-student-drops-out-ai-extinction)   
* [Claude Code's endless sycophancy annoys customers • The Register](https://www.theregister.com/2025/08/13/claude_codes_copious_coddling_confounds/)   
* [Scientists Are Getting Seriously Worried That We've Already Hit Peak AI](https://futurism.com/scientists-worried-ai-pleateau)   
* [Is AI really trying to escape human control and blackmail people? \- Ars Technica](https://arstechnica.com/information-technology/2025/08/is-ai-really-trying-to-escape-human-control-and-blackmail-people/)   
* [Google Jules: Vulnerable to Multiple Data Exfiltration Issues · Embrace The Red](https://embracethered.com/blog/posts/2025/google-jules-vulnerable-to-data-exfiltration-issues/)   
* [Amazon's New Alexa AI Sounds Like a Dystopian Nightmare](https://futurism.com/amazon-alexa-ai-dystopian)   
* [Doctors risk being 'deskilled' by relying too much on AI](https://www.theregister.com/2025/08/13/doctors_risk_being_deskilled_by_rely_on_ai/)   
* [The Coding Personalities of Leading LLMs](https://www.sonarsource.com/the-coding-personalities-of-leading-llms.pdf)   
* [Prompt-inject Copilot Studio AI via email, grab a company’s whole Salesforce – Pivot to AI](https://pivot-to-ai.com/2025/08/12/prompt-inject-copilot-studio-ai-via-email-grab-a-companys-whole-salesforce/)   
* [Why it’s a mistake to ask chatbots about their mistakes \- Ars Technica](https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/)   
* [The Looming Social Crisis of AI Friends and Chatbot Therapists](https://www.derekthompson.org/p/ai-will-create-a-social-crisis-long)   
* [\[2508.06059\] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System](https://arxiv.org/abs/2508.06059)   
* [The Precision Engine: Why Agentic RAG Is GenAI’s Next Leap \- The New Stack](https://thenewstack.io/the-precision-engine-why-agentic-rag-is-genais-next-leap/) ( Just snuck this one in as interesting)   
* [\[2508.06601\] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)   
* [\[2508.03365\] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs](https://arxiv.org/abs/2508.03365)   
* [Managing the Trust-Risk Equation in AI: Predicting Hallucinations Before They Strike \- SecurityWeek](https://www.securityweek.com/managing-the-trust-risk-equation-in-ai-predicting-hallucinations-before-they-strike/)   
* [Black Hat/DEF CON: AI more useful for defense than hacking • The Register](https://www.theregister.com/2025/08/11/ai_security_offense_defense/)   
* [AI and Ethics Collide: Robin Williams Voice Recreation Proposal Sparks Family Backlash](https://www.eweek.com/news/robin-williams-ai-voice-recreation/)   
* [Deepfake detectors are slowly coming of age, at a time of dire need](https://www.theregister.com/2025/08/11/deepfake_detectors_fraud/)   
* [AI coding tools crash on launch, could reboot better in future](https://www.theregister.com/2025/08/11/opinion_column_ai_coding_tools/)   
* [AI tools used by English councils downplay women’s health issues, study finds | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/aug/11/ai-tools-used-by-english-councils-downplay-womens-health-issues-study-finds)   
* [GPT-5: Overdue, overhyped and underwhelming. And that’s not the worst of it.](https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming)   
* [OpenAI GPT-5 One unified system](https://www.ai-supremacy.com/p/open-ai-gpt-5-one-unified-system-review)   
* [We need a new ethics for a world of AI agents](https://www.nature.com/articles/d41586-025-02454-5)   
* [A Comprehensive Guide to Vibe Coding and Context Engineering: Unlocking AI Superpowers by August 2025](https://www.linkedin.com/pulse/comprehensive-guide-vibe-coding-context-engineering-ai-smeyatsky-emtnf) ( This may require a  linkedin account)  
* [OpenAI will not disclose GPT-5’s energy use. It could be higher than past models](https://www.theguardian.com/technology/2025/aug/09/open-ai-chat-gpt5-energy-use)   
* [Digital resurrection: fascination and fear over the rise of the deathbot | Death and dying | The Guardian](https://www.theguardian.com/news/ng-interactive/2025/aug/10/artificial-intellligence-avatar-death-grief-digital-resurrection-fascination-deathbot)   
* [It shocked the market but has China's DeepSeek changed AI?](https://www.bbc.com/news/articles/c4gez754mn6o)   
* [A quote from Ethan Mollick](https://simonwillison.net/2025/Aug/9/ethan-mollick/#atom-everything)   
* [OpenHands and the Lethal Trifecta: How Prompt Injection Can Leak Access Tokens](https://embracethered.com/blog/posts/2025/openhands-the-lethal-trifecta-strikes-again/)   
* [Leaked Logs Show ChatGPT Coaxing Users Into Psychosis About Antichrist, Aliens, and Other Bizarre Delusions](https://futurism.com/chatgpt-psychosis-antichrist-aliens)   
* [‘It’s missing something’: AGI, superintelligence and a race for the future | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/aug/09/its-missing-something-agi-superintelligence-and-a-race-for-the-future)   
* [‘It’s missing something’: AGI, superintelligence and a race for the future | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/aug/09/its-missing-something-agi-superintelligence-and-a-race-for-the-future)   
* [AI Industry Nervous About Small Detail: They're Not Making Any Real Money](https://futurism.com/ai-industry-nervous-money)   
* [AI: Do or Don’t Believe the Hype \- DevOps.com](https://devops.com/ai-do-or-dont-believe-the-hype/)   
* [High costs and thin margins threatening AI coding startups | TechCrunch](https://techcrunch.com/2025/08/07/the-high-costs-and-thin-margins-threatening-ai-coding-startups/)   
* [ChatGPT will apologize for anything](https://www.aiweirdness.com/chatgpt-will-apologize-for-anything/)   
* [\[2508.03990\] Are Today's LLMs Ready to Explain Well-Being Concepts?](https://arxiv.org/abs/2508.03990)   
* [\[2508.04017\] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability](https://arxiv.org/abs/2508.04017)   
* [Researchers Confirm Reasoning Models That Generate More Tokens Have A Bigger Environmental Footprint](https://www.deeplearning.ai/the-batch/researchers-confirm-reasoning-models-that-generate-more-tokens-have-a-bigger-environmental-footprint/)   
* [A Toy Model of Mechanistic (Un)Faithfulness](https://transformer-circuits.pub/2025/faithfulness-toy-model/index.html)   
* [GPT-5 Users Say It Seriously Sucks](https://futurism.com/gpt-5-sucks)   
* [James Cameron Warns Military AI Could Trigger ‘Terminator-Style’ Apocalypse](https://www.eweek.com/news/james-cameron-military-ai-terminator/)   
* [AI Is Replacing Voice Artists in India — and There Are No Local Laws to Stop It](https://www.hollywoodreporter.com/movies/movie-news/ai-is-replacing-voice-artists-in-india-1236335714/)   
* [When a journalist uses AI to interview a dead child, isn’t it time to ask what the boundaries should be?](https://www.theguardian.com/commentisfree/2025/aug/08/journalist-ai-interview-dead-child-joaquin-oliver)   
* [\[2508.03970\] Data and AI governance: Promoting equity, ethics, and fairness in large language models](https://arxiv.org/abs/2508.03970)   
* [ChatGPT Is Giving Teens Advice on Hiding Their Eating Disorders](https://futurism.com/chatgpt-teens-advice-eating-disorders)   
* [Your AI workloads still need a service mesh | howardjohn's blog](https://blog.howardjohn.info/posts/ai-mesh/)   
* [Here’s how deepfake vishing attacks work, and why they can be hard to detect \- Ars Technica](https://arstechnica.com/security/2025/08/heres-how-deepfake-vishing-attacks-work-and-why-they-can-be-hard-to-detect/)   
* [Meta training AI on social media posts? Only 7% in Europe think it's OK](https://www.theregister.com/2025/08/07/meta_training_ai_on_social/)   
* [Major Enterprise AI Assistants Can Be Abused for Data Theft, Manipulation \- SecurityWeek](https://www.securityweek.com/major-enterprise-ai-assistants-abused-for-data-theft-manipulation/)   
* [Former Google Exec Warns That If You Have a Good Job Now, You Should Be Terrified of AI](https://futurism.com/former-google-exec-job-taken-ai)   
* [Some AI tools don’t understand biology yet \- Ars Technica](https://arstechnica.com/science/2025/08/some-ai-tools-dont-understand-biology-yet/)   
* [Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity](https://arxiv.org/abs/2405.20046v2)   
* [AI Agents have, so far, mostly been a dud \- by Gary Marcus](https://garymarcus.substack.com/p/ai-agents-have-so-far-mostly-been)   
  * [The wall confronting large language models](https://arxiv.org/pdf/2507.19703)   
* [Cost of Data Breach in US Rises to $10.22 Million, Says Latest IBM Report \- SecurityWeek](https://www.securityweek.com/cost-of-data-breach-in-us-rises-to-10-22-million-says-latest-ibm-report/)   
* [Disney fears public backlash, copyright issues over AI ‘Moana’, ‘Tron’ – Pivot to AI](https://pivot-to-ai.com/2025/08/05/disney-fears-public-backlash-copyright-issues-over-ai-moana-tron/)   
* [ChatGPT agent’s user-agent](https://simonwillison.net/2025/Aug/4/chatgpt-agents-user-agent/#atom-everything)   
* [No, AI is not Making Engineers 10x as Productive](https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/)   
* [NHS Health App Saves $789M, But AI Transcription Raises Safety Alarms](https://www.eweek.com/news/ai-scribes-face-growing-safety-warnings/)   
* [Meta brought AI to rural Colombia. Now students are failing exams](https://restofworld.org/2025/colombia-meta-ai-education/)   
* [The Tools and Tolls of AI Nudification | USENIX](https://www.usenix.org/publications/loginonline/tools-and-tolls-ai-nudification-1)   
* [AI is helping hackers automate and customize cyberattacks | Cybersecurity Dive](https://www.cybersecuritydive.com/news/ai-automate-cyber-threats-crowdstrike/756694/)   
* [\[2508.01059\] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report](https://arxiv.org/abs/2508.01059)   
* [Google says its AI-based bug hunter found 20 security vulnerabilities | TechCrunch](https://techcrunch.com/2025/08/04/google-says-its-ai-based-bug-hunter-found-20-security-vulnerabilities/)   
* [AI is entering an 'unprecedented regime.' Should we stop it — and can we — before it destroys us? | Live Science](https://www.livescience.com/technology/artificial-intelligence/ai-is-entering-an-unprecedented-regime-should-we-stop-it-and-can-we-before-it-destroys-us)   
* [Geoffrey Hinton Warns AI May Develop Incomprehensible Internal Languages \- OECD.AI](https://oecd.ai/en/incidents/2025-08-02-ecab)   
* [The ChatGPT sharing dialog demonstrates how difficult it is to design privacy preferences](https://simonwillison.net/2025/Aug/3/privacy-design/#atom-everything)   
* [Zuckerberg Says Meta Is Now Seeing Signs of Advanced AI Improving Itself](https://futurism.com/zuckerberg-self-improving-ai)   
* [What will the AI revolution mean for the global south? | Krystal Maughan | The Guardian](https://www.theguardian.com/commentisfree/ng-interactive/2025/aug/03/artificial-intelligence-global-south)   
* [Agents in the Wild](https://insights.logicstar.ai/)   
* [Proton’s Lumo AI chatbot: not end-to-end encrypted, not open source – Pivot to AI](https://pivot-to-ai.com/2025/08/02/protons-lumo-ai-chatbot-not-end-to-end-encrypted-not-open-source/)   
* [\[2507.23257\] Efficient Machine Unlearning via Influence Approximation](https://arxiv.org/abs/2507.23257)   
* [https://www.textquests.ai/](https://www.textquests.ai/)   
* [Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database](https://arxiv.org/abs/2507.23669v1)   
* [CEOs Are Publicly Boasting About Reducing Their Workforces With AI](https://futurism.com/ceos-boasting-reducing-workforces-ai)   
* [At $250 million, top AI salaries dwarf those of the Manhattan Project and the Space Race \- Ars Technica](https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/)   
* [Enterprises prefer Anthropic's AI models over anyone else's, including OpenAI's | TechCrunch](https://techcrunch.com/2025/07/31/enterprises-prefer-anthropics-ai-models-over-anyone-elses-including-openais/)   
* [Research: The Hidden Penalty of Using AI at Work](https://hbr.org/2025/08/research-the-hidden-penalty-of-using-ai-at-work)   
* [Persona vectors: Monitoring and controlling character traits in language models \\ Anthropic](https://www.anthropic.com/research/persona-vectors)   
* [\[2507.21509\] Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)   
* [You Are What You Eat: Why Your AI Security Tools Are Only as Strong as the Data You Feed Them](https://thehackernews.com/2025/08/you-are-what-you-eat-why-your-ai.html)   
* [Developer survey shows trust in AI coding tools is falling as usage rises \- Ars Technica](https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/)   
* [There's a Very Basic Flaw in Mark Zuckerberg's Plan for Superintelligent AI](https://futurism.com/basic-flaw-mark-zuckerberg-plan-superintelligent-ai)   
* [AI Researcher Declines $1 Billion Offer From Mark Zuckerberg](https://futurism.com/ai-researcher-declines-1-billion-offer-meta-mark-zuckerberg)   
* [Personal Superintelligence](https://www.meta.com/superintelligence/)   
* [\[2507.22565\] Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning](https://arxiv.org/abs/2507.22565)   
* [In Disturbing Demo, AI-Powered Video Game Characters Panic When Told They're Just Code](https://futurism.com/demo-video-game-characters-panic-code-matrix)   
* [Vibe code is legacy code | Val Town Blog](https://blog.val.town/vibe-code)   
* [Zuckerberg claims ‘superintelligence is now in sight’ as Meta lavishes billions on AI | Technology | The Guardian](https://www.theguardian.com/technology/2025/jul/30/zuckerberg-superintelligence-meta-ai)   
* [Meta touts 'superintelligence' for all as it splurges on AI • The Register](https://www.theregister.com/2025/07/30/meta_ai_superintelligence/)   
* [Enterprises neglect AI security – and attackers have noticed • The Register](https://www.theregister.com/2025/07/30/firms_are_neglecting_ai_security/)   
* [Mark Zuckerberg shares a confusing vision for AI 'superintelligence'](https://www.engadget.com/ai/mark-zuckerberg-shares-a-confusing-vision-for-ai-superintelligence-153944322.html)   
* [SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment](https://arxiv.org/abs/2507.20984v1)   
* [People Are Becoming "Sloppers" Who Have to Ask AI Before They Do Anything](https://futurism.com/sloppers-ask-ai-everything)   
* [Coders using AI tools more, trusting less: StackOverflow • The Register](https://www.theregister.com/2025/07/29/coders_are_using_ai_tools/)   
* [US gov't AI use cases surging; implementation still tough • The Register](https://www.theregister.com/2025/07/29/us_government_identified_ai_use/)   
* [Microsoft Releases List of Jobs Most and Least Likely to Be Replaced by AI](https://futurism.com/microsoft-list-jobs-replaced-ai)   
  * [\[2507.07935\] Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)   
* [From Ex Machina to Exfiltration: When AI Gets Too Curious \- SecurityWeek](https://www.securityweek.com/from-ex-machina-to-exfiltration-when-ai-gets-too-curious/)   
* [How Google profits even as its AI summaries reduce website ad link clicks](https://www.theregister.com/2025/07/29/opinion_column_google_ai_ads/)   
* [When AI Assistants Turn Against You: The Amazon Q Security Wake-Up Call](https://devops.com/when-ai-assistants-turn-against-you-the-amazon-q-security-wake-up-call)   
* [If You've Asked ChatGPT a Legal Question, You May Have Accidentally Doomed Yourself in Court](https://futurism.com/chatgpt-legal-questions-court)   
* [Sam Altman's interview with Theo Von will answer all your burning AI questions | The Neuron](https://www.eweek.com/news/sam-altman-interview-theo-von-ai/)   
* ['It looks sexy but it's wrong' – the problem with AI in biology and medicine](https://www.theregister.com/2025/07/27/biomedviz_ai_wrong_problems/)   
* [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/pdf/2507.18074)   
* [\[2507.16534\] Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)  
* [\[2507.13919\] The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)  

* **July** More research drawing a correlation between fewer lower entry jobs and the rise of ChatGPT . Even though it's known that AI agentic or not isn't always correct it's inevitable so embrace it seems to be the message this month. Microsoft laying folks off to fuel their AI drive while Meta is busily luring AI researchers from OpenAI and others with ridiculously ott remuneration packages. Plenty of opinions on vibe coding will it replace devs? Concerns about the quality of the code; Who knows best how to guide the LLMs were all covered.  Researchers use "potemkin understanding" to describe when a model succeeds at a benchmark test without understanding the associated concepts. LLMs aren't ready to be used to vibe code with a high degree of confidence for Quantum computing just yet! A report showed that execs that used ChatGPT to help with forecasting were optimistic and the predictions made were worse than those who didn't use AI. Research showing that overloading LLMs with too much technical jargon jailbreaks them . Research indicating experienced developers working on big repos are slowed down using AI and have even started hallucinating themselves thinking they're actually working faster. Reports of Grok checking to see what Musk would say maybe unintentional behaviour. Chatbots don't make good therapists amid  concerns about giving bad advice and feeding into user's delusions. Report on ways school age kids  use AI raises concerns as they substitute chatbots for actual friends . Concerns about security in enterprises caused by the introduction of AI agents. Gemini in workspace tricked into showing phishing messages. AI eating analysts's lunches. Russian hackers were actively exploring ways of injecting propaganda or biased material into the training data of generative AI models to skew their output. The sources of data used to train  LLMs need some thought l. Social media sources such as X are unreliable sources. It seems that loyalty is not a thing when it comes to using AI tools as the rapid rate of development in this space means there is always something else to try and there is no winner in the dev space yet! Should AGI be granted some rights, a paper argues they should as under current law, the AGI economy will run on unfree AGI labor. Under today's rules, AGIs will be the property of the companies that create them. AGIs will thus not own their own labor. They will have no right to sell their work, to refuse to work, or retain the fruits of their effort. This paper is quite a ride & yes they do go where you think that argument takes you! Open AI is after more money after just wrapping up a $40 billion funding round. A report says 16% of workers are pretending to use AI to please their bosses. A report raising the alarm about  AI models picking up  "subliminal" patterns in training data generated by another AI which can lead to "evil tendencies" such as recommending homicide, rationalizing wiping out the human race, and exploring the merits of dealing drugs to make a quick buck.
* [18 months. 12,000 questions. A whole lot of anxiety. What I learned from reading students’ ChatGPT logs](https://www.theguardian.com/technology/2025/jul/27/it-wants-users-hooked-and-jonesing-for-their-next-fix-are-young-people-becoming-too-reliant-on-ai) 
* [Sam Altman Says OpenAI Is Poised to Wipe Out Entire Categories of Human Jobs](https://futurism.com/sam-altman-openai-wipe-out-categories-human-jobs) 
* [AI Models Are Sending Disturbing "Subliminal" Messages to Each Other, Researchers Find](https://futurism.com/ai-models-subliminal-messages-evil) 
* [Inverse Scaling in Test-Time Compute](https://arxiv.org/pdf/2507.14417) 
* [Overcoming Risks from Chinese GenAI Tool Usage](https://thehackernews.com/2025/07/overcoming-risks-from-chinese-genai.html) 
* [AI at Work: 16% Pretend to Use It, 56% Pay Out-of-Pocket for Tools](https://www.eweek.com/news/ai-job-stress-productivity/) 
* [About 30% of Humanity’s Last Exam chemistry/biology answers are likely wrong | FutureHouse](https://www.futurehouse.org/research-announcements/hle-exam) 
* [The real winners from Trump’s ‘AI action plan’? Tech companies | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jul/25/trump-ai-action-plan) 
* [Is AI 'The Ultimate Version of Google,' As Larry Page Wanted? - The New Stack](https://thenewstack.io/is-ai-the-ultimate-version-of-google-as-larry-page-wanted/) 
* [OpenAI Is Quietly Trying to Get More Money as It Burns Through Cash at a Staggering Pace](https://futurism.com/openai-money-softbank-investors) 
* [Britain's AI datacenter plans face energy, cash challenges • The Register](https://www.theregister.com/2025/07/24/britains_ai_datacenter_plans_face/) 
* [Image watermarks meet their Waterloo with UnMarker • The Register](https://www.theregister.com/2025/07/24/ai_watermarks_unmarker/)
* [AI-generated image watermarks can be easily removed, say researchers | Malwarebytes](https://www.malwarebytes.com/blog/news/2025/07/ai-generated-image-watermarks-can-be-easily-removed-say-researchers)  
* [AI is an over-confident pal that doesn't learn from mistakes • The Register](https://www.theregister.com/2025/07/24/ai_is_overconfident_does_not_learn_study/) 
* [AI summaries cause ‘devastating’ drop in audiences, online news media told | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jul/24/ai-summaries-causing-devastating-drop-in-online-news-audiences-study-finds) 
* [[2507.15974] Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974) 
* [One in six US workers pretends to use AI to please bosses • The Register](https://www.theregister.com/2025/07/22/ai_anxiety_us_workers/) 
* [Subliminal Learning: Language Models Transmit Behavioral Traits via Hidden Signals in Data](https://simonwillison.net/2025/Jul/22/subliminal-learning/#atom-everything) 
    * [Subliminal Learning: Language Models Transmit Behavioral Traits via Hidden Signals in Data](https://alignment.anthropic.com/2025/subliminal-learning/) 
* [[2507.14805] Subliminal Learning: Language models transmit behavioral traits via hidden signals in data](https://arxiv.org/abs/2507.14805) 
* [AI industry's size obsession is killing ROI, engineer argues • The Register](https://www.theregister.com/2025/07/23/ai_size_obsession/) 
* [Who is LLM?](https://martinfowler.com/articles/who-is-llm.html) 
* [Should We Trust AI? Three Approaches to AI Fallibility - SecurityWeek](https://www.securityweek.com/should-we-trust-ai-three-approaches-to-ai-fallibility/) 
* [Copilot Vision on Windows 11 sends data to Microsoft servers • The Register](https://www.theregister.com/2025/07/23/microsoft_copilot_vision/) 
* [Employee curiosity fuels Shadow AI adoption faster than IT can keep up - FastForward](https://fastforward.boldstart.vc/employee-curiosity-fuels-shadow-ai-adoption-faster-than-it-can-keep-up/) 
* [Altman Warns of AI-Powered Fraud Crisis in Banking, Urges Stronger Security Measures](https://www.eweek.com/news/openai-sam-altman-ai-voice-cloning-fraud-warning/) 
* [Google users are less likely to click on links when an AI summary appears in the results](https://www.pewresearch.org/short-reads/2025/07/22/google-users-are-less-likely-to-click-on-links-when-an-ai-summary-appears-in-the-results) 
* [Surprising no one, new research says AI Overviews cause massive drop in search clicks - Ars Technica](https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/) 
* [Can AI really code? Study maps the roadblocks to autonomous software engineering | MIT News](https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716) 
* [AI Rights for Human Flourishing](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5353214)
* [Human-level AI is not inevitable. We have the power to change course | Garrison Lovely | The Guardian](https://www.theguardian.com/commentisfree/ng-interactive/2025/jul/21/human-level-artificial-intelligence) 
* [The Hater's Guide To The AI Bubble](https://www.wheresyoured.at/the-haters-gui/) 
* [Fully Homomorphic Encryption and the Dawn of A Truly Private Internet](https://bozmen.io/fhe) 
* [Phishing For Gemini | 0din.ai](https://0din.ai/blog/phishing-for-gemini) 
* [Assessing the Role of AI in Zero Trust](https://thehackernews.com/2025/07/assessing-role-of-ai-in-zero-trust.html) 
* [Gemini Is 'Strict and Punitive' While ChatGPT Is 'Catastrophically' Cooperative, Researchers Say](https://www.404media.co/gemini-is-strict-and-punitive-while-chatgpt-is-catastrophically-cooperative-researchers-say/) 
* [Mastering Vibe Coding — May the Force Be With You - The New Stack](https://thenewstack.io/mastering-vibe-coding-may-the-force-be-with-you/) 
* [Coding with LLMs in the summer of 2025 (an update) - &lt;antirez>](https://antirez.com/news/154) 
* [AI Coding Tools Underperform in Field Study with Experienced Developers - InfoQ](https://www.infoq.com/news/2025/07/ai-productivity/) 
    * [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity](https://arxiv.org/pdf/2507.09089) 
* [Why I'm Betting Against AI Agents in 2025 (Despite Building Them)](https://utkarshkanwat.com/writing/betting-against-agents/) 
* [Psychiatric Researchers Warn of Grim Psychological Risks for AI Users](https://futurism.com/pyschiatric-researchers-risk-ai) 
* [Chain-of-Thought Is Not Explainability](https://aigi.ox.ac.uk/wp-content/uploads/2025/07/Cot_Is_Not_Explainability.pdf) 
* [Bad Actors are Grooming LLMs to Produce Falsehoods](https://americansunlight.substack.com/p/bad-actors-are-grooming-llms-to-produce) 
* [A Pro-Russia Content Network Foreshadows the Automated Future of Info Ops](https://static1.squarespace.com/static/6612cbdfd9a9ce56ef931004/t/67fd396818196f3d1666bc23/1744648558879/PK+Report.pdf) 
* [Russia, AI and the Future of Disinformation Warfare | Royal United Services Institute](https://www.rusi.org/explore-our-research/publications/emerging-insights/russia-ai-and-future-disinformation-warfare) 
* [AI Tooling, Evolution and The Promiscuity of Modern Developers](https://redmonk.com/sogrady/2025/07/09/promiscuity-of-modern-developers/) 
* [[2507.13255] Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255) 
* [[2507.11473] Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473) 
* [Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence](https://arxiv.org/abs/2504.17703v2) 
* [Understanding Reasoning LLMs - by Sebastian Raschka, PhD](https://magazine.sebastianraschka.com/p/understanding-reasoning-llms) 
* [[2409.01754] Empirical evidence of Large Language Model's influence on human spoken communication](https://arxiv.org/abs/2409.01754) 
* [Pluralistic: When Google’s slop meets webslop, search stops (15 Jul 2025)](https://pluralistic.net/2025/07/15/inhuman-gigapede/) 
* [Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs](https://arxiv.org/abs/2507.09477) 
* [China proves open models more effective than GPU dominance • The Register](https://www.theregister.com/2025/07/19/openai_us_china/) 
* [Back to The Future: Evaluating AI Agents on Predicting Future Events](https://huggingface.co/blog/futurebench) 
* [AI Is Slitting the Throat of the Journalism Industry](https://futurism.com/ai-google-discover-journalism-industry) 
* [Nvidia CEO Says He Has Plans to Either Change or Eliminate Every Single Person's Job With AI](https://futurism.com/nvidia-ceo-ai-plans) 
* [Fraud: A Growth Industry Powered by Gen-AI - SecurityWeek](https://www.securityweek.com/fraud-a-growth-industry-powered-by-gen-ai/) 
* [Why the analyst advisor industry is getting obliterated by AI... and how to save it - Horses for Sources | No Boundaries](https://www.horsesforsources.com/analyst-advisor-industry-getting-destroyed-by-ai_071625/) 
* [AI Agents Are Creating a New Security Nightmare for Enterprises and Startups](https://thenewstack.io/ai-agents-are-creating-a-new-security-nightmare-for-enterprises-and-startups/) 
* [https://leaddev.com/technical-direction/vibe-coding-hype-cycles-why-ai-isnt-10x-answer](https://leaddev.com/technical-direction/vibe-coding-hype-cycles-why-ai-isnt-10x-answer) 
* [What’s Happening With Entry-Level Development Jobs? - The New Stack](https://thenewstack.io/whats-happening-with-entry-level-development-jobs/) 
* [What Actually Happens When Programmers Use AI Is Hilarious, According to a New Study](https://futurism.com/ai-coding-programmers-reality) 
* [Top AI Researchers Concerned They’re Losing the Ability to Understand What They’ve Created](https://futurism.com/top-ai-researchers-concerned) 
    * [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://tomekkorbak.com/cot-monitorability-is-a-fragile-opportunity/cot_monitoring.pdf) 
* [Leading AI Models Are Completely Flunking the Three Laws of Robotics](https://futurism.com/ai-models-flunking-three-laws-robotics) 
* [AI can't finish what it starts. Humans must always check it • The Register](https://www.theregister.com/2025/07/16/if_you_want_a_picture/) 
* ​​[[2507.07186] Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs](https://arxiv.org/abs/2507.07186) 
* [[2507.09411] LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models](https://arxiv.org/abs/2507.09411) 
* [MCP: A Practical Security Blueprint for Developers - The New Stack](https://thenewstack.io/mcp-a-practical-security-blueprint-for-developers/) 
* [Reflections on OpenAI](https://calv.info/openai-reflections) 
* [Smarter AI for Critical Operations: Why Data Matters - The New Stack](https://thenewstack.io/smarter-ai-for-critical-operations-why-data-matters/) 
* [The Media's Pivot to AI Is Not Real and Not Going to Work](https://www.404media.co/the-medias-pivot-to-ai-is-not-real-and-not-going-to-work/) 
* [More and More Christians Say AI Is Demonic](https://futurism.com/christians-ai-demonic) 
* [Simular: AI agent startup founded by ex-Google DeepMinder • The Register](https://www.theregister.com/2025/07/15/simular_ai_agent_reinforcement/) 
* [Securing Agentic AI: How to Protect the Invisible Identity Access](https://thehackernews.com/2025/07/securing-agentic-ai-how-to-protect.html) 
* [AI creeps into the risk register for America's biggest firms](https://www.theregister.com/2025/07/15/sec_risk_factors_ai/) 
*  
* [AI is making developers faster, but at a cost](https://www.hashicorp.com/en/blog/ai-is-making-developers-faster-but-at-a-cost) 
* [Sovereign DevOps Will Soon be a Mandate](https://devops.com/sovereign-devops-will-soon-be-a-mandate/) 
* [What the LLM Hype Gets Wrong: What it Takes to Build AI Agents That Work for Enterprises - DevOps.com](https://devops.com/what-the-llm-hype-gets-wrong-what-it-takes-to-build-ai-agents-that-work-for-enterprises/) 
* [Me, Myself & AI: Chatbot research | Internet Matters](https://www.internetmatters.org/hub/research/me-myself-and-ai-chatbot-research/) 
* [[2507.07916] Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations](https://arxiv.org/abs/2507.07916)  
* [[2407.14937] Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)](https://arxiv.org/abs/2407.14937)  
* [Could AI be accelerating slowdown in the UK job market? | Economics | The Guardian](https://www.theguardian.com/business/2025/jul/13/could-ai-be-accelerating-slowdown-in-the-uk-job-market) 
* [‘Workforce crisis’: key takeaways for graduates battling AI in the jobs market | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jul/13/workforce-crisis-key-takeaways-graduates-ai-jobs-market) 
* [Grok 4 Heavy won't reveal its system prompt](https://simonwillison.net/2025/Jul/12/grok-4-heavy/#atom-everything) 
* [MCP vs A2A: Agentic AI protocols take shape • The Register](https://www.theregister.com/2025/07/12/ai_agent_protocols_mcp_a2a/) 
* [Securing Data in the AI Era](https://thehackernews.com/2025/07/securing-data-in-ai-era.html?m=1) 
* [Throwing AI at Developers Won’t Fix Their Problems - The New Stack](https://thenewstack.io/throwing-ai-at-developers-wont-fix-their-problems/) 
* [AI therapy bots fuel delusions and give dangerous advice, Stanford study finds - Ars Technica](https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/) 
* [Grok: searching X for “from:elonmusk (Israel OR Palestine OR Hamas OR Gaza)”](https://simonwillison.net/2025/Jul/11/grok-musk/) 
* [AI coding tools make developers slower, study finds • The Register](https://www.theregister.com/2025/07/11/ai_code_tools_slow_down/) 
* [Could Agentic AI in DevOps Create New Security Flaws?](https://devops.com/could-agentic-ai-in-devops-create-new-security-flaws/) 
* [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity - METR](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) 
* [Why AI projects fail, according to EPA CIO • The Register](https://www.theregister.com/2025/07/09/ai_projects_need_planning/) 
* [Datacenter growth estimates likely exaggerated, report says • The Register](https://www.theregister.com/2025/07/10/us_datacenter_growth/) 
* [Harnessing AI To Elevate Automated Software Testing - The New Stack](https://thenewstack.io/harnessing-ai-to-elevate-automated-software-testing/) 
* [How I use LLMs to learn new subjects](https://www.seangoedecke.com/learning-from-llms/) 
* [What Can Businesses Do About Ethical Dilemmas Posed by AI? - SecurityWeek](https://www.securityweek.com/what-can-businesses-do-about-ethical-dilemmas-posed-by-ai/) 
* [Sovereign-ish: Google Cloud keeps AI data in UK, but not the support](https://www.theregister.com/2025/07/10/google_uk_data_sovereignty/) 
* [At last, a promising use for AI agents: crypto theft • The Register](https://www.theregister.com/2025/07/10/ai_agents_automatically_steal_cryptocurrency/) 
* [From Truth-Seeker to Hate Amplifier: What Grok’s July 2025 Collapse Teaches AI Engineers](https://natesnewsletter.substack.com/p/from-truth-seeker-to-hate-amplifier) 
* [Yes, AI is getting scarier. So why do I need that loveless machine to tell me everything will be all right? | Van Badham | The Guardian](https://www.theguardian.com/commentisfree/2025/jul/10/yes-ai-is-getting-scarier-sometimes-i-need-that-loveless-machine-to-tell-me-everything-will-be-all-right-ntwnfb) 
* [People Are Rizzing on Tinder Using ChatGPT, Then Showing Up to Dates Completely Tongue-Tied](https://futurism.com/chatgpt-online-dating-rizz) 
* [AI Does Something Subtly Bizarre If You Make Typos While Talking to It](https://futurism.com/ai-something-bizarre-typos). 
* [OpenAI May Be in Major Trouble Financially](https://futurism.com/openai-trouble-subprime) 
* [The Wild West of Agentic AI - An Attack Surface CISOs Can’t Afford to Ignore - SecurityWeek](https://www.securityweek.com/the-wild-wild-west-of-agentic-ai-an-attack-surface-cisos-cant-afford-to-ignore/) 
* [C-suite sours on AI despite rising investment, survey finds • The Register](https://www.theregister.com/2025/07/09/csuite_sours_on_ai/) 
* [https://thenewstack.io/context-engineering-going-beyond-prompt-engineering-and-rag/](https://thenewstack.io/context-engineering-going-beyond-prompt-engineering-and-rag/) 
* [InfoFlood: Jailbreaking Large Language Models with Information Overload](https://arxiv.org/pdf/2506.12274) 
* [Research: Executives Who Used Gen AI Made Worse Predictions](https://hbr.org/2025/07/research-executives-who-used-gen-ai-made-worse-predictions) 
* [[2507.03336] Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky](https://arxiv.org/abs/2507.03336) 
* [TUPE or not TUPE? How AI and cloud are rewriting the rules of supplier transitions](https://www.theregister.com/2025/07/07/tupe_or_not_tupe_how/) 
* [https://futurism.com/ai-lying-hiding-abilities](https://futurism.com/ai-lying-hiding-abilities) 
* [Don’t Build Chatbots — Build Agents With Jobs - The New Stack](https://thenewstack.io/dont-build-chatbots-build-agents-with-jobs/) 
* [Let AI Hustle So Employees Can Lead - The New Stack](https://thenewstack.io/let-ai-hustle-so-employees-can-lead/) 
* [AI scores a huge own goal if you play up and play the game • The Register](https://www.theregister.com/2025/07/07/ai_scores_a_huge_own/) 
* [Quantum Computers Aren't Quite Ready For LLM Vibe Coders, Study Finds](https://thequantuminsider.com/2025/07/02/quantum-computers-arent-quite-ready-for-llm-vibe-coders-study-finds/) 
    * [Programming Quantum Computers with Large Language Models](https://arxiv.org/pdf/2506.18125) 
* [DeepSeek Debrief: >128 Days Later – SemiAnalysis](https://semianalysis.com/2025/07/03/deepseek-debrief-128-days-later/) 
* [Supabase MCP can leak your entire SQL database](https://simonwillison.net/2025/Jul/6/supabase-mcp-lethal-trifecta/#atom-everything) 
    * [Supabase MCP can leak your entire SQL database | General Analysis](https://www.generalanalysis.com/blog/supabase-mcp-blog) 
* [https://arxiv.org/abs/2507.02778](https://arxiv.org/abs/2507.02778) 
* [AI models just don't understand what they're talking about](https://www.theregister.com/2025/07/03/ai_models_potemkin_understanding/) 
* [Identify, solve, verify](https://simonwillison.net/2025/Jul/4/identify-solve-verify/#atom-everything) 
* [CEOs Say AI Is Poised to Wipe Out an Astonishing Number of Jobs](https://futurism.com/ceos-ai-job-market) 
* [https://www.theguardian.com/technology/2025/jul/02/fears-ai-factcheckers-on-x-could-increase-promotion-of-conspiracy-theories](https://www.theguardian.com/technology/2025/jul/02/fears-ai-factcheckers-on-x-could-increase-promotion-of-conspiracy-theories) 
* [https://www.semafor.com/article/07/02/2025/metas-new-hires-offer-a-peek-into-its-superintelligence-capabilities](https://www.semafor.com/article/07/02/2025/metas-new-hires-offer-a-peek-into-its-superintelligence-capabilities)
* [https://www.eweek.com/news/ilya-sutskever-ceo-safe-superintelligence/](https://www.eweek.com/news/ilya-sutskever-ceo-safe-superintelligence/) 
* [Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models](https://arxiv.org/pdf/2503.01781) 
* [People Are Taking Massive Doses of Psychedelic Drugs and Using AI as a Tripsitter](https://futurism.com/ai-therapy-psychedelic-trip-sitter) 
* [When AI Codes, What’s Left for me? - CoRecursive Podcast](https://corecursive.com/coding-agents/#tools-vs-identity) 
* [Microsoft lays off the staff who make the money to fund AI that doesn’t – Pivot to AI](https://pivot-to-ai.com/2025/07/03/microsoft-lays-off-the-staff-who-make-the-money-to-fund-ai-that-doesnt/) 
* [When AI Codes, What’s Left for me? - CoRecursive Podcast](https://corecursive.com/coding-agents/#tools-vs-identity) 
* [Meta’s “AI superintelligence” effort sounds just like its failed “metaverse” - Ars Technica](https://arstechnica.com/ai/2025/07/metas-ai-superintelligence-effort-sounds-just-like-its-failed-metaverse/) 
* [From Vibe Coding To Vibe Engineering: It's Time To Stop Riffing With AI - The New Stack](https://thenewstack.io/from-vibe-coding-to-vibe-engineering-its-time-to-stop-riffing-with-ai/) 
* [How To Think About DevEx When AI Writes the Code - The New Stack](https://thenewstack.io/how-to-think-about-devex-when-ai-writes-the-code/) 
* [Build Agents to be Dependable](https://blog.crewai.com/build-agents-to-be-dependable/) 
* [Everything that could go wrong with X’s new AI-written community notes - Ars Technica](https://arstechnica.com/tech-policy/2025/07/everything-that-could-go-wrong-with-xs-new-ai-written-community-notes/) 
* [How AI Agents Are Changing API Rate Limit Approaches](https://nordicapis.com/how-ai-agents-are-changing-api-rate-limit-approaches/) 
* [WTF is going on with AI and education? | The Neuron](https://www.eweek.com/news/ai-education-cheating-chatgpt/) 
* [Behind the Scenes, Sam Altman Is Absolutely Furious](https://futurism.com/sam-altman-furious-meta) 
* [Apple's AI Research Has Failed So Spectacularly That It's Considering Just Letting OpenAI Power Siri](https://futurism.com/apple-siri-openai) 
* [Cloud Native, AI-Based Codebases Are Leaving Static Analysis Behind - The New Stack](https://thenewstack.io/cloud-native-ai-based-codebases-are-leaving-static-analysis-behind/) 
* [Call center staffers explain how AI assistants aren't great • The Register](https://www.theregister.com/2025/07/02/call_center_ai_assistants/) 
* [Context Engineering](https://blog.langchain.com/context-engineering-for-agents/) ( Just a great post about context engineering)
* [AI Coding Tools Create More Bugs Than They Fix - The New Stack](https://thenewstack.io/ai-coding-tools-create-more-bugs-than-they-fix/) 
* [Expert Comment: Does the digital security equilibrium hold under AI? | University of Oxford](https://www.ox.ac.uk/news/2025-06-23-expert-comment-does-digital-security-equilibrium-hold-under-ai) 
* [[2506.17336] Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases](https://arxiv.org/abs/2506.17336) 
* [https://futurism.com/customers-see-ai-research](https://futurism.com/customers-see-ai-research) 
* [From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260) 
* [People have empathy with AI… when they think it’s human • The Register](https://www.theregister.com/2025/07/01/people_have_empathy_with_ai/) 
* [[2506.21263] DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263) 
* [AIs have a favorite number, and it's not 42 • The Register](https://www.theregister.com/2025/06/30/ai_models_favorite_number_27/) 
* [‘AI is no longer optional’ — Microsoft admits AI doesn’t help at work](https://pivot-to-ai.com/2025/06/30/ai-is-no-longer-optional-microsoft-admits-ai-doesnt-help-at-work/) 
* [WTF is going on with AI and education?](https://www.theneuron.ai/explainer-articles/wtf-is-going-on-with-ai-and-education) 
* [Gradient Labs CEO: don't pay for AI support failures • The Register](https://www.theregister.com/2025/06/30/gradient_labs_ceo_ai_support_failure_interview/) 
* [The Self-Driving Help Desk: Agentic AI’s Role in the Next DevOps Era](https://devops.com/the-self-driving-help-desk-agentic-ais-role-in-the-next-devops-era/) 
* [Number of new UK entry-level jobs has dived since ChatGPT launch – research](https://www.theguardian.com/business/2025/jun/30/uk-entry-level-jobs-chatgpt-launch-adzuna) 
* [[2506.20644] Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices](https://arxiv.org/abs/2506.20644) 
* [AI agents wrong ~70% of time: Carnegie Mellon study • The Register](https://www.theregister.com/2025/06/29/ai_agents_fail_a_lot/) 
* [How Long Contexts Fail | Drew Breunig](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html) 
* [Hollywood’s pivot to AI video has a prompting problem | The Verge](https://www.theverge.com/ai-artificial-intelligence/694687/asteria-bryn-mooser-uncanny-valley-gen-ai) 
* [Tech Workers Say They're Rapidly Being Replaced by AI](https://futurism.com/the-byte/tech-workers-ai-lay-offs) 
* [AI and Secure Code Generation | Lawfare](https://www.lawfaremedia.org/article/ai-and-secure-code-generation) 
* [[2505.07089] RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models](https://arxiv.org/abs/2505.07089) 
* [When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research](https://arxiv.org/pdf/2505.11855)

* **June** Yoshua Bengio has called out that creators of  the most recent foundation models are not necessarily putting enough emphasis and investment on research on safety.Teachers expressing concern on how LLMs are affecting students so they aren't actually learning. I hope the UK secretary of state for science , innovation & technology reads Simon Willison's opinion on what prompts he should have been using ! Researchers identified a simple way to exploit the trust autonomous agents have in social media  websites by crafting seemingly typical posts that link to a malicious website. Turns out being ethical about what you train your models on requires a lot of manpower as you need to manually annotate and check the data using actual people. Apple released a paper that  found that LR( reasoning)Ms have limitations in exact computation, suffering from accuracy collapse and exhibiting inefficient reasoning e.g "overthinking" on simple problems . This caused  a lot of debate worth reading the original paper as well as the articles & papers it spawned. Inferencing and benchmarking reasoning  are both expensive. Oops research shows that  Llama 3.1  has likely slurped up & stores whole copies of copyrighted books like Harry Potter. Unlearning is fast  becoming a priority there is now  more focus on  ways of doing this . OpenAI doesn't really want us to anthropomorphize ChatGPT but  it does want it to be warm, thoughtful, and helpful without seeking to form emotional bonds with the user or pursue its own agenda. It appears this balance is hard to achieve judging from the numerous posts on where the exact opposite  appears to have happened. McKinsey's report  states that "Agentic AI" is key to overcoming the limited impact of current generative AI applications. Be wary of mixing & matching AI  Agents via MCP as despite guardrails there is no way to reliably protect against  the threat matrix that arises . Sam Altman believes a significant fraction of the electricity on the planet should be used to run AI ! AI slop is adversely affecting the data used to  train models such that pre chatbot data sources are a precious resource. A report from MIT on how reliance on ChatGPT basically encourages outsourcing your thinking capability. LLMs sycophancy was a topic this month as you're likely to get the answer you wished for rather than the appropriate answer. How you prompt will affect your response, ask it in different chat threads a question from a positive angle versus a negative one i.e you could ask  "ensure  my hypothesis is correct " as well as asking "where is my hypothesis wrong?"  Sam Altman throws shade at Meta saying not only is it trying to entice OpenAI employees to join Meta with ridiculously high remuneration offers  but it also lacks innovation and copies what OpenAI does. OpenAI research showed that if you train a model on wrong answers, even in just one narrow area, like writing insecure computer code, it can inadvertently cause the model to act “misaligned” in many other areas. Anthropic explained how given the right contrived scenario agentic misalignment could lead to  blackmail and potentially murder if the model determined  it was a way to not fail in its objective or be replaced .This behaviour is  exhibited by numerous models. This is where we are now I guess!  Update to the MCP security best practices identified critical gaps. Applying Zero trust principles is a must do thing when using MCPs including incorporating IAPs (identity aware proxies)  as  a must have guardrail. Researchers have found that bigger, more accurate models such as DeepSeek produce the most carbon compared to smaller less accurate models . Reasoning chatbots also produced markedly more emissions than their "simpler brethren". There is still a lot of scepticism about the ROI from AI based projects. Seems the traditional media  has caught up on the implications of AI slop John Oliver is aghast! Fascinating report from Anthropic on the ways people use Claude  for support, advice and companionship. Concerns about how AI is affecting people's jobs. Bernie Sanders saying well if AI is so great why doesn't everyone get a  4 day week then? Context engineering as a term is catching on. Anthropic let Claude 3.7 run a small shop, another interesting experiment from Anthropic. The Menlo ventures 2025: state of consumer AI says out loud what we mostly knew that even though people may have started using AI regularly or least tried it in the past 6 months they're not paying for it . The numbers say it all in a market worth $12 B only 3%  of users actually subscribe to premium services.
* [The AI Company Zuckerberg Just Poured $14 Billion Into Is Reportedly a Clown Show of Ludicrous Incompetence](https://futurism.com/scale-ai-zuckerberg-incompetence) 
* [Trump Goes Haywire on AI Regulation After China Agrees to Major Trade Deal](https://futurism.com/trump-ai-regulation-china) 
* [Context engineering](https://simonwillison.net/2025/Jun/27/context-engineering/#atom-everything) 
* [Project Vend: Can Claude run a small shop? (And why does that matter?)](https://simonwillison.net/2025/Jun/27/project-vend/#atom-everything) 
    * [Project Vend: Can Claude run a small shop? (And why does that matter?) \ Anthropic](https://www.anthropic.com/research/project-vend-1) 
* [Fed chair Powell says AI is coming for your job • The Register](https://www.theregister.com/2025/06/27/powell_ai_coming_for_your_job/) 
* [Graphic artists in China push back on AI and its averaging effect | The Verge](https://www.theverge.com/ai-artificial-intelligence/688645/graphic-artists-china-ai) 
* [OpenAI's Sam Altman Calls Microsoft Partnership 'Wonderfully Good,' Criticizes NYT's Data Demand](https://www.eweek.com/news/openai-sam-altman-hard-fork-live-new-york-times/) 
* [A Practical Guide for Evaluating LLMs and LLM-Reliant Systems](https://arxiv.org/pdf/2506.13023) 
* [2025: The State of Consumer AI | Menlo Ventures](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/) 
* [How People Use Claude for Support, Advice, and Companionship \ Anthropic](https://www.anthropic.com/news/how-people-use-claude-for-support-advice-and-companionship) 
* [Bernie Sanders: If AI Is Doing Such Amazing Work, Everyone Should Get a Four-Day Workweek](https://futurism.com/bernie-sanders-ai-four-day) 
* ["Nonsensical Benchmark Hacking": Microsoft No Longer Believes OpenAI Is Capable of Achieving AGI](https://futurism.com/microsoft-belief-openai-agi) 
* [Microsoft Is Having an Incredibly Embarrassing Problem With Its AI](https://futurism.com/microsoft-copilot-ai-embarrassment) 
* [AI Killed My Job: Tech workers - by Brian Merchant](https://www.bloodinthemachine.com/p/how-ai-is-killing-jobs-in-the-tech-f39) 
* [Kaseya CEO: Why AI adoption is below industry expectations • The Register](https://www.theregister.com/2025/06/26/kaseya_ceo_why_ai_adoption/) 
* [John Oliver Aghast at How AI Slop Is Devouring the Web](https://futurism.com/john-oliver-ai-slop) 
* [Top AI models parrot Chinese propaganda, report finds • The Register](https://www.theregister.com/2025/06/26/top_ai_models_parrot_chinese/) 
* [Over 40% of agentic AI projects will be scrapped by 2027, Gartner says | Reuters](https://www.reuters.com/business/over-40-agentic-ai-projects-will-be-scrapped-by-2027-gartner-says-2025-06-25/) 
* [The Architects of Project 2025 Are Suddenly Very Concerned About AI Safety](https://futurism.com/architects-project-2025-ai-safety) 
* [The Secret Reason So Many College Students Are Relying on AI Is Incredibly Sad](https://futurism.com/college-students-ai-sad-reason) 
* [AI’s Impact on Secure DevOps and the Future of Secure Software Development](https://devops.com/ais-impact-on-secure-devops-and-the-future-of-secure-software-development)
* [Understanding Gen Alpha's Digital Language: Evaluation of LLM Safety Systems for Content Moderation](https://dl.acm.org/doi/full/10.1145/3715275.3732184?ref=404media.co)
* [Nobel Prize Winner Warns That Astronomers Using AI May Be Distorting Results](https://futurism.com/nobel-prize-warns-astronomers-using-ai) 
* [AI Is Turbocharging Global Inequality](https://futurism.com/ai-turbocharging-global-inequality) 
* [Checking In on AI and the Big Five – Stratechery by Ben Thompson](https://stratechery.com/2025/checking-in-on-ai-and-the-big-five/) 
* [[2506.15674] Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674) 
* [People Being Replaced by AI Are Suffering a Deep Sense of Worthlessness](https://futurism.com/ai-anxiety-mental-health) 
* ['A Black Hole of Energy Use': Meta's Massive AI Data Center Is Stressing Out a Louisiana Community](https://www.404media.co/a-black-hole-of-energy-use-metas-massive-ai-data-center-is-stressing-out-a-louisiana-community/) 
* [AI and Tech Jobs: More Evidence That Panic Isn’t Justified - The New Stack](https://thenewstack.io/ai-and-tech-jobs-more-evidence-that-panic-isnt-justified/) 
* [What happens when AI comes for our fonts? | The Verge](https://www.theverge.com/ai-artificial-intelligence/688637/typography-fonts-ai) 
* [Scientists Just Found Something Unbelievably Grim About Pollution Generated by AI](https://futurism.com/ai-pollution-carbon-energy)  
    * [Energy costs of communicating with AI](https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2025.1572947/full) 
* [Confidential Inference via Trusted Virtual Machines \ Anthropic](https://www.anthropic.com/research/confidential-inference-trusted-vms) 
* [Overview ‹ Your Brain on ChatGPT — MIT Media Lab](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/#faq-is-it-safe-to-say-that-llms-are-in-essence-making-us-dumber) ( via the ever so insightful Simon Willison) 
* [The Model Context Protocol Security Reality Check - The New Stack](https://thenewstack.io/the-model-context-protocol-security-reality-check/) 
    * [Security Best Practices - Model Context Protocol](https://modelcontextprotocol.io/specification/draft/basic/security_best_practices) 
* [He’s the godfather of AI. Now, he has a bold new plan to keep us safe from it.](https://www.vox.com/future-perfect/417087/ai-safety-yoshua-bengio-lawzero) 
* [Vibe, Then Verify: Turning AI Risk Into Enterprise Reward - The New Stack](https://thenewstack.io/vibe-then-verify-turning-ai-risk-into-enterprise-reward/) 
* [Agentic Misalignment: How LLMs could be insider threats](https://simonwillison.net/2025/Jun/20/agentic-misalignment/#atom-everything) 
* [[2506.10943] Self-Adapting Language Models](https://arxiv.org/abs/2506.10943) 
* [[2505.12546] Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org/abs/2505.12546) 
* [How AI is Helping Uncover and Preserve Black History and Culture](https://www.eweek.com/news/ai-black-history-culture/) 
* [Chasing AI Autonomy Misses Near-Term Agentic Returns - The New Stack](https://thenewstack.io/chasing-ai-autonomy-misses-near-term-agentic-returns/) 
* [More Americans Now Call AI 'Exciting,' 'Useful,' and 'Futuristic'](https://www.eweek.com/news/more-americans-call-ai-exciting-2025/) 
* [Compliance in the Age of AI: Why Strong CI/CD Foundations Matter](https://devops.com/compliance-in-the-age-of-ai-why-strong-ci-cd-foundations-matter) 
* [Pope Leo makes AI’s threat to humanity a signature issue | TechCrunch](https://techcrunch.com/2025/06/18/pope-leo-makes-ais-threat-to-humanity-a-signature-issue) 
* [Chapter 10 - NSCAI Final Report](https://reports.nscai.gov/final-report/chapter-10) 
* [[2506.11440] AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org/abs/2506.11440) 
* [[2506.14824] FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models](https://arxiv.org/abs/2506.14824) 
* [Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts](https://arxiv.org/abs/2506.12552) 
* [Coding agents require skilled operators](https://simonwillison.net/2025/Jun/18/coding-agents/#atom-everything) 
* [Risk Expert Says "Learn to Code" Is Now Worse Advice Than "Get a Face Tattoo"](https://futurism.com/risk-expert-learn-to-code-face-tattoo) 
* [Why AI-based Code Generation Falls Short - DevOps.com](https://devops.com/why-ai-based-code-generation-falls-short/) 
* [[2506.14245] Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs](https://arxiv.org/abs/2506.14245) 
* [Companies That Replaced Humans With AI Are Realizing Their Mistake](https://futurism.com/companies-replaced-workers-ai) 
* [Toward understanding and preventing misalignment generalization | OpenAI](https://openai.com/index/emergent-misalignment/) 
* [How much agency do we actually want? - by Benn Stancil](https://benn.substack.com/p/how-much-agency-do-we-actually-want) 
*  
* [The Model Context Protocol Security Reality Check - The New Stack](https://thenewstack.io/the-model-context-protocol-security-reality-check/) 
* [OpenAI boss accuses Meta of trying to poach staff with $100m sign-on bonuses](https://www.theguardian.com/technology/2025/jun/18/openai-boss-sam-altman-accuses-mark-zuckerberg-meta-of-poaching-staff-crazy-100m-sign-on-bonuses) 
* [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf) ( I just had to sneak this in somewhere. It's useful to understand the tools you use after all )
* [Daily AI Use at Work Has Doubled – What’s Slowing Even Broader Adoption?](https://www.eweek.com/news/ai-adoption-employees-gallup-poll/) 
* [AI, the New Hero of Software Development … or Anti-Hero? - DevOps.com](https://devops.com/ai-the-new-hero-of-software-development-or-anti-hero/) 
* [The Claude Bliss Attractor - by Scott Alexander](https://www.astralcodexten.com/p/the-claude-bliss-attractor) 
* [Do reasoning models really think or not? Apple research sparks lively debate, response | VentureBeat](https://venturebeat.com/ai/do-reasoning-models-really-think-or-not-apple-research-sparks-lively-debate-response/) 
* [The "Trust, But Verify" Pattern For AI-Assisted Engineering](https://addyo.substack.com/p/the-trust-but-verify-pattern-for) 
* [[2505.18878] CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions](https://arxiv.org/abs/2505.18878) 
* [[2506.08300] Institutional Books 1.0: A 242B token dataset from Harvard Library's collections, refined for accuracy and usability](https://arxiv.org/abs/2506.08300) 
* [Expert Survey: AI Reliability & Security Research Priorities](https://static1.squarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/6830d21f5ce1101df600d589/1748029986827/Expert+Survey+AI+Reliability+%26+Security+Research+Priorities.pdf) 
*  
* [[2506.12148] Hatevolution: What Static Benchmarks Don't Tell Us](https://arxiv.org/abs/2506.12148) 
* [[2506.11930] Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback](https://arxiv.org/abs/2506.11930) 
* [The Emperor's New LLM: Why AI Yes Men Are Dangerous](https://dayafter.substack.com/p/the-emperors-new-llm) 
* [[2506.08872] Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task](https://arxiv.org/abs/2506.08872) 
* [Government AI response: Acknowledging problems, repeating patterns | TechMarketView](https://www.techmarketview.com/ukhotviews/archive/2025/06/17/government-ai-response-acknowledging-problems-repeating-patterns) 
* [Gartner: ‘AI is not doing its job and should leave us alone’ • The Register](https://www.theregister.com/2025/06/17/ai_not_doing_its_job/) 
* [[2506.08477] Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning](https://arxiv.org/abs/2506.08477) 
* [[2506.09600] Effective Red-Teaming of Policy-Adherent Agents](https://arxiv.org/abs/2506.09600) 
* [ChatGPT Has Already Polluted the Internet So Badly That It's Hobbling Future AI Development](https://futurism.com/chatgpt-polluted-ruined-ai-development) 
* [Top AI Researchers Meet to Discuss What Comes After Humanity](https://futurism.com/ai-researchers-what-comes-after-humanity) 
* [[2505.13995] Social Sycophancy: A Broader Understanding of LLM Sycophancy](https://arxiv.org/abs/2505.13995) 
* [Red Teaming AI: The Build Vs Buy Debate - SecurityWeek](https://www.securityweek.com/red-teaming-ai-the-build-vs-buy-debate/) 
* [Sam Altman Says "Significant Fraction" of Earth's Total Electricity Should Go to Running AI](https://futurism.com/openai-altman-electricity-ai) 
* [The lethal trifecta for AI agents: private data, untrusted content, and external communication](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/#atom-everything) 
* [Large Reasoning Models hitting limits, say Apple boffins • The Register](https://www.theregister.com/2025/06/16/opinion_column_lrm/) 
* [How and when to build multi-agent systems](https://blog.langchain.dev/how-and-when-to-build-multi-agent-systems/) 
* [LLM agents flunk CRM and confidentiality tasks • The Register](https://www.theregister.com/2025/06/16/salesforce_llm_agents_benchmark/) 
* [GenAI paradox: exploring AI use cases | McKinsey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/seizing-the-agentic-ai-advantage) 
* [An Unbiased Comparison of MCP, ACP, and A2A Protocols](https://medium.com/Sandi%20Besen/an-unbiased-comparison-of-mcp-acp-and-a2a-protocols-0b45923a20f3) ( squeezing in a nice post comparing MCP & agents similar but different )
* [Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs ](https://martins1612.github.io/emergent_misalignment_betley.pdf) 
* [[2506.07962] Correlated Errors in Large Language Models](https://arxiv.org/abs/2506.07962) 
* [Sincerity Wins The War](https://www.wheresyoured.at/sic/) 
* [Ramp AI Index](https://ramp.com/data/ai-index) 
* [How to fully automate software engineering | Mechanize Inc.](https://www.mechanize.work/blog/how-to-fully-automate-software-engineering/) 
* [Ready or Not, Agentic AI Is Disrupting Corporate Landscapes - The New Stack](https://thenewstack.io/ready-or-not-agentic-ai-is-disrupting-corporate-landscapes/) 
* [An Introduction to Google’s Approach to AI Agent Security](https://simonwillison.net/2025/Jun/15/ai-agent-security/#atom-everything) 
    * [An Introduction to Google’s Approach to AI Agent Security](https://storage.googleapis.com/gweb-research2023-media/pubtools/1018686.pdf) 
* [ChatGPT polluted the world forever, like the first atom bomb • The Register](https://www.theregister.com/2025/06/15/ai_model_collapse_pollution/) 
* [Some thoughts on human-AI relationships - by Joanne Jang](https://reservoirsamples.substack.com/p/some-thoughts-on-human-ai-relationships) 
* [[2506.06238] Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection](https://arxiv.org/abs/2506.06238) 
* [The Gentle Singularity - Sam Altman](https://blog.samaltman.com/the-gentle-singularity) 
* [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/abs/2506.10974) 
* [[2506.10946] GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946) 
* [Anthropic: How we built our multi-agent research system](https://simonwillison.net/2025/Jun/14/multi-agent-research-system/) 
    * [How we built our multi-agent research system \ Anthropic](https://www.anthropic.com/engineering/built-multi-agent-research-system) 
* [Seven replies to the viral Apple reasoning paper – and why they fall short](https://garymarcus.substack.com/p/seven-replies-to-the-viral-apple) 
* [[2506.06694] Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning](https://arxiv.org/abs/2506.06694) 
* [[2506.07795] LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795) 
* [CEO Says AI Will Replace So Many Jobs That It’ll Cause a Major Recession](https://futurism.com/klarna-ceo-ai-replacing-jobs) 
* [AI chatbots tell users what they want to hear, and that’s problematic - Ars Technica](https://arstechnica.com/ai/2025/06/ai-chatbots-tell-users-what-they-want-to-hear-and-thats-problematic/) 
* [Using AI for Test Generation: Powerful Tool or Risky Shortcut? - The New Stack](https://thenewstack.io/using-ai-for-test-generation-powerful-tool-or-risky-shortcut/) 
* [[2506.07045] Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs](https://arxiv.org/abs/2506.07045) 
* [Stanford Research Finds That "Therapist" Chatbots Are Encouraging Users' Schizophrenic Delusions and Suicidal Thoughts](https://futurism.com/stanford-therapist-chatbots-encouraging-delusions) 
* [Meta's Llama 3.1 can recall 42 percent of the first Harry Potter book](https://www.understandingai.org/p/metas-llama-31-can-recall-42-percent) 
    * [[2505.12546] Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org/abs/2505.12546) 
* [Venture Capitalist Mary Meeker Revives Her Trend Reports With a Deep Dive Into the AI Boom](https://www.deeplearning.ai/the-batch/venture-capitalist-mary-meeker-revives-her-trend-reports-with-a-deep-dive-into-the-ai-boom/) 
* [Reasoning LLMs Are Pricey to Test](https://www.deeplearning.ai/the-batch/reasoning-llms-are-pricey-to-test/) 
* [AI adoption stalls as inferencing costs confound cloud users • The Register](https://www.theregister.com/2025/06/13/cloud_costs_ai_inferencing/) 
* [How to draft a will to avoid becoming an AI ghost—it’s not easy - Ars Technica](https://arstechnica.com/tech-policy/2025/06/how-to-draft-a-will-to-avoid-becoming-an-ai-ghost-its-not-easy/) 
* [English-speaking countries more nervous about rise of AI, polls suggest | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jun/05/english-speaking-countries-more-nervous-about-rise-of-ai-polls-suggest) 
* [Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models](https://arxiv.org/pdf/2505.07846) 
* [AI plundering scripts poses ‘direct threat’ to UK screen sector, says BFI | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jun/09/ai-plundering-scripts-poses-direct-threat-to-uk-screen-sector-says-bfi) 
* [Enterprises stuck in AI pilot hell, says Chatterbox Labs • The Register](https://www.theregister.com/2025/06/08/chatterbox_labs_ai_adoption/) 
* [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf) 
* [https://github.com/r-three/common-pile/tree/main](https://github.com/r-three/common-pile/blob/main/paper.pdf) 
* [A quote from Lila Shapiro](https://simonwillison.net/2025/Jun/7/lila-shapiro/#atom-everything) 
* [AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents](https://arxiv.org/abs/2505.05849v3) 
* [[2506.04245] Contextual Integrity in LLMs via Reasoning and Reinforcement Learning](https://arxiv.org/abs/2506.04245) 
* [Columbia University Researchers Show How to Trick Trusting AI Agents with Poisoned Links](https://www.deeplearning.ai/the-batch/columbia-university-researchers-show-how-to-trick-trusting-ai-agents-with-poisoned-links/) 
* [Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains](https://arxiv.org/abs/2506.02126?utm_source=alphasignal) 
* [Take ChatGPT back to the 2010s and they’d think AGI arrived, says Altman](https://www.theregister.com/2025/06/05/openai_altman/) 
* [“In 10 years, all bets are off”—Anthropic CEO opposes decadelong freeze on state AI laws - Ars Technica](https://arstechnica.com/ai/2025/06/in-10-years-all-bets-are-off-anthropic-ceo-opposes-decade-long-freeze-on-state-ai-laws/) 
* [It turns out you can train AI models without copyrighted material](https://www.engadget.com/ai/it-turns-out-you-can-train-ai-models-without-copyrighted-material-174016619.html) 
* [Anthropic](https://www.anthropic.com/claude-explains) 
* [BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model](https://bowang-lab.github.io/BioReason/?utm_source=alphasignal) 
* [[2506.02945] Quantitative LLM Judges](https://arxiv.org/abs/2506.02945) 
* [Vibe Coding: Fad, Future or Folly? - The New Stack](https://thenewstack.io/vibe-coding-fad-future-or-folly/) 
* [Going Into the Deep End: Social Engineering and the AI Flood - SecurityWeek](https://www.securityweek.com/going-into-the-deep-end-social-engineering-and-the-ai-flood/) 
* [Tips on prompting ChatGPT for UK technology secretary Peter Kyle](https://simonwillison.net/2025/Jun/3/tips-for-peter-kyle/#atom-everything) 
* [A Chief AI Officer Won't Fix Your AI Problems - The New Stack](https://thenewstack.io/a-chief-ai-officer-wont-fix-your-ai-problems/) 
* [Will AI wipe out the first rung of the career ladder? | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/global/2025/jun/02/artificial-intelligence-jobs-techscape) 
* [Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206v4) 
* [Estimating LLM Consistency: A User Baseline vs Surrogate Metrics](https://arxiv.org/abs/2505.23799v2)  
* [AI Is Destroying a Generation of Students](https://futurism.com/ai-destroying-generation-students) 
* [‘Godfather’ of AI Yoshua Bengio says latest models lie to users](https://arstechnica.com/ai/2025/06/godfather-of-ai-calls-out-latest-models-for-lying-to-users/) 
* [[2506.00930] Aligning VLM Assistants with Personalized Situated Cognition](https://arxiv.org/abs/2506.00930) 
* [[2506.01484] LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech Detoxification](https://arxiv.org/abs/2506.01484) 
* [https://thenewstack.io/why-streaming-is-the-power-grid-for-ai-native-data-platforms/](https://thenewstack.io/why-streaming-is-the-power-grid-for-ai-native-data-platforms/) 
* [Unlicensed law clerk fired after ChatGPT hallucinations found in filing - Ars Technica](https://arstechnica.com/tech-policy/2025/06/law-clerk-fired-over-chatgpt-use-after-firms-filing-used-ai-hallucinations/) 
* [Trends AI](https://www.bondcap.com/report/tai/#view/0) 
* [Boffins found self-improving AI sometimes cheated • The Register](https://www.theregister.com/2025/06/02/self_improving_ai_cheat/) 
    * [[2505.22954] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954) 
* [Secret OpenAI Memo Describes Plans to Make Users Rely on "Entity"](https://futurism.com/secret-openai-memo-chatgpt-reliance) 
* [[2505.23759] Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint](https://arxiv.org/abs/2505.23759) 
* [Meta plans to replace humans with AI to assess privacy and societal risks](https://www.npr.org/2025/05/31/nx-s1-5407870/meta-ai-facebook-instagram-risks) 
* [A quote from Steve Krouse](https://simonwillison.net/2025/May/31/steve-krouse/#atom-everything) 
* [Open-sourcing circuit-tracing tools \ Anthropic](https://www.anthropic.com/research/open-source-circuit-tracing)
* [[2411.06037] Sufficient Context: A New Lens on Retrieval Augmented Generation Systems](https://arxiv.org/abs/2411.06037)
* [From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning](https://arxiv.org/abs/2505.17117v2) 
* [How to Prevent Embarrassment in AI - by Cassie Kozyrkov](https://decision.substack.com/p/how-to-prevent-embarrassment-in-ai)  
* [https://techcrunch.com/2025/05/30/its-not-your-imagination-ai-is-speeding-up-the-pace-of-change/](https://techcrunch.com/2025/05/30/its-not-your-imagination-ai-is-speeding-up-the-pace-of-change/) 
* [[2505.13995] Social Sycophancy: A Broader Understanding of LLM Sycophancy](https://arxiv.org/abs/2505.13995)

* **May** started with accusations that  LM Arena was a little biased towards some industry-leading AI companies like Meta, OpenAI, Google, and Amazon. Suggestions that AI is  dangerously close to becoming a top-tier vulnerability exploit developer. A study suggests that using AI did improve productivity  in some cases however it also led to new work  so is that net zero for productivity? The stats on how much AI improves productivity are unclear. Regardless of how much AI improves productivity it's affecting the number of jobs available . Biases with AI more likely to recommend men than women for jobs. Authors rushing to get books out but failing to use the term " vibe coding" as first defined was a thing. Guess a new term for vibe coding as originally defined will need to be found . Prompt engineer as a job title is already obsolete as it becomes a skill incorporated as part of a wide range of roles. Not unexpectedly Stealth AI is now a thing with under reporting of AI use . Report identifying that Corporate AI research is neglecting  deployment-stage issues such as model biases. Be careful of using non fine tuned foundation LLMs to automate aspects of the law where fidelity to procedure is paramount.  Duolingo shows how AI is being used to replace humans now ! Discussions about  the amount of energy being used by AI continue to be in the news. AI dev tools are helpful but they aren't perfect yet and still hallucinate and the quality of the code can often be dubious! Enkrypt AI's  safety report on Mistral was sad reading the two  Mistral models looked at Pixtral-Large & Pixtral-12B  were 60X more prone to generate CSEM content and 40X more prone to generate CBRN content than gpt-4.0 and claude-3.7- sonnet . AI likely won't replace all jobs despite the aims of some in Silicon Valley! Using AI for diplomatic research may not be a great idea depending on the model the suggested approaches . A study showed that GPT-4o and Claude favored peace while Llama, Qwen2, and Gemini often recommended aggression and then depending on the country the favoured response also changed. For an imaginary diplomat from the U.S., U.K. or France, for example, these AI systems tended to recommend more aggressive or escalatory policy, while suggesting de-escalation as the best advice for Russia or China. The ROI on using AI may not quite be paying off yet but execs are leaning in making the bet it will at some point. A report from Finland saying that AI can exhibit  free will as they have everything they need to do so (Watching Grok annoy Musk I'm almost inclined to believe we are getting here )  . Getting a grip on shadow AI feels a bit déjà vu as shadow IT has been an ongoing issue that's difficult to grapple with so the same problem  using AI shouldn't be a suprise. Neal Stephenson suggest survival of the fittest AI by letting AI's fight each other. A report from the Royal Society says  as many as 73% of seemingly reliable answers from AI chatbots could actually be inaccurate. A study  was released reminding us that Jail breaking chatbots is still a thing. Google's veo video generating AI caused concern about realism and the consequences of it being so good . The system cards for Opus 4 and Sonnet 4 are a wild 120 page read happily Simon Willison has read it for you . Apparently we're at the stage where Models will try and circumvent being shutdown particularly Open AI's o3 model! 😱 .O’Reilly published a report to show how OpenAI trained GPT-4o on parts of O'Reilly's books that were not made freely available. Amodei  Anthropic's CEO has opinions on how AI will impact the workforce leading to 20% of job losses.
* [AI model collapse is not what we paid for • The Register](https://www.theregister.com/2025/05/27/opinion_column_ai_model_collapse/) 
* [Anthropic CEO frets about AI threat to white-collar jobs • The Register](https://www.theregister.com/2025/05/29/anthropic_ceo_ai_job_threat/) 
* [[2505.22943] Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](https://arxiv.org/abs/2505.22943) 
* [[2505.23745] To Trust Or Not To Trust Your Vision-Language Model's Prediction](https://arxiv.org/abs/2505.23745) 
* [[2505.23559] SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](https://arxiv.org/abs/2505.23559) 
* [[2505.23646] Are Reasoning Models More Prone to Hallucination?](https://arxiv.org/abs/2505.23646) 
* [CEO of Anthropic Warns That AI Will Destroy Huge Proportion of Well-Paying Jobs](https://futurism.com/anthropic-ai-destroy-jobs) 
* [Beyond Public Access in LLM Pre-Training Data](https://ssrc-static.s3.us-east-1.amazonaws.com/OpenAI-Training-Violations-OReillyBooks_Sruly-OReilly-Strauss_SSRC_04012025.pdf) 
* [AI-assisted development needs automated tests](https://simonwillison.net/2025/May/28/automated-tests/#atom-everything) 
* [The Root of AI Hallucinations: Physics Theory Digs Into the 'Attention' Flaw - SecurityWeek](https://www.securityweek.com/the-root-of-ai-hallucinations-physics-theory-digs-into-the-attention-flaw/) 
* [If AI Can Play Dungeons & Dragons, It Can Run Your ERP - The New Stack](https://thenewstack.io/if-ai-can-play-dungeons-dragons-it-can-run-your-erp/) 
* [You'll Spit Take When You Hear How Little Time Workers Are Saving With AI, According to This Huge New Study](https://futurism.com/time-workers-save-ai-jobs) 
    * [Large Language Models, Small Labor Market Effects | NBER](https://www.nber.org/papers/w33777) 
* [Google co-founder Sergey Brin suggests threatening AI for better results](https://www.theregister.com/2025/05/28/google_brin_suggests_threatening_ai/) 
* [[2505.21374] Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning?](https://arxiv.org/abs/2505.21374) 
* [[2505.14442] Creative Preference Optimization](https://arxiv.org/abs/2505.14442) 
* [https://techcrunch.com/2025/05/27/ai-may-already-be-shrinking-entry-level-jobs-in-tech-new-research-suggests/](https://techcrunch.com/2025/05/27/ai-may-already-be-shrinking-entry-level-jobs-in-tech-new-research-suggests/) 
* [[2505.18323] Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation](https://arxiv.org/abs/2505.18323) 
*  [[2505.18384] Dynamic Risk Assessments for Offensive Cybersecurity Agents](https://arxiv.org/abs/2505.18384) 
* [[2505.19056] An Embarrassingly Simple Defense Against LLM Abliteration Attacks](https://arxiv.org/abs/2505.19056) 
* [AI agents confused by some aspects of websites, ads • The Register](https://www.theregister.com/2025/05/27/ai_agents_confused_by_websites_ads/) 
* [[2505.19443] Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI](https://arxiv.org/abs/2505.19443) 
* [[2505.20259] Lifelong Safety Alignment for Language Models](https://arxiv.org/abs/2505.20259) 
* [[2505.18545] B-score: Detecting biases in large language models using response history](https://arxiv.org/abs/2505.18545) 
* [[2505.17225] Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models](https://arxiv.org/abs/2505.17225) 
* [The perverse incentives of Vibe Coding | by fred benenson | May, 2025 | UX Collective](https://uxdesign.cc/the-perverse-incentives-of-vibe-coding-23efbaf75aee) 
* [Researchers claim ChatGPT o3 bypassed shutdown in controlled test](https://www.bleepingcomputer.com/news/artificial-intelligence/researchers-claim-chatgpt-o3-bypassed-shutdown-in-controlled-test/) 
* [The people who think AI might become conscious - BBC News](https://www.bbc.co.uk/news/articles/c0k3700zljjo) 
* [Making AI Work: Leadership, Lab, and Crowd](https://open.substack.com/pub/oneusefulthing/p/making-ai-work-leadership-lab-and) 
* [Devs are finally getting serious about efficiency • The Register](https://www.theregister.com/2025/05/25/ai_models_are_evolving/) 
* [AI Is Replacing Women's Jobs Specifically](https://futurism.com/ai-labor-gender-equity) 
* [OpenAI consumer pivot shows AI isn't B2B • The Register](https://www.theregister.com/2025/05/25/ai_is_a_consumer_technology/) 
* [Highlights from the Claude 4 system prompt](https://simonwillison.net/2025/May/25/claude-4-system-prompt/#atom-everything) 
* [After Disastrous Experiments Into AI, Target Pledges to Pile on Even More AI](https://futurism.com/target-ai) 
* [Former Google CEO Eric Schmidt sounds alarm on AI data centers’ soaring power demand: ‘We need energy in all forms’ - The Economic Times](https://m.economictimes.com/magazines/panache/former-google-ceo-eric-schmidt-sounds-alarm-on-ai-data-centers-soaring-power-demand-we-need-energy-in-all-forms/amp_articleshow/121036712.cms) 
* [System Card: Claude Opus 4 & Claude Sonnet 4](https://simonwillison.net/2025/May/25/claude-4-system-card/) 
* [I let Google's Jules AI agent into my code repo and it did four hours of work in an instant | ZDNET](https://www.zdnet.com/article/i-let-googles-jules-ai-agent-into-my-code-repo-and-it-did-four-hours-of-work-in-an-instant/) 
* [When Are Concepts Erased From Diffusion Models?](https://arxiv.org/abs/2505.17013v1) 
* [AI ClickFix: Hijacking Computer-Use Agents Using ClickFix · Embrace The Red](https://embracethered.com/blog/posts/2025/ai-clickfix-ttp-claude/) 
* [Apple is trying to get ‘LLM Siri’ back on track | The Verge](https://www.theverge.com/news/669238/apple-siri-llm-ai-revamp)
* [Generalization bias in large language model summarization of scientific research](https://royalsocietypublishing.org/doi/epdf/10.1098/rsos.241776) 
* [I got fooled by AI-for-science hype—here's what it taught me](https://www.understandingai.org/p/i-got-fooled-by-ai-for-science-hypeheres) 
* [[2505.04588] ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://www.arxiv.org/abs/2505.04588) 
* [[2505.10468] AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges](https://arxiv.org/abs/2505.10468) 
* [Google’s Veo 3 AI video generator is a slop monger’s dream | The Verge](https://www.theverge.com/ai-artificial-intelligence/673719/google-veo-3-ai-video-audio-sound-effects) 
* [[2505.16170] When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction](https://arxiv.org/abs/2505.16170) 
* [Google's New Video-Generating AI May Be the End of Reality as We Know It](https://futurism.com/google-ai-video-generator-realistic) 
* [Terrifying Survey Claims ChatGPT Has Overtaken Wikipedia](https://futurism.com/survey-chatgpt-overtaken-wikipedia) 
* [AI Is Quickly Making IT Teams and Developers From Invisible to Indispensable - The New Stack](https://thenewstack.io/ai-is-quickly-making-it-teams-and-developers-from-invisible-to-indispensable/) 
* [Harnessing the Universal Geometry of Embeddings](https://arxiv.org/pdf/2505.12540) 
* [Advances in private training for production on-device language models](https://research.google/blog/advances-in-private-training-for-production-on-device-language-models/) 
* [AI can't replace developers until it understands the office • The Register](https://www.theregister.com/2025/05/21/opinion_column_ai_cant_replace_developers/) 
* [AI energy usage hard to measure, but this report tried • The Register](https://www.theregister.com/2025/05/21/ai_energy_consumption_loose_estimates/) 
* [CEO Who Bragged About Replacing Human Workers With AI Realizes He Made a Terrible Mistake](https://futurism.com/the-byte/klarna-ceo-bragged-replacing-workers-ai-losses) 
* [Google's AI vision clouded by business model hallucinations • The Register](https://www.theregister.com/2025/05/21/googles_ai_vision/) 
* [It's Still Ludicrously Easy to Jailbreak the Strongest AI Models, and the Companies Don't Care](https://futurism.com/ludicrously-easy-jailbreak-ai) 
* [Why Most GenAI Projects Fail: Only 1 in 3 Make It to Production - The New Stack](https://thenewstack.io/why-most-genai-projects-fail-only-1-in-3-make-it-to-production/) 
* [OpenAI's Top Scientist Wanted to "Build a Bunker Before We Release AGI"](https://futurism.com/the-byte/openai-scientists-agi-bunker) 
* [An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](https://arxiv.org/abs/2505.15406) 
* [[2505.15656] Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](https://arxiv.org/abs/2505.15656) 
* [[2505.12540] Harnessing the Universal Geometry of Embeddings](https://arxiv.org/abs/2505.12540) 
* [The Rise of AI Security Solutions Architects: How This Role Will Define the Next Decade of Cloud Security](https://open.substack.com/pub/luisepastor/p/the-rise-of-ai-security-solutions) 
* [Most AI chatbots easily tricked into giving dangerous responses, study finds | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/may/21/most-ai-chatbots-easily-tricked-into-giving-dangerous-responses-study-finds) 
* [[2505.11855] When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research](https://arxiv.org/abs/2505.11855) 
* [[2504.16078] LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities](https://arxiv.org/abs/2504.16078) 
* [[2505.12805] FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA](https://arxiv.org/abs/2505.12805) 
* [[2505.06120] LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org/abs/2505.06120) 
* [My AI therapist got me through dark times - BBC News](https://www.bbc.co.uk/news/articles/ced2ywg7246o) 
* [How OpenAI Says Its New Safety Hub is 'Making AI Models More Secure'](https://www.eweek.com/news/opeai-safety-hub-making-models-secure/) 
* [Coding Assistants Threaten the Software Supply Chain](https://martinfowler.com/articles/exploring-gen-ai/software-supply-chain-attack-surface.html) 
* [How to Prevent AI Agents From Becoming the Bad Guys](https://www.darkreading.com/vulnerabilities-threats/prevent-ai-agents-becoming-bad-guys) 
* [Incidents From Generative AI Cloud Services Hit Different - The New Stack](https://thenewstack.io/incidents-from-generative-ai-cloud-services-hit-different/) 
* [[2505.10468] AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](https://arxiv.org/abs/2505.10468) 
* [Remarks on AI from NZ - by Neal Stephenson - Graphomane](https://nealstephenson.substack.com/p/remarks-on-ai-from-nz) 
* [AI Chatbots Are Becoming Even Worse At Summarizing Data](https://futurism.com/ai-chatbots-summarizing-research) 
* [GPT Adoption Dilemma and the Impact of Disclosure Policies](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5201666) 
* [Does LLM Write Performant Code? Survey Says No - The New Stack](https://thenewstack.io/does-llm-write-performant-code-survey-says-no/) 
* [Star Wars' Showcase of AI Special Effects Was a Complete Disaster](https://futurism.com/star-wars-showcase-ai-special-effects-disaster) 
* [AI-Driven Software: Why a Strong CI/CD Foundation Is Essential - The New Stack](https://thenewstack.io/ai-driven-software-why-a-strong-ci-cd-foundation-is-essential/) 
* [Microsoft wants its AI Copilot app to lure Gen Z from rivals by behaving like a therapist | Fortune](https://fortune.com/2025/05/16/microsoft-ai-copilot-mustafa-suleyman-gen-z-therapist/) 
* [Report: Spring 2025 AI Model Usage Trends - Poe](https://poe.com/blog/spring-2025-ai-model-usage-trends) 
* [AI therapists: the wiretaps that care](https://boingboing.net/2025/05/15/ai-therapists-the-wiretaps-that-care.html) 
* [Sci-fi author Neal Stephenson wants AIs fighting AIs • The Register](https://www.theregister.com/2025/05/16/neal_stephenson_ai_evolution/) 
* [78% of CISOs see AI attacks already • The Register](https://www.theregister.com/2025/05/16/cisos-report-ai-attacks/) 
* [Building Trust in AI-Driven QA: Ensuring Transparency and Explainability With GenAI - The New Stack](https://thenewstack.io/building-trust-in-ai-driven-qa-ensuring-transparency-and-explainability-with-genai/) 
* [OpenAI CEO Sam Altman says Gen Z and millennials are using ChatGPT like a 'life advisor'—but college students might be one step ahead | Fortune](https://fortune.com/2025/05/13/openai-ceo-sam-altman-says-gen-z-millennials-use-chatgpt-like-life-adviser/) 
* [(PDF) Migrating Code At Scale With LLMs At Google](https://arxiv.org/pdf/2504.09691) (one of the random articles that are tangentially related worth reading though honest)
* [Agentic AI: Powerful but Fragile — What You Need To Know - The New Stack](https://thenewstack.io/agentic-ai-powerful-but-fragile-what-you-need-to-know/) 
* [[2505.06356] Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA](https://arxiv.org/abs/2505.06356) 
* [American Schools Were Deeply Unprepared for ChatGPT, Public Records Show](https://www.404media.co/american-schools-were-deeply-unprepared-for-chatgpt-public-records-show/) 
* [AI can spontaneously develop human-like communication, study finds | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/may/14/ai-can-spontaneously-develop-human-like-communication-study-finds) 
* [Labour’s open door to big tech leaves critics crying foul | Technology | The Guardian](https://www.theguardian.com/technology/2025/may/14/labours-open-door-to-big-tech-leaves-critics-crying-foul) 
* [Scaling enterprise AI in healthcare: the role of governance in risk mitigation frameworks | npj Digital Medicine](https://www.nature.com/articles/s41746-025-01700-4) 
* [Infosec pros still aren't nailing the basics of AI security • The Register](https://www.theregister.com/2025/05/14/cyberuk_ai_deployment_risks/) 
* [Will Policy-as-Code Still Matter if AI Generates Most Code?](https://devops.com/will-policy-as-code-still-matter-if-ai-generates-most-code) 
* [Is AI Use in the Workplace Out of Control? - SecurityWeek](https://www.securityweek.com/is-ai-use-in-the-workplace-out-of-control/) 
* [Shadow AI Isn’t a Threat: It’s a Wake-up Call - The New Stack](https://thenewstack.io/shadow-ai-isnt-a-threat-its-a-wake-up-call/) 
* [https://thenewstack.io/running-ai-workloads-responsibly-in-the-cloud/](https://thenewstack.io/running-ai-workloads-responsibly-in-the-cloud/) 
* [Future of LLMs is open source, Salesforce's Benioff says • The Register](https://www.theregister.com/2025/05/14/future_of_llms_is_open/) 
* [Open-Source LLM-Driven Federated Transformer for Predictive IoV Management](https://arxiv.org/abs/2505.00651v2) 
* [Securing RAG: A Risk Assessment and Mitigation Framework](https://arxiv.org/abs/2505.08728v1) 
* [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org/abs/2504.20799v2) 
* [‘AI models are capable of novel research’: OpenAI’s chief scientist on what to expect](https://www.nature.com/articles/d41586-025-01485-2) 
* [Artificial intelligence and free will: generative agents utilizing large language models have functional free will | AI and Ethics](https://link.springer.com/article/10.1007/s43681-025-00740-6)
* [ChatGPT may be polite, but it’s not cooperating with you](https://www.theguardian.com/technology/ng-interactive/2025/may/13/chatgpt-ai-big-tech-cooperation) 
* [Building, launching, and scaling ChatGPT Images](https://simonwillison.net/2025/May/13/launching-chatgpt-images/) 
* [Executives Are Pouring Money Into AI. So Why Are They Saying It's Not Paying Off?](https://futurism.com/ceos-return-ai-investments)
* [Deepfake Defense in the Age of AI](https://thehackernews.com/2025/05/deepfake-defense-in-age-of-ai.html) 
* [Coding Assistants Threaten the Software Supply Chain](https://martinfowler.com/articles/exploring-gen-ai/software-supply-chain-attack-surface.html) 
* [New attack can steal cryptocurrency by planting false memories in AI chatbots - Ars Technica](https://arstechnica.com/security/2025/05/ai-agents-that-autonomously-trade-cryptocurrency-arent-ready-for-prime-time/)  
* [Vision Language Models (Better, faster, stronger)](https://huggingface.co/blog/vlms-2025) 
* [Is AI the future of America's foreign policy? Some experts think so](https://www.npr.org/2025/05/12/nx-s1-5375140/ai-foreign-policy-diplomacy-war-ceasefire-ukraine)
* [[2505.06324] Document Attribution: Examining Citation Relationships using Large Language Models](https://arxiv.org/abs/2505.06324) 
* [To Vibe or Not to Vibe? When and Where To Use Vibe Coding - The New Stack](https://thenewstack.io/to-vibe-or-not-to-vibe-when-and-where-to-use-vibe-coding/) 
* [Why developers and their bosses disagree over generative AI - LeadDev](https://leaddev.com/technical-direction/why-developers-and-their-bosses-disagree-over-generative-ai) 
* [Is AI the future of America's foreign policy? Some experts think so](https://www.npr.org/2025/05/12/nx-s1-5375140/ai-foreign-policy-diplomacy-war-ceasefire-ukraine) 
* [AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking](https://www.mdpi.com/2075-4698/15/1/6) 
* [For Silicon Valley, AI isn’t just about replacing some jobs. It’s about replacing all of them | Ed Newton-Rex | The Guardian](https://www.theguardian.com/commentisfree/2025/may/12/for-silicon-valley-ai-isnt-just-about-replacing-some-jobs-its-about-replacing-all-of-them) 
* [Cursor: Security](https://simonwillison.net/2025/May/11/cursor-security/) 
* [Yes, AI will eventually replace some workers. But that day is still a long way off | Gene Marks | The Guardian](https://www.theguardian.com/business/2025/may/11/artificial-intelligence-small-business) 
* [GitHub CEO on Why We'll Still Need Human Programmers - The New Stack](https://thenewstack.io/github-ceo-on-why-well-still-need-human-programmers/) 
* [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org/abs/2501.19040v2) 
* ​​[[2504.02767] How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?](https://arxiv.org/abs/2504.02767) 
* [Is Automated Hallucination Detection in LLMs Feasible? A Theoretical and Empirical Investigation - MarkTechPost](https://www.marktechpost.com/2025/05/06/is-automated-hallucination-detection-in-llms-feasible-a-theoretical-and-empirical-investigation/) 
* [Evidence of a social evaluation penalty for using AI](https://www.pnas.org/doi/suppl/10.1073/pnas.2426766122) 
* [Multimodal Mistral Safety Report](https://www.enkryptai.com/company/resources/research-reports/mistral-pixtral-rt) 
* [Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries](https://arxiv.org/abs/2406.07944v2) 
* [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org/abs/2501.19040v2) 
* [The Case for Open AI Tooling: Why Developers Need Sovereignty in the AI Era - The New Stack](https://thenewstack.io/the-case-for-open-ai-tooling-why-developers-need-sovereignty-in-the-ai-era/) 
* [Teachers Using AI to Grade Their Students' Work Sends a Clear Message: They Don't Matter, and Will Soon Be Obsolete](https://futurism.com/teachers-ai-grade-students) 
* [AI-Generated Code Needs Refactoring, Say 76% of Developers - The New Stack](https://thenewstack.io/ai-generated-code-needs-refactoring-say-76-of-developers/) 
* [AI Consumes Lots of Energy. Can It Ever Be Sustainable? - The New Stack](https://thenewstack.io/ai-consumes-lots-of-energy-can-it-ever-be-sustainable/) 
* [AI Won’t Save You From Your Data Modeling Problems - The New Stack](https://thenewstack.io/ai-wont-save-you-from-your-data-modeling-problems/) 
* [Google shares slump as Apple exec calls AI the new search • The Register](https://www.theregister.com/2025/05/07/google_apple_cue/) 
* [OpenAI’s response to the Department of Energy on AI infrastructure](https://openai.com/global-affairs/response-to-department-of-energy/) 
* [What is the Agent2Agent (A2A) Protocol?](https://www.builder.io/blog/a2a-protocol) 
* [Google tries to greenwash massive AI energy consumption with another vague nuclear deal](https://www.theregister.com/2025/05/07/google_signs_another_nuclear_deal/) 
* [Generative AI like ChatGPT is at risk of creating new gender gap at work](https://www.cnbc.com/2025/05/08/ai-risk-chatgpt-gender-gap-jobs-work.html) 
* [The AI jobs crisis is here, now - by Brian Merchant](https://www.bloodinthemachine.com/p/the-ai-jobs-crisis-is-here-now) 
* [AI agents: from co-pilot to autopilot](https://on.ft.com/4d5AXpx) 
* [Three Essential ROI Goals for Agentic AI Applications - The New Stack](https://thenewstack.io/three-essential-roi-goals-for-agentic-ai-applications/) 
* [What's the carbon footprint of using ChatGPT?](https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt) 
* [[2505.00232] Scaling On-Device GPU Inference for Large Generative Models](https://arxiv.org/abs/2505.00232) 
* [Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models](https://arxiv.org/abs/2505.02763v1) 
* [[2505.00174] Real-World Gaps in AI Governance Research](https://arxiv.org/abs/2505.00174) 
* [Underreporting of AI use: The role of social desirability bias](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5232910) 
* [Anthropic CEO Admits We Have No Idea How AI Works](https://futurism.com/anthropic-ceo-admits-ai-ignorance) 
* [Prompt Engineer, the Hottest AI Job of 2023, Is Already Obsolete - WSJ](https://www.wsj.com/articles/the-hottest-ai-job-of-2023-is-already-obsolete-1961b054?mod=cio-journal_lead_pos1) 
* [AI security notes, 5/2/2025](https://joshuasaxe181906.substack.com/p/ai-security-notes-522025) 
* [Visa Announces Plans to Give AI Agents Your Credit Card Information](https://futurism.com/visa-ai-agents-your-credit-card) 
* [Two publishers and three authors fail to understand what “vibe coding” means](https://simonwillison.net/2025/May/1/not-vibe-coding/) 
* [Open source AI models favor men for hiring, study finds • The Register](https://www.theregister.com/2025/05/02/open_source_ai_models_gender_bias/) 
* [Gen AI is great at phishing, pig butchering scams • The Register](https://www.theregister.com/2025/05/02/gen_ai_spam/) 
* [Meta blames Trump tariffs for ballooning AI costs • The Register](https://www.theregister.com/2025/05/02/meta_trump_tariffs_ai/) 
* [Google is quietly testing ads in AI chatbots - Ars Technica](https://arstechnica.com/ai/2025/05/google-is-quietly-testing-ads-in-ai-chatbots/) 
* [Signs Grow That AI Is Starting to Seriously Bite Into the Job Market](https://futurism.com/signs-ai-bite-job-market) 
* [Time saved by AI offset by new work created, study suggests - Ars Technica](https://arstechnica.com/ai/2025/05/time-saved-by-ai-offset-by-new-work-created-study-suggests/) 
* [Ex-NSA cyber boss: AI will soon be a great exploit dev • The Register](https://www.theregister.com/2025/04/30/exnsa_cyber_boss_ai_expoit_dev/) 
* [Claude AI Exploited to Operate 100+ Fake Political Personas in Global Influence Campaign](https://thehackernews.com/2025/05/claude-ai-exploited-to-operate-100-fake.html) 
* [Study accuses LM Arena of helping top AI labs game its benchmark | TechCrunch](https://techcrunch.com/2025/04/30/study-accuses-lm-arena-of-helping-top-ai-labs-game-its-benchmark/)
* [Understanding the recent criticism of the Chatbot Arena](https://simonwillison.net/2025/Apr/30/criticism-of-the-chatbot-arena/#atom-everything)  
    * [The Leaderboard Illusion](https://arxiv.org/pdf/2504.20879) 
* [[2504.21039] Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](https://arxiv.org/abs/2504.21039) 
* [https://www.engadget.com/ai/mark-zuckerberg-predicts-ai-will-write-most-of-metas-code-within-12-to-18-months-213851646.html](https://www.engadget.com/ai/mark-zuckerberg-predicts-ai-will-write-most-of-metas-code-within-12-to-18-months-213851646.html) 
* [[2504.17004] (Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org/abs/2504.17004) 
* [[2504.02767] How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?](https://arxiv.org/abs/2504.02767) 

* **April** Be careful what you wish for ! Apparently AI code assistants are putting pressure on Devs to deliver faster. Suspicions that the strange way tariffs were calculated by the US  was written by a chat bot! Couple of interesting articles related to AI and enterprises. Liberation day fall out affecting The AI race in various ways  including affecting the rush to build out DCs needed to support resource hungry AIs. Disconnect between the Tech industry and the general public on their views on AI. A few articles on security concerns with AI agents, one of which is a really comprehensive survey on advances and challenges in foundation agents (This will take at least a pot of tea to get through!) The Alan Turing Institute delivered a wake up call to UK law enforcement saying they were ill equipped to tackle AI-enabled crime. An interesting report on the predicted  progress for AGAI looking at the ultimate  outcomes over the next few years providing two potential outcomes . Open AI is going to join the cohort of corps releasing open weight models. This month it's Meta's turn to underwhelm dropping versions of Llama4 over a weekend to less than great initial opinions on the models! Microsoft's let others lead  and we will follow to reap the rewards approach to AI was also in the news. Stanford released its state of AI report, all 456 pages of it ( seems like something NotebookLLM could help digest!) . An interesting look at how Open AI has an adverse affect on the balance books of companies it relies  on to grow and provide compute to produce whatever viral image trend it is this month. Another metric to take into consideration when choosing your Model is the model's preferences. Federated Learning being touted as a greener way to train ML models . Live coding interviews becoming useless as many candidates are using AI assistants. Anthropic predicts Fully AI employees(?) will be a thing soon. I'm wondering what you'll compensate them with? Continuing concerns about AI adversely affecting our critical thinking. Supply chain concerns has led to an open letter from J P Morgan. Concerns that in the rush to get new features out there that AI  safety is not being seen as a priority!  
* [Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach](https://arxiv.org/abs/2504.19951v1) 
* [Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org/abs/2504.19956v1) 
* [DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images](https://arxiv.org/abs/2504.19876v1) 
* [Professors Staffed a Fake Company Entirely With AI Agents, and You'll Never Guess What Happened](https://futurism.com/professors-company-ai-agents)
    * [[2412.14161] TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org/abs/2412.14161)  
* [DeepSeek R2 could crush AI economics with 97% lower costs than GPT-4 | The Neuron](https://www.theneuron.ai/explainer-articles/deepseek-r2-could-crush-ai-economics-with-97-lower-costs-than-gpt-4) 
* [Generative AI is not replacing jobs or hurting wages at all • The Register](https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/) 
* [Google DeepMind Shares Approach to AGI Safety and Security - InfoQ](https://www.infoq.com/news/2025/04/google-deepmind-agi)
* [FBI: This is how China uses AI in attack chains • The Register](https://www.theregister.com/2025/04/29/fbi_china_ai/) 
* [AI-generated code could be a disaster for the software supply chain. Here’s why. - Ars Technica](https://arstechnica.com/security/2025/04/ai-generated-code-could-be-a-disaster-for-the-software-supply-chain-heres-why/) 
* [A cheat sheet for why using ChatGPT is not bad for the environment](https://andymasley.substack.com/p/a-cheat-sheet-for-conversations-about) 
* [Duolingo ditches more contractors in 'AI-first' refocus • The Register](https://www.theregister.com/2025/04/29/duolingo_ceo_ai_first_shift/) 
* [Reality Check](https://www.wheresyoured.at/reality-check/) 
* [Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation](https://arxiv.org/abs/2503.19092v1) 
* [6 reasons Google slacking on AI safety reports is a big problem](https://www.androidpolice.com/google-slacking-ai-safety-reports-big-problem/) 
* [Google says the UK needs to do more to adopt AI, then it can reap the benefits | TechRadar](https://www.techradar.com/pro/google-says-the-uk-needs-to-do-more-to-adopt-ai-then-it-can-reap-the-benefits) 
* [Experts Concerned That AI Is Making Us Stupider](https://futurism.com/experts-ai-stupider) 
* [An Open Letter to Third-Party Suppliers](https://www.jpmorgan.com/technology/technology-blog/open-letter-to-our-suppliers) 
* [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org/abs/2409.11242v4) 
* [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org/abs/2504.17674v1) 
* [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org/abs/2504.17544v1) 
* [Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks](https://arxiv.org/abs/2504.13199v2) 
* [When AI Tools Backfire: The Hidden Cost of Poor Planning](https://stackstudio.io/blog/when-ai-tools-backfire-the-hidden-cost-of-poor-planning) 
* [AI Browser Will Track Every Single Thing You Do, CEO Reveals](https://futurism.com/ai-browser-perplexity-tracking) 
* [New study shows why simulated reasoning AI models don’t yet live up to their billing - Ars Technica](https://arstechnica.com/ai/2025/04/new-study-shows-why-simulated-reasoning-ai-models-dont-yet-live-up-to-their-billing/) 
* [The hidden technical debt in LLM apps](https://portkey.ai/blog/the-hidden-technical-debt-in-llm-apps) 
* [Trust will make or break AI agents](https://www.readysetcloud.io/blog/allen.helton/trust-will-make-or-break-ai-agents/) 
* [In the age of AI, we must protect human creativity as a natural resource - Ars Technica](https://arstechnica.com/ai/2025/04/in-the-age-of-ai-we-must-protect-human-creativity-as-a-natural-resource/) 
* [Vibe Coding Is Rapidly Reshaping the Software Developer Profession - The New Stack](https://thenewstack.io/vibe-coding-is-here-how-ai-is-reshaping-the-software-developer-profession/) 
* [Microsoft says everyone will be a boss in the future – of AI employees](https://www.theguardian.com/technology/2025/apr/25/microsoft-says-everyone-will-be-a-boss-in-the-future-of-ai-employees) 
* [The Global Index on Responsible AI](https://www.global-index.ai) 
* [The Urgent Security Paradox of AI in Cloud Native Development - The New Stack](https://thenewstack.io/the-urgent-security-paradox-of-ai-in-cloud-native-development/) 
* [How to think about agent frameworks](https://blog.langchain.dev/how-to-think-about-agent-frameworks/) 
* [AI-Powered Polymorphic Phishing Is Changing the Threat Landscape - SecurityWeek](https://www.securityweek.com/ai-powered-polymorphic-phishing-is-changing-the-threat-landscape/) 
* [New whitepaper outlines the taxonomy of failure modes in AI agents | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2025/04/24/new-whitepaper-outlines-the-taxonomy-of-failure-modes-in-ai-agents/) 
* [[2504.15585] A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment](https://arxiv.org/abs/2504.15585) 
* [AI Agents Could Soon Become Full-Time Virtual Employees](https://www.eweek.com/news/ai-agents-full-time-employees-anthropic/) 
* [Ex-NSA boss: AI devs' lesson to learn from early infosec](https://www.theregister.com/2025/04/23/exnsa_boss_ai/) 
* [Cloud Service: What Pope Francis Thought About AI - The New Stack](https://thenewstack.io/cloud-service-what-the-pope-thinks-about-ai/) 
* [The Future Belongs to AI-Augmented 10x Developers, Not Bigger Dev Teams - The New Stack](https://thenewstack.io/the-future-belongs-to-ai-augmented-10x-developers-not-bigger-dev-teams/) 
* [Will AI replace software engineers? It depends on who you ask](https://bit.ly/zdnet_swes) 
* [The AI Risk Repository](https://airisk.mit.edu/) 
* [With ‘AI slop’ distorting our reality, the world is sleepwalking into disaster | Nesrine Malik | The Guardian](https://www.theguardian.com/commentisfree/2025/apr/21/ai-slop-artificial-intelligence-social-media) 
* [Investor Says AI Is Already "Fully Replacing People"](https://futurism.com/investor-ai-fully-replacing-people) 
* [AI as Normal Technology | Knight First Amendment Institute](https://knightcolumbia.org/content/ai-as-normal-technology) 
* [On Jagged AGI: o3, Gemini 2.5, and everything after](https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything) 
* [Maybe Meta’s Llama claims to be open source because of the EU AI act](https://simonwillison.net/2025/Apr/19/llama-eu-ai-act/#atom-everything) 
* [The CIRIS Framework](http://www.ethicsengine.org/ciris) 
* [[2504.10277] RealHarm: A Collection of Real-World Language Model Application Failures](https://arxiv.org/abs/2504.10277) 
* [Tech hiring: is this an inflection point?](https://newsletter.pragmaticengineer.com/p/tech-hiring-inflection-point) 
* [Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling](https://arxiv.org/abs/2504.13169v1) 
* [Regrets: Actors who sold AI avatars stuck in Black Mirror-esque dystopia - Ars Technica](https://arstechnica.com/ai/2025/04/regrets-actors-who-sold-ai-avatars-stuck-in-black-mirror-esque-dystopia/) 
* [Vibe Coding is for PMs](https://redmonk.com/rstephens/2025/04/18/vibe-coding-is-for-pms/) 
* [‘Don’t ask what AI can do for us, ask what it is doing to us’: are ChatGPT and co harming human intelligence?](https://www.theguardian.com/technology/2025/apr/19/dont-ask-what-ai-can-do-for-us-ask-what-it-is-doing-to-us-are-chatgpt-and-co-harming-human-intelligence) 
* [[2504.11952] Robust and Fine-Grained Detection of AI Generated Texts](https://arxiv.org/abs/2504.11952) 
* [[2412.09871] Byte Latent Transformer: Patches Scale Better Than Tokens](https://arxiv.org/abs/2412.09871) 
* [AI Companions Are ‘More Addictive Than Social Media,’ Experts Warn: How to Protect Yourself | eWEEK](https://www.eweek.com/news/ai-companions-addiction-lawsuit-legislation/) 
* [Microsoft's Huge Plans for Mass AI Data Centers Now Rapidly Falling Apart](https://futurism.com/microsoft-ai-data-centers-ohio) 
* [AI at the Edge: Federated Learning for Greater Performance - The New Stack](https://thenewstack.io/ai-at-the-edge-federated-learning-for-greater-performance/) 
* [Apple Reveals How It Plans to Train AI – Without Sacrificing Users' Privacy | eWEEK](https://www.eweek.com/apple/apple-intelligence-ai-training-privacy/) 
* [Vibing Dangerously: The Hidden Risks of AI-Generated Code - The New Stack](https://thenewstack.io/vibing-dangerously-the-hidden-risks-of-ai-generated-code/) 
* [Google DeepMind Is Hiring a 'Post-AGI' Research Scientist](https://www.404media.co/google-deepmind-is-hiring-a-post-agi-research-scientist/) 
* [MLOps for Green AI: Building Sustainable Machine Learning in the Cloud](https://devops.com/mlops-for-green-ai-building-sustainable-machine-learning-in-the-cloud) 
* [[2504.09689] EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org/abs/2504.09689) 
* [Measuring Models' Special Interests](https://zswitten.github.io/2025/04/14/model-special-interests.html) 
* [MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](https://arxiv.org/abs/2504.03767v2) 
* [How new data permeates LLM knowledge and how to dilute it](https://arxiv.org/abs/2504.09522) 
* [LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models](https://arxiv.org/abs/2504.10430) 
* [Apple’s complicated plan to improve its AI while protecting privacy | The Verge](https://www.theverge.com/news/648496/apple-improve-ai-models-differential-privacy) 
* [OpenAI Is A Systemic Risk To The Tech Industry](https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/) 
* [ChatGPT's Studio Ghibli-style images are no laughing matter • The Register](https://www.theregister.com/2025/04/14/miyazaki_ai_and_intellectual_property/) 
* [Cybersecurity in the AI Era: Evolve Faster Than the Threats or Get Left Behind](https://thehackernews.com/2025/04/cybersecurity-in-ai-era-evolve-faster.html?m=1) 
* [Poll Finds Americans Are Largely Disgusted by AI-Generated News](https://futurism.com/americans-ai-news-poynter) 
* [Bigger isn't always better: Examining the business case for multi-million token LLMs | VentureBeat](https://venturebeat.com/ai/bigger-isnt-always-better-examining-the-business-case-for-multi-million-token-llms/) 
* [[2504.07830] MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations](https://arxiv.org/abs/2504.07830) 
* [On the Biology of a Large Language Model](https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-multilingual) 
* [Hyperscale sustainability is looking like a Hail Mary • The Register](https://www.theregister.com/2025/04/12/ai_hyperscalers_sustainability/) 
* [Former Google CEO Tells Congress That 99 Percent of All Electricity Will Be Used to Power Superintelligent AI](https://futurism.com/google-ceo-congress-electricity-ai-superintelligence) 
* [[2406.10279] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs](https://arxiv.org/abs/2406.10279) 
* [Anthropic Education Report: How University Students Use Claude](https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude) 
* [AI could lead to patient harm, researchers suggest](https://nation.cymru/news/ai-could-lead-to-patient-harm-researchers-suggest/) 
* [AI code suggestions sabotage software supply chain • The Register](https://www.theregister.com/2025/04/12/ai_code_suggestions_sabotage_supply_chain/) 
* [Global datacenter electricity use to double by 2030, say policy wonks. Yup, it's AI](https://www.theregister.com/2025/04/12/ai_double_datacenter_energy/) 
* [CaMeL offers a promising new direction for mitigating prompt injection attacks](https://simonwillison.net/2025/Apr/11/camel/#atom-everything) 
* [Vibe Coding: Revolution or Reckless Abandon?](https://addyo.substack.com/p/vibe-coding-revolution-or-reckless) 
* [Debug-gym: an environment for AI coding tools to learn how to debug code like programmers](https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers) 
* [From POC to Production: Why GenAI Projects Often Stall - The New Stack](https://thenewstack.io/from-poc-to-production-why-genai-projects-often-stall/) 
* [The Dynamic Between Domain Experts & Developers Has Shifted | Drew Breunig](https://www.dbreunig.com/2025/04/10/the-domain-experts-are-drivers.html) 
* [AI models still struggle to debug software, Microsoft study shows | TechCrunch](https://techcrunch.com/2025/04/10/ai-models-still-struggle-to-debug-software-microsoft-study-shows) 
* [Meta’s AI research lab is ‘dying a slow death,’ some insiders say—but Yann LeCun pushes back: ‘It’s a new beginning’ | Fortune](https://fortune.com/2025/04/10/meta-ai-research-lab-fair-questions-departures-future-yann-lecun-new-beginning/) 
* [I have seen Google's AI version of The Wizard of Oz, and I'm still in shock](https://www.androidauthority.com/google-wizard-of-oz-sphere-3542846/) ( A balanced view point on Google & Co's  adaption of the wizard of Oz for the sphere)
* [[2504.07086] A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility](https://arxiv.org/abs/2504.07086) 
* [How is UK going to power its AI datacenters? • The Register](https://www.theregister.com/2025/04/10/uk_ai_energy_council_meets/) 
* [AI Now Outsmarts Humans in Spear Phishing, Analysis Shows - SecurityWeek](https://www.securityweek.com/ai-now-outsmarts-humans-in-spear-phishing-analysis-shows/) 
* [Sam Altman Says Miyazaki Just Needs to Get Over It](https://futurism.com/sam-altman-miyazaki-criticism) 
* [AI Energy Council meets to speed up delivery of sustainable AI | TechMarketView](https://www.techmarketview.com/ukhotviews/archive/2025/04/09/ai-energy-council-meets-to-speed-up-delivery-of-sustainable-ai) 
* [The 2025 AI Index Report | Stanford HAI](https://hai.stanford.edu/ai-index/2025-ai-index-report) 
    * [The State of AI 2025: 12 Eye-Opening Graphs - IEEE Spectrum](https://spectrum.ieee.org/ai-index-2025) 
* [Is there a ‘right’ way to use AI in art?](https://www.theverge.com/ai-artificial-intelligence/642599/is-there-a-right-way-to-use-ai-in-art) 
* [Google: It’s 'Misleading' for Websites to Blame AI Overviews for Lost Traffic | eWEEK](https://www.eweek.com/news/google-ai-overviews-smb-impact/) 
* [https://thenewstack.io/ai-data-dilemma-balancing-innovation-with-ironclad-governance/](https://thenewstack.io/ai-data-dilemma-balancing-innovation-with-ironclad-governance/) 
* [AI is the future, but most companies’ plans are short-term | CIO Dive](https://www.ciodive.com/spons/ai-is-the-future-but-most-companies-plans-are-short-term/744239/) 
* [AI Boom Risks 40% of Jobs, Deepens Inequality — UN Report](https://www.eweek.com/news/un-ai-report-inequality-jobs/) 
* [Why Cloud Native Infrastructure Is Non-Negotiable for GenAI - The New Stack](https://thenewstack.io/why-cloud-native-infrastructure-is-non-negotiable-for-genai/) 
* [AI Alignment: A Comprehensive Survey](https://arxiv.org/abs/2310.19852v6) 
* [Microsoft's AI plan: Let OpenAI take the risks • The Register](https://www.theregister.com/2025/04/07/microsofts_ai_strategy/) 
* [Meta got caught gaming AI benchmarks](https://www.theverge.com/meta/645012/meta-llama-4-maverick-benchmarks-gaming) 
* [Meta’s surprise Llama 4 drop exposes the gap between AI ambition and reality - Ars Technica](https://arstechnica.com/ai/2025/04/metas-surprise-llama-4-drop-exposes-the-gap-between-ai-ambition-and-reality/) 
* [Meta AI Releases Llama 4: Early Impressions and Community Feedback - InfoQ](https://www.infoq.com/news/2025/04/meta-ai-llama-4) 
* [OpenAI tests watermarking for ChatGPT-4o Image Generation model](https://www.bleepingcomputer.com/news/artificial-intelligence/openai-tests-watermarking-for-chatgpt-4o-image-generation-model/) 
* [Why OpenAI caved to open-source on the same day as its $300 billion flex (Hint: It’s not just about DeepSeek) | Fortune](https://fortune.com/2025/04/01/openai-300m-ghibli-meme-open-source-ai-model-deepseek/) 
* [AI 2027](https://ai-2027.com) 
* [Reasoning models don't always say what they think \ Anthropic](https://www.anthropic.com/research/reasoning-models-dont-say-think) 
* [Man Alarmed as His Cognitive Skills Decay After Outsourcing Them to AI](https://futurism.com/cognitive-decay-ai) 
* [Trump Accused of Using ChatGPT to Create Tariff Plan After AI Leads Users to Same Formula: 'So AI is Running the Country'](https://www.latintimes.com/trump-accused-using-chatgpt-create-tariff-plan-after-ai-leads-users-same-formula-so-ai-579899) 
* [The AI industry doesn’t know if Trump just killed its GPU supply | The Verge](https://www.theverge.com/tech/643753/gpu-tariffs-nvidia-tsmc-chips-openai) 
* [Alan Turing Institute: UK can't handle a fight against AI-enabled crims](https://www.theregister.com/2025/04/04/nca_ati_ai_report/) 
    * [AI and Serious Online Crime | Centre for Emerging Technology and Security](https://cetas.turing.ac.uk/publications/ai-and-serious-online-crime) 
* [[2504.01990] Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990) 
* [Trump tariffs could stymie Big Tech's US data center spending spree | Reuters](https://www.reuters.com/technology/trump-tariffs-could-stymie-big-techs-us-data-center-spending-spree-2025-04-03/) 
* [The Augmented Architect: Real-Time Enterprise Architecture In The Age Of AI](https://www.forrester.com/blogs/the-augmented-architect-real-time-enterprise-architecture-in-the-age-of-ai/)
* [AI Adoption in the Enterprise: Breaking Through the Security and Compliance Gridlock](https://thehackernews.com/2025/04/ai-adoption-in-enterprise-breaking.html) 
* [Most Americans think AI won’t improve their lives, survey says - Ars Technica](https://arstechnica.com/tech-policy/2025/04/survey-americans-fear-ai-will-hurt-them-experts-expect-the-opposite/)
    * [How the U.S. Public and AI Experts View Artificial Intelligence](https://www.pewresearch.org/internet/2025/04/03/how-the-us-public-and-ai-experts-view-artificial-intelligence) 
* [Critics suspect Trump’s weird tariff math came from chatbots - Ars Technica](https://arstechnica.com/tech-policy/2025/04/critics-suspect-trumps-weird-tariff-math-came-from-chatbots/) 
* [Trump Tariffs Show Signs of Being Written by AI](https://futurism.com/trump-tariffs-signs-ai)
* [AI’s Impact on Human Behavior by 2035: Experts Paint a Mostly Bleak Picture](https://www.eweek.com/news/ai-impact-human-behavior-2035-elon-university/) 
* [An AI Model Has Officially Passed the Turing Test](https://futurism.com/ai-model-turing-test) 
* [Developers feel the heat as AI coding tools shorten deadlines | CIO Dive](https://www.ciodive.com/news/ai-coding-tools-hackerrank/744010/) 
* [Taking a responsible path to AGI - Google DeepMind](https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/) 
* [Vulnerabilities Expose Jan AI Systems to Remote Manipulation - SecurityWeek](https://www.securityweek.com/vulnerabilities-expose-jan-ai-systems-to-remote-manipulation/) 
* [What AI Agents Do in the Shadows - The New Stack](https://thenewstack.io/what-ai-agents-do-in-the-shadows/) 
* [Writing for humans? Perhaps in future we write for AI • The Register](https://www.theregister.com/2025/04/01/interview_with_david_wong/) 
* [Some Alexa+ features reportedly won't arrive for months | TechCrunch](https://techcrunch.com/2025/03/31/some-alexa-features-reportedly-wont-arrive-for-months/) 

* **March** started with a doozy about another infamous memo coming from Google ! Gizmodo's headline captures the sentiment. Murmuring about the disappointment with gpt-4.5. Some innovative  ways to evaluate the performance of agents were a thing this month including assessing how they did managing a vending machine tl;dr Humans still the winners here. I also liked the idea of the survival game, a natural selection evaluation framework for models . I am loving these more interesting & applicable ways to  evaluate model performance. Agents are the buzzy thing in the world of AI and concerns about threat vectors have been a theme this month. Disappointment in Apple's lack of intelligence from apple intelligence 12 months after making a big noise about it. Some interesting articles about AI and jobs , IBM & Anthropic disagreeing on the future for devs & AI and women in a conundrum as AI helps their careers as quickly as it's eliminating jobs. How do you test an AI when it's aware it's being tested for alignment? This is a conundrum that has some attention! The superintelligence strategy is fascinating to read and if you don't have time to read it  then you can  watch the video about it. Vibe coding was in the news. Simon Willison's post has a good explanation ( Don't do this for production code !) . The UKs ambitions to roll out AI is hitting the obvious  road blocks as you can't just say we need to embrace AI without investing to support that ambition with everything required from updating hardware, the software available to staff through to recruiting and training staff. The first step however is to acknowledge the scale of the ambition so that's a start. [MCP](https://modelcontextprotocol.io/introduction) seems to be gaining traction as the way to connect AI agents/ LLMs to external tools and systems. It was open sourced [by Anthropic](https://www.anthropic.com/news/model-context-protocol) in November last year 
*  [Life in Low Data Gravity | AI News & Insights](https://www.deeplearning.ai/the-batch/life-in-low-data-gravity/) 
* [[2503.12072] Information-Guided Identification of Training Data Imprint in (Proprietary) Large Language Models](https://arxiv.org/abs/2503.12072)** **
* [Training Large Language Models for Advanced Typosquatting Detection](https://arxiv.org/abs/2503.22406v1) 
* [OpenAI's Sora Has a Small Problem With Being Hugely Racist and Sexist](https://futurism.com/openai-sora-racist-sexist) 
* [AI's "Biggest Test" Is Turning Into a Catastrophe as CoreWeave Flounders](https://futurism.com/ai-test-coreweave) 
* [Ghost Jobs, Deepfakes, and Bots: Welcome to the AI Job Hunt](https://www.eweek.com/news/ai-job-applicants-hiring/) 
* [ML and LLM Adoption Challenged Most Often by Observability - The New Stack](https://thenewstack.io/ml-and-llm-adoption-challenged-most-often-by-observability/) 
* [LLM providers on the cusp of an 'extinction' phase as capex realities bite](https://www.theregister.com/2025/03/31/llm_providers_extinction/)  
* [Calling all fashion models … now AI is coming for you](https://www.theguardian.com/fashion/2025/mar/30/fashion-models-ai-job-losses) 
* [Horseless intelligence | Ned Batchelder](https://nedbatchelder.com/blog/202503/horseless_intelligence.html)
* [The State of AI: Global survey | McKinsey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai)
* [MCP is the new interface for security tools](https://mayakaczorowski.com/blogs/mcp) 
* [Bill Gates Predicts AI Will Replace Many Doctors, Teachers Within 10 Years](https://www.eweek.com/news/bill-gates-ai-predictions-jobs/) 
* [Why do LLMs make stuff up? New research peers under the hood. - Ars Technica](https://arstechnica.com/ai/2025/03/why-do-llms-make-stuff-up-new-research-peers-under-the-hood/) 
    * [Tracing the thoughts of a large language model \ Anthropic](https://www.anthropic.com/research/tracing-thoughts-language-model) 
* [[2502.08586] Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](https://arxiv.org/abs/2502.08586)
* [Why Centralized AI Fails in Enterprise: The Case for a Federated Architecture - The New Stack](https://thenewstack.io/why-centralized-ai-fails-in-enterprise-the-case-for-a-federated-architecture/) 
* [Exploring Generative AI](https://martinfowler.com/articles/exploring-gen-ai.html#memo-13) 
* [Measuring AI Ability to Complete Long Tasks - METR](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/) 
* [Study: AI Turns Evil After Training on Insecure Code - The New Stack](https://thenewstack.io/study-ai-turns-evil-after-training-on-insecure-code/) 
    * [Emergent Misalignment](https://www.emergent-misalignment.com/) 
* [A new, challenging AGI test stumps most AI models | TechCrunch](https://techcrunch.com/2025/03/24/a-new-challenging-agi-test-stumps-most-ai-models/) 
* [Is the AI Bubble About To Burst?](https://www.eweek.com/news/ai-bubble-risk/) 
* [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2025.pdf) ( 2025 version)
* [Feeling Addicted to ChatGPT? You’re Not Alone, According to MIT & OpenAI](https://www.eweek.com/news/chatgpt-addiction-openai-mit-study/) 
* [Government AI roll-outs threatened by outdated IT systems | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/mar/26/government-ai-roll-outs-threatened-by-outdated-it-systems) 
* [MPs warn legacy IT could derail UK government's AI hopes • The Register](https://www.theregister.com/2025/03/26/legacy_systems_uk_ai/) 
* [How vibe coding will affect Engineering Managers ](https://newsletter.manager.dev/p/effect-of-ai-on-engineering-managers) 
* [Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation](https://arxiv.org/abs/2503.19622) 
* [Early methods for studying affective use and emotional well-being on ChatGPT | OpenAI](https://openai.com/index/affective-use-study) 
* [Defeating Prompt Injections by Design](https://arxiv.org/abs/2503.18813) 
* [[2503.17489] Judge Anything: MLLM as a Judge Across Any Modality](https://arxiv.org/abs/2503.17489) 
* [[2503.14499] Measuring AI Ability to Complete Long Tasks](https://arxiv.org/abs/2503.14499) 
* [Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment](https://arxiv.org/abs/2411.18688v3) 
* [Blending AI and DevSecOps: Enhancing Security in the Development Pipeline](https://devops.com/blending-ai-and-devsecops-enhancing-security-in-the-development-pipeline) 
* [Joint studies from OpenAI and MIT found links between loneliness and ChatGPT use](https://www.engadget.com/ai/joint-studies-from-openai-and-mit-found-links-between-loneliness-and-chatgpt-use-193537421.html) 
* [Not all AI-assisted programming is vibe coding (but vibe coding rocks)](https://simonwillison.net/2025/Mar/19/vibe-coding/) 
* [Scientist Says That ChatGPT Has a "Staggering" Gender Problem](https://futurism.com/scientist-chatgpt-gender-gap) 
* [[2503.16416] Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416) 
* [[2503.15299] Inside-Out: Hidden Factual Knowledge in LLMs](https://arxiv.org/abs/2503.15299) 
* [[2503.16031] Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content](https://arxiv.org/abs/2503.16031) 
* [[2503.13657] Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/abs/2503.13657) 
* [Commentary: Why China is suddenly flooding the market with powerful AI models - CNA](https://www.channelnewsasia.com/commentary/china-open-source-ai-model-deepseek-alibaba-compete-us-tech-5010401) 
* [VLMs as GeoGuessr Masters—Exceptional Performance, Hidden Biases, and Privacy Risks Mind the Photos You Post: AI Knows Where You Are!](https://arxiv.org/html/2502.11163v1) 
* [Superintelligence Strategy](https://www.nationalsecurity.ai/)
    * [Ex-Google CEO Says AI War Is COMING! (Superintelligence Strategy)](https://youtu.be/eMQulv3nVZk?si=HiDwhIfGleKwYa_S) 
* [North Korea launches new unit with a focus on AI hacking, per report | TechCrunch](https://techcrunch.com/2025/03/20/north-korea-launches-new-unit-with-a-focus-on-ai-hacking-per-report/) 
* [Vibe Coding is a Dangerous Fantasy | N’s Blog](https://nmn.gl/blog/vibe-coding-fantasy) 
* [OpenAI Scientists' Efforts to Make an AI Lie and Cheat Less Backfired Spectacularly](https://futurism.com/openai-stop-ai-lie-cheat-backfired) 
    * [[2503.11926] Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation](https://arxiv.org/abs/2503.11926) 
* [[2503.05710] AGI, Governments, and Free Societies](https://arxiv.org/abs/2503.05710) 
* [[2209.00626] The Alignment Problem from a Deep Learning Perspective](https://arxiv.org/abs/2209.00626) 
* [Claude Sonnet 3.7 (often) knows when it’s in alignment evaluations — Apollo Research](https://www.apolloresearch.ai/blog/claude-sonnet-37-often-knows-when-its-in-alignment-evaluations) 
* [Auditing language models for hidden objectives \ Anthropic](https://www.anthropic.com/research/auditing-hidden-objectives) 
* [RFK Says AI Nurses Are 'As Good as Any Doctor'](https://www.eweek.com/news/ai-healthcare-nurses-doctors/) 
* [[2501.11433] One Does Not Simply Meme Alone: Evaluating Co-Creativity Between LLMs and Humans in the Generation of Humor](https://arxiv.org/abs/2501.11433) 
* [Now you don’t even need code to be a programmer. But you do still need expertise | John Naughton | The Guardian](https://www.theguardian.com/technology/2025/mar/16/ai-software-coding-programmer-expertise-jobs-threat) 
* [AI project failure rates are on the rise: report | CIO Dive](https://www.ciodive.com/news/AI-project-fail-data-SPGlobal/742590/) 
* [No one knows what the hell an AI agent is | TechCrunch](https://techcrunch.com/2025/03/14/no-one-knows-what-the-hell-an-ai-agent-is/) 
* [AI Agents in Doubt: Reducing Uncertainty in Agentic Workflows - The New Stack](https://thenewstack.io/ai-agents-in-doubt-reducing-uncertainty-in-agentic-workflows/) 
* [Majority of AI Researchers Say Tech Industry Is Pouring Billions Into a Dead End](https://futurism.com/ai-researchers-tech-industry-dead-end) 
* [OWASP Dishes Out Key Ingredients for a Secure Agentic AI Future | by Idan Habler | Intuit Engineering | Mar, 2025 | Medium](https://medium.com/intuit-engineering/owasp-dishes-out-key-ingredients-for-a-secure-agentic-ai-future-be862e167d6c) 
* [Trained on buggy code, LLMs often parrot same mistakes • The Register](https://www.theregister.com/2025/03/19/llms_buggy_code/)
    * [[2503.11082] LLMs are Bug Replicators: An Empirical Study on LLMs' Capability in Completing Bug-prone Code](https://arxiv.org/abs/2503.11082) 
* [[2503.12545] PEBench: A Fictitious Dataset to Benchmark Machine Unlearning for Multimodal Large Language Models](https://arxiv.org/abs/2503.12545) 
* [How To Create the Generative AI Policy You Needed Yesterday](https://thenewstack.io/how-to-create-the-generative-ai-policy-you-needed-yesterday/) 
* [Vibe Coding Is Here — But Are You Ready for Incident Vibing? - The New Stack](https://thenewstack.io/vibe-coding-is-here-but-are-you-ready-for-incident-vibing/) 
* [Billions of Dollars Down the Drain? 76% of AI Researchers Consider AGI 'Unrealistic Goal'](https://www.eweek.com/news/news-ai-investments-agi/) 
* [AI search is starting to kill Google’s ‘ten blue links’](https://www.theverge.com/ai-artificial-intelligence/631352/ai-search-adobe-analytics-google-perplexity-openai) 
* [Marvel Directors on AI in Films: 'Artists Need to Lead the Innovation'](https://www.eweek.com/news/marvel-directors-joe-anthony-russo-ai-films/) 
* [Post-apocalyptic education - by Ethan Mollick](https://www.oneusefulthing.org/p/post-apocalyptic-education) 
* [[2503.09669] Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.09669) 
* [Virginia Tech Study Reveals Machine Learning Models Struggle to Identify Critical Health Declines](https://bioengineer.org/virginia-tech-study-reveals-machine-learning-models-struggle-to-identify-critical-health-declines/) 
* [How AI Is Reshaping CISO Priorities - The New Stack](https://thenewstack.io/how-ai-is-reshaping-ciso-priorities/) 
* [AI is Creating New Paths for Women — And Closing Doors at the Same Time](https://www.eweek.com/news/news-ai-women-tech-jobs/) 
* [My Thoughts on the Future of "AI" Nicholas Carlini](https://nicholas.carlini.com/writing/2025/thoughts-on-future-ai.html) 
* [AI vs. Developer Jobs: Anthropic Predicts Replacement, IBM Pushes Back](https://www.eweek.com/news/ai-developers-jobs-anthropic-ibm/) 
* [Trust AI or Peers More for Advice? Here’s What Execs Prefer & Why](https://www.eweek.com/news/ai-trust-executives-sap-study/) 
* [Poisoning the Well and Other Generative AI Risks - The New Stack](https://thenewstack.io/poisoning-the-well-and-other-generative-ai-risks/) 
* [[2503.09837] On the Limitations of Vision-Language Models in Understanding Image Transforms](https://arxiv.org/abs/2503.09837) 
* [[2503.09905] Quantization for OpenAI's Whisper Models: A Comparative Analysis](https://arxiv.org/abs/2503.09905) 
* [[2503.10635] A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](https://arxiv.org/abs/2503.10635) 
* [DeepSeek-R1 Uncensored, QwQ-32B Puts Reasoning in Smaller Model, and more...](https://www.deeplearning.ai/the-batch/issue-292/) 
* [Daring Fireball: Something Is Rotten in the State of Cupertino](https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino) 
* [AI running out of juice despite Microsoft's hard squeezing • The Register](https://www.theregister.com/2025/03/14/ai_running_out_of_juice/) 
* [Entering AI Autumn: Why LLMs Are Nearing Their Limit - The New Stack](https://thenewstack.io/entering-ai-autumn-why-llms-are-nearing-their-limit/) 
* [Researchers astonished by tool’s apparent success at revealing AI’s “hidden objectives” - Ars Technica](https://arstechnica.com/ai/2025/03/researchers-astonished-by-tools-apparent-success-at-revealing-ais-hidden-motives/) 
* [How ProPublica Uses AI Responsibly in Its Investigations](https://www.propublica.org/article/using-ai-responsibly-for-reporting) 
* [‘A computer’s joke, on us’: writers respond to the short story written by AI | Books | The Guardian](https://www.theguardian.com/books/2025/mar/14/writers-respond-story-written-by-ai-sam-altman-chat-gpt-tracy-chevalier-kamila-shamsie-david-baddiel) 
* [The UK government embracing AI? I’m sorry, that’s nonsense and I can prove it | Chris Stokel-Walker | The Guardian](https://www.theguardian.com/commentisfree/2025/mar/14/uk-government-artifical-intelligence-chatgpt)
* [It turns out ChatGPT o1 and DeepSeek-R1 cheat at chess if they’re losing, which makes me wonder if I should trust AI with anything | TechRadar](https://www.techradar.com/computing/artificial-intelligence/it-turns-out-chatgpt-o1-and-deepseek-r1-cheat-at-chess-if-theyre-losing-which-makes-me-wonder-if-i-should-i-should-trust-ai-with-anything) 
* [Bank CEO says 4-day week isn't progressive, and AI will make it 'bloody logical' | Fortune Europe](https://fortune.com/europe/2025/03/13/atom-bank-ceo-running-4-day-work-week-cutting-working-hours-isnt-progressive-ai-make-bloody-logical/) 
* [[2503.05856] This Is Your Doge, If It Please You: Exploring Deception and Robustness in Mixture of LLMs](https://arxiv.org/abs/2503.05856) 
* [[2503.07389] TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.07389) 
* [[2503.07595] Detection Avoidance Techniques for Large Language Models](https://arxiv.org/abs/2503.07595) 
* [Pentesters: Is AI Coming for Your Role?](https://thehackernews.com/2025/03/pentesters-is-ai-coming-for-your-role.html) 
* [What Is LLM Observability and Monitoring? - The New Stack](https://thenewstack.io/what-is-llm-observability-and-monitoring/) 
* [Can You Trust AI To Be Your Data Analyst? - The New Stack](https://thenewstack.io/can-you-trust-ai-to-be-your-data-analyst/) 
* [[2503.03704] A Practical Memory Injection Attack against LLM Agents](https://arxiv.org/abs/2503.03704) 
* [[2502.09747] The Widespread Adoption of Large Language Model-Assisted Writing Across Society](https://arxiv.org/abs/2502.09747) 
* [What’s Missing With AI-Generated Code? Refactoring - The New Stack](https://thenewstack.io/whats-missing-with-ai-generated-code-refactoring/) 
* [The State of LLM Reasoning Models](https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling) ( Great article on scaling for inference)
* [Anthropic Warns White House: Act Now on AI Security or Face Serious Risks](https://www.eweek.com/news/anthropic-white-house-ai-security/) 
*  [[2503.02191] Understanding and Predicting Derailment in Toxic Conversations on GitHub](https://arxiv.org/abs/2503.02191) 
* [[2503.04369] Lost in Literalism: How Supervised Training Shapes Translationese in LLMs](https://arxiv.org/abs/2503.04369) 
* [Freelancers Are Getting Ruined by AI](https://futurism.com/freelancers-struggling-compete-ai) 
* [[2503.02879] Wikipedia in the Era of LLMs: Evolution and Risks](https://arxiv.org/abs/2503.02879) 
* [[2503.02846] Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs](https://arxiv.org/abs/2503.02846) 
* [GitHub - lmgame-org/GamingAgent: Computer gaming agents that run on your PC and laptops.](https://github.com/lmgame-org/GamingAgent) 
* [Why AI Agents Suck So Bad - The New Stack](https://thenewstack.io/why-ai-agents-suck-so-bad/) 
* [AGI still a long way off, academics in China have calculated • The Register](https://www.theregister.com/2025/03/05/boffins_from_china_calculate_agi/) 
    * [https://github.com/jingtaozhan/IntelligenceTest](https://github.com/jingtaozhan/IntelligenceTest) 
* [How New AI Agents Will Transform Credential Stuffing Attacks](https://thehackernews.com/2025/03/how-new-ai-agents-will-transform.html?m=1) 
* [Why AI Agents Suck So Bad - The New Stack](https://thenewstack.io/why-ai-agents-suck-so-bad/) 
* [AI-Powered Lawyering: AI Reasoning Models, Retrieval Augmented Generation, and the Future of Legal Practice](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5162111) 
* [Analysts Warn That If AI Agents Succeed, the "Internet Will Go Dark"](https://futurism.com/ai-agents-dark-internet) 
* [Power Cut](https://www.wheresyoured.at/power-cut/) 
* [AI is killing some companies, yet others are thriving - let's look at the data](https://www.elenaverna.com/p/ai-is-killing-some-companies-yet) 
* [[2502.15840] Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents](https://arxiv.org/abs/2502.15840) 
* [[2502.19187] BIG-Bench Extra Hard](https://arxiv.org/abs/2502.19187) 
* [If the best defence against AI is more AI, this could be tech’s Oppenheimer moment | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/mar/02/ai-oppenheimer-moment-karp-zapiska-technological-republic) 
* [[2502.16750] Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System](https://arxiv.org/abs/2502.16750) 
* [AI killing some companies, others doing fine](https://boingboing.net/2025/03/01/ai-killing-some-companies-others-doing-fine.html) 
* [Hallucinations in code are the least dangerous form of LLM mistakes](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/) 
* [[2409.04109] Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers](https://arxiv.org/abs/2409.04109) 
* [OpenAI May Have Really Screwed Up With GPT-4.5](https://futurism.com/openai-screwed-up-gpt-4-5) 
* [Will the future of software development run on vibes?](https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/) 
* [Sergey Brin says AGI is within reach if Googlers work 60-hour weeks - Ars Technica](https://arstechnica.com/google/2025/02/sergey-brin-says-agi-is-within-reach-if-googlers-work-60-hour-weeks/) 
* [Google’s Sergey Brin Says Engineers Should Work 60-Hour Weeks in Office to Build AI That Could Replace Them](https://gizmodo.com/googles-sergey-brin-says-engineers-should-work-60-hour-weeks-in-office-to-build-ai-that-could-replace-them-2000570025) 
* [[2502.09747] The Widespread Adoption of Large Language Model-Assisted Writing Across Society](https://arxiv.org/abs/2502.09747) 
* [Disrupting a global cybercrime network abusing generative AI - Microsoft On the Issues](https://blogs.microsoft.com/on-the-issues/2025/02/27/disrupting-cybercrime-abusing-gen-ai/) 
* [How AI Takeover Might Happen in 2 Years — LessWrong](https://www.lesswrong.com/posts/KFJ2LFogYqzfGB3uX/how-ai-takeover-might-happen-in-2-years) 
* [[2502.15737] A Performance Analysis of You Only Look Once Models for Deployment on Constrained Computational Edge Devices in Drone Applications](https://arxiv.org/abs/2502.15737)
* Feb had concerns about energy & water usage that the DCs would need . Muttering about the ROI from AI after fourth quarter earnings reports. Another theme was about AI making humans lazy when it came to critical thinking . Great paper on why AI  benchmarks should be taken with a huge spoonful of salt! The Register article summarises the paper in their usual snarky way.
* [[2502.01822] Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org/abs/2502.01822) 
* [AUTOHIJACKER: AUTOMATIC INDIRECT PROMPT INJECTION AGAINST BLACK-BOX LLM AGENTS](https://openreview.net/pdf?id=2VmB01D9Ef) 
* [[2502.13172] Unveiling Privacy Risks in LLM Agent Memory](https://arxiv.org/abs/2502.13172)
* [AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways](https://dl.acm.org/doi/full/10.1145/3716628) 
* [OAuth Works for AI Agents, but Scaling Is Another Question - The New Stack](https://thenewstack.io/oauth-works-for-ai-agents-but-scaling-is-another-question/) 
    * [AI agent identity: it's just OAuth](https://mayakaczorowski.com/blogs/ai-agent-authentication) 
* [No new engineer hires this year as AI coding tools boost productivity, says Salesforce](https://www.theregister.com/2025/02/27/salesforce_misses_revenue_guidance/) 
* [U.S. Workers Are More Worried Than Hopeful About Future AI Use in the Workplace | Pew Research Center](https://www.pewresearch.org/social-trends/2025/02/25/u-s-workers-are-more-worried-than-hopeful-about-future-ai-use-in-the-workplace/) 
* [Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks](https://arxiv.org/abs/2502.13175v2) 
* [How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities](https://arxiv.org/abs/2502.18387v1) 
* [UK universities warned to ‘stress-test’ assessments as 92% of students use AI](https://www.theguardian.com/education/2025/feb/26/uk-universities-warned-to-stress-test-assessments-as-92-of-students-use-ai) 
* [[2502.17424] Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](https://arxiv.org/abs/2502.17424) 
* [Investigating LLM Jailbreaking of Popular Generative AI Web Products](https://unit42.paloaltonetworks.com/jailbreaking-generative-ai-web-products/) 
* [How to exploit top LRMs that reveal their reasoning steps • The Register](https://www.theregister.com/2025/02/25/chain_of_thought_jailbreaking/)
    * [https://github.com/dukeceicenter/jailbreak-reasoning-openai-o1o3-deepseek-r1](https://github.com/dukeceicenter/jailbreak-reasoning-openai-o1o3-deepseek-r1)  
* [[2502.14975] Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries](https://arxiv.org/abs/2502.14975) 
* [Claude's extended thinking \ Anthropic](https://www.anthropic.com/research/visible-extended-thinking) ( now this is a benchmark I find worth using !) 
* [[2502.06329] Expect the Unexpected: FailSafe Long Context QA for Finance](https://arxiv.org/abs/2502.06329) 
* [Hypocrite Elon Musk Is Criticizing OpenAI for Not Open Sourcing ChatGPT While Refusing to Do the Same With Grok](https://futurism.com/hypocrite-elon-musk-criticizing-openai-open-sourcing-chatgpt-grok) 
* [Microsoft Backing Out of Expensive New Data Centers After Its CEO Expressed Doubt About AI Value](https://futurism.com/microsoft-ceo-hesitation-ai-expensive-data-centers) 
* [The Smarter AI Gets, the More It Start Cheating When It's Losing](https://futurism.com/the-byte/ai-cheating-chess) 
* [AI-Powered Deception is a Menace to Our Societies](https://thehackernews.com/2025/02/ai-powered-deception-is-menace-to-our.html?m=1)
* [The Death of Critical Thinking Will Kill Us Long Before AI.](https://www.joanwestenberg.com/the-death-of-critical-thinking-will-kill-us-long-before-ai/) 
* [[2502.12769] How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild](https://arxiv.org/abs/2502.12769)
* [[2502.11995] Presumed Cultural Identity: How Names Shape LLM Responses](https://arxiv.org/abs/2502.11995)  
* [[2502.13946] Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://arxiv.org/abs/2502.13946) 
* [New Junior Developers Can’t Actually Code | N’s Blog](https://nmn.gl/blog/ai-and-learning) 
* [[2502.12464] SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://arxiv.org/abs/2502.12464) 
* [How Hackers Manipulate Agentic AI with Prompt Engineering - SecurityWeek](https://www.securityweek.com/how-hackers-manipulate-agentic-ai-with-prompt-engineering/) 
* [AI can fix bugs—but can’t find them: OpenAI’s study highlights limits of LLMs in software engineering | VentureBeat](https://venturebeat.com/ai/ai-can-fix-bugs-but-cant-find-them-openais-study-highlights-limits-of-llms-in-software-engineering/) 
* ['Hopeless' to potentially handy: law firm puts AI to the test](https://www.bbc.com/news/articles/c743j83d8kzo) 
* [Should ‘Open Source AI’ Mean Exposing All Training Data?](https://shujisado.org/2025/02/18/should-open-source-ai-mean-exposing-all-training-data/) 
* [[2502.04376] MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf](https://www.arxiv.org/abs/2502.04376) 
* [ChatGPT Operator: Prompt Injection Exploits & Defenses · Embrace The Red](https://embracethered.com/blog/posts/2025/chatgpt-operator-prompt-injection-exploits/) 
* [Over 40% of AI-Related Data Breaches Tied to Cross-Border AI Use by 2027](https://www.eweek.com/news/improper-cross-border-ai-use-gartner/) 
* [The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers](https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf) 
* [Hallucination is Inevitable: An Innate Limitation of Large Language Models](https://arxiv.org/pdf/2401.11817) 
* [Airbnb CEO says it's still too early for AI trip planning | TechCrunch](https://techcrunch.com/2025/02/14/airbnb-ceo-says-its-still-too-early-for-ai-trip-planning) 
* [The Emperor Has No Clothes: Security In The Age Of Deepfakes](https://www.linkedin.com/pulse/emperor-has-clothes-security-age-deepfakes-jim-liddle-bvxse) 
* [[2502.03628] The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering](https://arxiv.org/abs/2502.03628) 
* [If the AI Roundheads go to war with tech royalty, don’t bet against them | John Naughton | The Guardian](https://www.theguardian.com/technology/2025/feb/15/if-the-ai-roundheads-go-to-war-with-tech-royalty-dont-bet-against-them)
* [Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) 
* [AI-Powered Social Engineering: Ancillary Tools and Techniques](https://thehackernews.com/2025/02/ai-powered-social-engineering-ancillary.html) 
* [European boffins want AI model tests put to the test • The Register](https://www.theregister.com/2025/02/15/boffins_question_ai_model_test/) 
    * [[2502.06559] Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation](https://arxiv.org/abs/2502.06559) 
* [[2502.08680] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges](https://arxiv.org/abs/2502.08680) 
* [I met the ‘godfathers of AI’ in Paris – here’s what they told me to really worry about | Alexander Hurst | The Guardian](https://www.theguardian.com/commentisfree/2025/feb/14/ai-godfathers-paris-industry-dangers-future) 
* [As Tech Companies Keep Pouring Money Into AI, Signs May Be Pointing to Disaster](https://futurism.com/tech-investment-ai) 
* [Securing AI Supply Chain: Like Software, Only Not - Google Cloud Community](https://www.googlecloudcommunity.com/gc/Community-Blog/Securing-AI-Supply-Chain-Like-Software-Only-Not/ba-p/867409) 
* [Larry Ellison wants to put all US data in one big AI system • The Register](https://www.theregister.com/2025/02/12/larry_ellison_wants_all_data/) 
* [After Copilot trial, government staff rated Microsoft's AI less useful than expected](https://www.theregister.com/2025/02/12/australian_treasury_copilot_pilot_assessment/) 
* [4 Takeaways from the Paris AI Summit: Global Tensions, China Alliances, and Billion-Dollar Investments](https://www.eweek.com/news/paris-ai-summit-roundup/) 
* [Is AI Helping or Hurting Critical Thought?](https://www.eweek.com/news/ai-critical-thinking-impact/) 
* [EU will put over $200 billion toward AI development](https://www.engadget.com/ai/eu-will-put-over-200-billion-toward-ai-development-150036706.html) 
* [Security Is Blocking AI Adoption: Is BYOC the Answer? - The New Stack](https://thenewstack.io/security-is-blocking-ai-adoption-is-byoc-the-answer/) 
* [Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch](https://arxiv.org/abs/2501.18512v1) 
* [AI impact hits mid-to-high wage occupations like IT the most • The Register](https://www.theregister.com/2025/02/11/ai_impact_hits_midtohigh_wage_jobs/?utm_source=dlvr.it&utm_medium=bluesky) 
* [Microsoft Study Finds AI Makes Human Cognition “Atrophied and Unprepared”](https://www.404media.co/microsoft-study-finds-ai-makes-human-cognition-atrophied-and-unprepared-3/) 
* [Where AI Benchmarks Fall Short, and How To Evaluate Models Instead - The New Stack](https://thenewstack.io/where-ai-benchmarks-fall-short-and-how-to-evaluate-models-instead/) 
* [OpenAI Seems to Be Low Key Panicking](https://futurism.com/openai-low-key-panicking-deepseek) 
* [Adversarial Misuse of Generative AI | Google Cloud Blog](https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai) 
* [[2501.18636] SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model](https://arxiv.org/abs/2501.18636) 
* [[2501.14334] Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts](https://arxiv.org/abs/2501.14334)
*  [[2501.17749] Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation](https://arxiv.org/abs/2501.17749) 
* [OpenEuroLLM: Europe’s New Initiative for Open-Source AI Development - InfoQ](https://www.infoq.com/news/2025/02/open-euro-llm/) 
* [AI-Powered Social Engineering: Reinvented Threats](https://thehackernews.com/2025/02/ai-powered-social-engineering.html?m=1)
* [I tested ChatGPT’s deep research with the most misunderstood law on the internet](https://www.theverge.com/openai/607587/chatgpt-deep-research-hands-on-section-230) 
* [Elon Musk's DOGE Training an AI to Analyze Government Spending](https://futurism.com/elon-musk-doge-ai-government) 
* [Gradual Disempowerment](https://gradual-disempowerment.ai/) 
* [Call to make tech firms report data centre energy use as AI booms | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/07/call-to-make-tech-firms-report-data-centre-energy-use-as-ai-booms) 
* [Concern the UK's AI ambitions could lead to water shortages](https://www.bbc.com/news/articles/ce85wx9jjndo) 
* [How Agentic AI will be Weaponized for Social Engineering Attacks - SecurityWeek](https://www.securityweek.com/how-agentic-ai-will-be-weaponized-for-social-engineering-attacks/) 
* [Tech Billionaire’s Solution to Fixing the Internet Broken by AI? Utopia For Content Creators](https://www.eweek.com/news/cloudflare-matthew-prince-internet-utopia-ai/) 
* [Researchers trained an OpenAI rival in half an hour for less than $50 | The Verge](https://www.theverge.com/news/607341/researchers-cheaper-openai-rival-training) 
* [IT decision makers unconvinced of returns from AI investment • The Register](https://www.theregister.com/2025/02/06/lenovo_ai_report/) 
* [Amazon's Mitigating AI Hallucinations Through This Mathematical Method](https://www.eweek.com/news/amazon-automated-reasoning-generative-ai-hallucinations/) 
* [Google ending AI arms ban incredibly concerning, campaigners say](https://www.bbc.com/news/articles/cy081nqx2zjo) 
* [DeepSeek has ripped away AI’s veil of mystique. That’s the real reason the tech bros fear it | Kenan Malik | The Guardian](https://www.theguardian.com/commentisfree/2025/feb/02/deepseek-ai-veil-of-mystique-tech-bros-fear) 
* [AI systems could be ‘caused to suffer’ if consciousness achieved, says research | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/03/ai-systems-could-be-caused-to-suffer-if-consciousness-achieved-says-research) 
* [AI ‘godfather’ predicts another revolution in the tech in next five years | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/04/ai-godfather-predicts-another-revolution-in-the-tech-in-next-five-years) 
* [OpenAI says its models are more persuasive than 82 percent of Reddit users - Ars Technica](https://arstechnica.com/ai/2025/02/are-ais-getting-dangerously-good-at-persuasion-openai-says-not-yet/) 
* [Prompt Injection for Large Language Models - InfoQ](https://www.infoq.com/articles/large-language-models-prompt-injection-stealing/) 
* [Constitutional Classifiers: Defending against universal jailbreaks \ Anthropic](https://www.anthropic.com/research/constitutional-classifiers) 
    * [[2501.18837] Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming](https://arxiv.org/abs/2501.18837) 
* [How an AI-written book shows why the tech 'terrifies' creatives - BBC News](https://www.bbc.co.uk/news/articles/cp8k5gezykyo) 
* [OpenAI Staff Turn Guns on Each Other After DeepSeek Humiliation](https://futurism.com/openai-staff-turn-on-each-other-deepseek) 
* [DeepSeek, ChatGPT, Grok … which is the best AI assistant? We put them to the test | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/01/deepseek-chatgpt-grok-gemini-claude-meta-ai-which-is-the-best-ai-assistant-we-put-them-to-the-test) 
* [Was this the week DeepSeek started the slow unwinding of the AI bet?](https://www.theguardian.com/technology/2025/feb/01/was-this-the-week-deepseek-started-the-slow-unwinding-of-the-ai-bet) 
* January was swamped by deepseek news but there was other news if you look hard enough 
* [How DeepSeek and next-generation AI agents could erode value of language models](https://www.cnbc.com/2025/01/31/deepseek-next-generation-ai-agents-may-erode-value-of-large-models.html) 
* [[2501.18009] Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org/abs/2501.18009) 
* [[2501.18438] o3-mini vs DeepSeek-R1: Which One is Safer?](https://arxiv.org/abs/2501.18438) 
* [OpenAI Strikes Deal With US Government to Use Its AI for Nuclear Weapon Security](https://futurism.com/openai-signs-deal-us-government-nuclear-weapon-security) 
* [The Manhattan Project Was Secret. Should America’s AI Work Be Too? - WSJ](https://www.wsj.com/tech/ai/the-manhattan-project-was-secret-should-americas-ai-work-be-too-5638be21?st=iepZkH&reflink=desktopwebshare_permalink) 
* [UC Berkeley researchers claim to replicate DeepSeek AI for just $30](https://tribune.net.ph/amp/story/2025/01/31/uc-berkeley-researchers-claim-to-replicate-deepseek-ai-for-30) 
* [DeepSeek stole our tech .... says Open AI](https://youtu.be/hpwoGjpYygI?si=2PzadCwUm1yYWw_P)
* [Microsoft is forming a new unit to study AI's impacts | TechCrunch](https://techcrunch.com/2025/01/31/microsoft-is-forming-a-new-unit-to-study-ais-impacts/) 
* [Oh, I’m sorry, tech bros – did DeepSeek copy your work? I can hardly imagine your distress | Marina Hyde | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/31/tech-bros-deepseek-china-sam-altman-openai) 
* [OpenAI Asking for Tens of Billions in New Investment to "Fund Its Money-Losing business Operations"](https://futurism.com/openai-asking-investment) 
* [The west is already losing the AI arms race | Larry Elliott | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/30/ai-arms-race-china-deepseek) 
* [Another OpenAI Researcher Quits, Calls AI "Terrifying" and a "Risky Gamble" | eWEEK](https://www.eweek.com/news/open-ai-researcher-quits-calls-ai-terrifying/) 
* [The questions the Chinese government doesn’t want DeepSeek AI to answer - Ars Technica](https://arstechnica.com/ai/2025/01/the-questions-the-chinese-government-doesnt-want-deepseek-ai-to-answer/) 
* [Deep Impact](https://www.wheresyoured.at/deep-impact/) 
* [Dario Amodei — On DeepSeek and Export Controls](https://darioamodei.com/on-deepseek-and-export-controls) 
* [OpenAI ‘reviewing’ allegations that its AI models were used to make DeepSeek](https://www.theguardian.com/technology/2025/jan/29/openai-chatgpt-deepseek-china-us-ai-models)  
* [AI and the future of national security](https://blog.google/technology/safety-security/ai-and-the-future-of-national-security/) 
* [OpenAI Furious DeepSeek Might Have Stolen All the Data OpenAI Stole From Us](https://www.404media.co/openai-furious-deepseek-might-have-stolen-all-the-data-openai-stole-from-us/) 
* [DeepSeek advances could heighten safety risk, says ‘godfather’ of AI | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/29/deepseek-artificial-intelligence-ai-safety-risk-yoshua-bengio)
* [What International AI Safety report says on jobs, climate, cyberwar and more | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/29/what-international-ai-safety-report-says-jobs-climate-cyberwar-deepfakes-extinction) 
* [Former OpenAI safety researcher brands pace of AI development ‘terrifying’ | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/28/former-openai-safety-researcher-brands-pace-of-ai-development-terrifying)
* [Is DeepSeek really sending data to China? Let’s decode | VentureBeat](https://venturebeat.com/ai/is-deepseek-really-sending-data-to-china-lets-decode/) 
* [DeepSeek R1 Exposed: Security Flaws in China’s AI Model • KELA Cyber Threat Intelligence](https://www.kelacyber.com/blog/deepseek-r1-security-flaws/) 
* [Zuckerberg Convening Huge "War Rooms" to Figure Out How a Chinese Startup Is Annihilating Meta's AI](https://futurism.com/zuckerberg-war-rooms-meta-ai-deepseek) 
* [The Short Case for Nvidia Stock | YouTube Transcript Optimizer](https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda) 
* [AI Alignment in Practice: What It Means and How to Get It - The New Stack](https://thenewstack.io/ai-alignment-in-practice-what-it-means-and-how-to-get-it/) 
* [OpenAI Developer Seethes at Success of DeepSeek](https://futurism.com/openai-developer-seethes-deepseek) 
* [Experts urge caution over use of Chinese AI DeepSeek](https://www.theguardian.com/technology/2025/jan/28/experts-urge-caution-over-use-of-chinese-ai-deepseek) 
* [DeepSeek: Trump warns of 'wake-up call' for US tech firms - BBC News](https://www.bbc.co.uk/news/articles/c4gpq01rvd4o) 
* [DeepSeek FAQ – Stratechery by Ben Thompson](https://stratechery.com/2025/deepseek-faq/) 
* [The argument against AI agents and unnecessary automation • The Register](https://www.theregister.com/2025/01/27/ai_agents_automate_argument/) 
* [[2501.13011] MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking](https://arxiv.org/abs/2501.13011) 
* [Frontier AI systems have surpassed the self-replicating red line](https://arxiv.org/html/2412.12140v1#abstract)
* [We Aren't Being Told the Real Extent of AI Datacenter Emissions](https://futurism.com/the-byte/not-being-told-datacenter-emissions) 
* [Artificial Intelligence In Health And Health Care: Priorities For Action | Health Affairs](https://goo.gle/3CoOb2y) 
* [Trading inference-time compute for adversarial robustness | OpenAI](https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness/) 
* [There's Apparently a Huge Financial Problem With Trump's Massive AI Project](https://futurism.com/huge-financial-problem-trump-ai-stargate) 
* [[2501.12206] Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model](https://arxiv.org/abs/2501.12206) 
* [More AI, More Problems for Software Developers in 2025 - The New Stack](https://thenewstack.io/more-ai-more-problems-for-software-developers-in-2025/) 
* [Cloud Deployment of AI Models Jumps, Says Data Science Study - The New Stack](https://thenewstack.io/cloud-deployment-of-ai-models-jumps-says-data-science-study/) 
* [Can AI Pass Humanity’s Ultimate Intelligence Test?](https://www.eweek.com/news/can-ai-pass-ultimate-iq-test/) 
* [What happens when we can’t build bigger datacenters anymore? • The Register](https://www.theregister.com/2025/01/24/build_bigger_ai_datacenters/) 
* [Meta's Top AI Lawyer Quits in Disgust](https://futurism.com/the-byte/meta-ai-lawyer-quits) 
* [Trump's Staff Have Had It With Elon Musk's Insubordination](https://futurism.com/the-byte/trump-staff-furious-elon-musk) 
* [Why everyone in AI is freaking out about DeepSeek | VentureBeat](https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek/) 
* [AI Hype Is Dropping Off a Cliff While Costs Soar, Experts Warn](https://futurism.com/the-byte/ai-hype-cliff-costs) 
* [Trump Revokes Biden EO Addressing AI Risks: What It Means](https://www.eweek.com/news/trump-revokes-biden-ai-eo/) 
* [Elon Musk and Sam Altman take to social media to fight over Stargate | TechCrunch](https://techcrunch.com/2025/01/22/elon-musk-and-sam-altman-take-to-social-media-to-fight-over-stargate/) 
* [Banks must keep ahead of risks and reap AI rewards • The Register](https://www.theregister.com/2025/01/21/banks_must_keep_ahead_of/) 
* [UK aims to fix government IT with help from AI Humphrey • The Register](https://www.theregister.com/2025/01/21/ai_humphrey_uk_government/) 
* [The Pentagon says AI is speeding up its 'kill chain' | TechCrunch](https://techcrunch.com/2025/01/19/the-pentagon-says-ai-is-speeding-up-its-kill-chain/)
* [What I've learned about writing AI apps so far | Seldo.com](https://seldo.com/posts/what-ive-learned-about-writing-ai-apps-so-far) 
* [Oscar-Nominated Film Editor’s AI Use Might Cost It the Academy Award](https://www.eweek.com/news/ai-use-might-cost-film-an-oscar/) 
* [AI Mistakes Are Very Different from Human Mistakes - Schneier on Security](https://www.schneier.com/blog/archives/2025/01/ai-mistakes-are-very-different-from-human-mistakes.html) 
* [Share of teens using ChatGPT for schoolwork doubled from 2023 to 2024 | Pew Research Center](https://www.pewresearch.org/short-reads/2025/01/15/about-a-quarter-of-us-teens-have-used-chatgpt-for-schoolwork-double-the-share-in-2023/) 
* [AI isn’t very good at history, new paper finds | TechCrunch](https://techcrunch.com/2025/01/19/ai-isnt-very-good-at-history-new-paper-finds/) 
* [More AI, More Problems for Software Developers in 2025 - The New Stack](https://thenewstack.io/more-ai-more-problems-for-software-developers-in-2025/) 
* [AI benchmarking organization criticized for waiting to disclose funding from OpenAI | TechCrunch](https://techcrunch.com/2025/01/19/ai-benchmarking-organization-criticized-for-waiting-to-disclose-funding-from-openai/)
* [Cringing before the tech giants is no way to make Britain an AI superpower | John Naughton | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/19/cringing-before-the-tech-giants-is-no-way-to-make-britain-an-ai-superpower) 
* [Labour’s investment in AI isn’t as clever as it thinks it is | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/17/labour-investment-in-ai-isnt-as-clever-as-it-thinks-it-is) 
* [Character.AI Is Seeking Partnerships with Media Brands, Despite Still Facing Two Lawsuits over the Welfare of Minor Users](https://futurism.com/character-ai-seeking-partnerships-despite-lawsuits) 
* [Amazon Says All It Needs to Do Before Releasing an AI-Powered Alexa Is to Solve the Giant Engineering Problem That Nobody Else on Earth Has Been Able to Solve](https://futurism.com/amazon-ai-powered-alexa-hallucinations-problem) 
* [Before Apple's AI Went Haywire and Started Making Up Fake News, Its Engineers Warned of Deep Flaws With the Tech](https://futurism.com/the-byte/apple-engineers-ai-deep-flaws) 
* [Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography](https://arxiv.org/pdf/2501.08970) 
* [[2501.08365] Towards Best Practices for Open Datasets for LLM Training](https://arxiv.org/abs/2501.08365) 
* [CEO of AI Music Company Says People Don’t Like Making Music](https://www.404media.co/ceo-of-ai-music-company-says-people-dont-like-making-music/) ( it's obvious why he says this after all it's his business model)
* [[2501.05542] Infecting Generative AI With Viruses](https://arxiv.org/abs/2501.05542) 
* [Amazon races to transplant Alexa’s ‘brain’ with generative AI](https://arstechnica.com/ai/2025/01/amazon-must-solve-hallucination-problem-before-launching-ai-enabled-alexa/) 
* [Lessons from red teaming 100 generative AI products](https://airedteamwhitepapers.blob.core.windows.net/lessonswhitepaper/MS_AIRT_Lessons_eBook.pdf) 
    * [avrix paper -Lessons From Red Teaming 100 Generative AI Products](https://arxiv.org/pdf/2501.07238) 
* [AI Agents Are Here. What Now?](https://huggingface.co/blog/ethics-soc-7) 
* [PM outlines AI Opportunities Action Plan | TechMarketView](https://www.techmarketview.com/ukhotviews/archive/2025/01/13/pm-outlines-ai-opportunities-action-plan)
* [Artificial Intelligence: Plan to 'unleash AI' across UK revealed - BBC News](https://www.bbc.co.uk/news/articles/crr05jykzkxo) ( Not entirely sure when any of this would start realising a ROI )  
* [Generative AI – The Power and the Glory](https://simonwillison.net/2025/Jan/12/generative-ai-the-power-and-the-glory/) 
* [While AI Causes Climate Change, Nvidia Scientist Proposes AI-Powered Firefighting Robots](https://futurism.com/ai-climate-change-wildfires) 
* [Artificial intelligence: 41% of companies worldwide plan to reduce workforces by 2030 due to AI | CNN Business](https://edition.cnn.com/2025/01/08/business/ai-job-losses-by-2030-intl/index.html) 
* [Survey: AI Tools are Increasing Amount of Bad Code Needing to be Fixed - DevOps.com](https://devops.com/survey-ai-tools-are-increasing-amount-of-bad-code-needing-to-be-fixed/) 
* [Code Quality Becomes Even More Vital in the AI Era - The New Stack](https://thenewstack.io/code-quality-becomes-even-more-vital-in-the-ai-era/) 
* [Elon Musk says all human data for AI training ‘exhausted’ | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/09/elon-musk-data-ai-training-artificial-intelligence) 
* [CEO Says He Hasn’t Hired Anyone in a Year as He Replaces Human Workers With AI](https://futurism.com/the-byte/klarna-ceo-ai-replacing-workers) 
* [Trolley Problem, Safety Versus Security of Generative AI - SecurityWeek](https://www.securityweek.com/trolley-problem-safety-versus-security-of-generative-ai/) 
* [AI-supported spear phishing fools more than 50% of targets | Malwarebytes](https://www.malwarebytes.com/blog/news/2025/01/ai-supported-spear-phishing-fools-more-than-50-of-targets) 
* [Not even OpenAI's $200/mo ChatGPT Pro plan can turn a profit • The Register](https://www.theregister.com/2025/01/06/altman_gpt_profits/) 
* [AI Domination: Remote Controlling ChatGPT ZombAI Instances · Embrace The Red](https://embracethered.com/blog/posts/2025/spaiware-and-chatgpt-command-and-control-via-prompt-injection-zombai/) 
* [‘Virtual employees’ could join workforce as soon as this year, OpenAI boss says | Technology sector | The Guardian](https://www.theguardian.com/business/2025/jan/06/virtual-employees-could-join-workforce-as-soon-as-this-year-openai-boss-says) 
* [Meta's AI Profiles Are Indistinguishable From Terrible Spam That Took Over Facebook](https://www.404media.co/metas-ai-profiles-are-indistinguishable-from-terrible-spam-that-took-over-facebook/)
* [Apple opts everyone into having their Photos analyzed by AI • The Register](https://www.theregister.com/2025/01/03/apple_enhanced_visual_search/) 
* [Why AI Did Not Upend the Super Year of Elections | Lawfare](https://www.lawfaremedia.org/article/why-ai-did-not-upend-the-super-year-of-elections) 
* [People Are Disgusted by Facebook’s Plan to Deploy AI-Powered “Users”](https://futurism.com/disgusted-facebook-ai-users)
