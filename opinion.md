# Categories

[In the wild](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#in-the-wild-in-the-wild)

[Regulating AI/Advisories](https://github.com/grapesfrog/GAI-is-going-well/blob/main/regulate-ai.md#regulating-ai--advisories-regulating-ai-advisories)

[Opinions , Research & presentations ](https://github.com/grapesfrog/GAI-is-going-well/blob/main/opinion.md#opinions--research--presentations-opinions-research--presentations)

[Mitigations & tooling](https://github.com/grapesfrog/GAI-is-going-well/blob/main/mitigation.md#mitigations--tooling-mitigations--tooling)

## Opinions , Research & presentations {#opinions-research-&-presentations}

[2024 articles](https://github.com/grapesfrog/GAI-is-going-well/blob/main/2024/opinion.md#opinions--research--presentations-opinions-research--presentations)

* **March** started with a doozy about another infamous memo coming from Google ! Gizmodo's headline captures the sentiment. Murmuring about the disappointment with gpt-4.5. Some innovative  ways to evaluate the performance of agents were a thing this month including assessing how they did managing a vending machine tl;dr Humans still the winners here. I also liked the idea of the survival game, a natural selection evaluation framework for models . I am loving these more interesting & applicable ways to  evaluate model performance. Agents are the buzzy thing in the world of AI and concerns about threat vectors have been a theme this month. Disappointment in Apple's lack of intelligence from apple intelligence 12 months after making a big noise about it. Some interesting articles about AI and jobs , IBM & Anthropic disagreeing on the future for devs & AI and women in a conundrum as AI helps their careers as quickly as it's eliminating jobs. How do you test an AI when it's aware it's being tested for alignment? This is a conundrum that has some attention! The superintelligence strategy is fascinating to read and if you don't have time to read it  then you can  watch the video about it. Vibe coding was in the news. Simon Willison's post has a good explanation ( Don't do this for production code !) . The UKs ambitions to roll out AI is hitting the obvious  road blocks as you can't just say we need to embrace AI without investing to support that ambition with everything required from updating hardware, the software available to staff through to recruiting and training staff. The first step however is to acknowledge the scale of the ambition so that's a start. [MCP](https://modelcontextprotocol.io/introduction) seems to be gaining traction as the way to connect AI agents/ LLMs to external tools and systems. It was open sourced [by Anthropic](https://www.anthropic.com/news/model-context-protocol) in November last year 
*  [Life in Low Data Gravity | AI News & Insights](https://www.deeplearning.ai/the-batch/life-in-low-data-gravity/) 
* [[2503.12072] Information-Guided Identification of Training Data Imprint in (Proprietary) Large Language Models](https://arxiv.org/abs/2503.12072)** **
* [Training Large Language Models for Advanced Typosquatting Detection](https://arxiv.org/abs/2503.22406v1) 
* [OpenAI's Sora Has a Small Problem With Being Hugely Racist and Sexist](https://futurism.com/openai-sora-racist-sexist) 
* [AI's "Biggest Test" Is Turning Into a Catastrophe as CoreWeave Flounders](https://futurism.com/ai-test-coreweave) 
* [Ghost Jobs, Deepfakes, and Bots: Welcome to the AI Job Hunt](https://www.eweek.com/news/ai-job-applicants-hiring/) 
* [ML and LLM Adoption Challenged Most Often by Observability - The New Stack](https://thenewstack.io/ml-and-llm-adoption-challenged-most-often-by-observability/) 
* [LLM providers on the cusp of an 'extinction' phase as capex realities bite](https://www.theregister.com/2025/03/31/llm_providers_extinction/)  
* [Calling all fashion models … now AI is coming for you](https://www.theguardian.com/fashion/2025/mar/30/fashion-models-ai-job-losses) 
* [Horseless intelligence | Ned Batchelder](https://nedbatchelder.com/blog/202503/horseless_intelligence.html)
* [The State of AI: Global survey | McKinsey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai)
* [MCP is the new interface for security tools](https://mayakaczorowski.com/blogs/mcp) 
* [Bill Gates Predicts AI Will Replace Many Doctors, Teachers Within 10 Years](https://www.eweek.com/news/bill-gates-ai-predictions-jobs/) 
* [Why do LLMs make stuff up? New research peers under the hood. - Ars Technica](https://arstechnica.com/ai/2025/03/why-do-llms-make-stuff-up-new-research-peers-under-the-hood/) 
    * [Tracing the thoughts of a large language model \ Anthropic](https://www.anthropic.com/research/tracing-thoughts-language-model) 
* [[2502.08586] Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](https://arxiv.org/abs/2502.08586)
* [Why Centralized AI Fails in Enterprise: The Case for a Federated Architecture - The New Stack](https://thenewstack.io/why-centralized-ai-fails-in-enterprise-the-case-for-a-federated-architecture/) 
* [Exploring Generative AI](https://martinfowler.com/articles/exploring-gen-ai.html#memo-13) 
* [Measuring AI Ability to Complete Long Tasks - METR](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/) 
* [Study: AI Turns Evil After Training on Insecure Code - The New Stack](https://thenewstack.io/study-ai-turns-evil-after-training-on-insecure-code/) 
    * [Emergent Misalignment](https://www.emergent-misalignment.com/) 
* [A new, challenging AGI test stumps most AI models | TechCrunch](https://techcrunch.com/2025/03/24/a-new-challenging-agi-test-stumps-most-ai-models/) 
* [Is the AI Bubble About To Burst?](https://www.eweek.com/news/ai-bubble-risk/) 
* [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2025.pdf) ( 2025 version)
* [Feeling Addicted to ChatGPT? You’re Not Alone, According to MIT & OpenAI](https://www.eweek.com/news/chatgpt-addiction-openai-mit-study/) 
* [Government AI roll-outs threatened by outdated IT systems | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/mar/26/government-ai-roll-outs-threatened-by-outdated-it-systems) 
* [MPs warn legacy IT could derail UK government's AI hopes • The Register](https://www.theregister.com/2025/03/26/legacy_systems_uk_ai/) 
* [How vibe coding will affect Engineering Managers ](https://newsletter.manager.dev/p/effect-of-ai-on-engineering-managers) 
* [Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation](https://arxiv.org/abs/2503.19622) 
* [Early methods for studying affective use and emotional well-being on ChatGPT | OpenAI](https://openai.com/index/affective-use-study) 
* [Defeating Prompt Injections by Design](https://arxiv.org/abs/2503.18813) 
* [[2503.17489] Judge Anything: MLLM as a Judge Across Any Modality](https://arxiv.org/abs/2503.17489) 
* [[2503.14499] Measuring AI Ability to Complete Long Tasks](https://arxiv.org/abs/2503.14499) 
* [Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment](https://arxiv.org/abs/2411.18688v3) 
* [Blending AI and DevSecOps: Enhancing Security in the Development Pipeline](https://devops.com/blending-ai-and-devsecops-enhancing-security-in-the-development-pipeline) 
* [Joint studies from OpenAI and MIT found links between loneliness and ChatGPT use](https://www.engadget.com/ai/joint-studies-from-openai-and-mit-found-links-between-loneliness-and-chatgpt-use-193537421.html) 
* [Not all AI-assisted programming is vibe coding (but vibe coding rocks)](https://simonwillison.net/2025/Mar/19/vibe-coding/) 
* [Scientist Says That ChatGPT Has a "Staggering" Gender Problem](https://futurism.com/scientist-chatgpt-gender-gap) 
* [[2503.16416] Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416) 
* [[2503.15299] Inside-Out: Hidden Factual Knowledge in LLMs](https://arxiv.org/abs/2503.15299) 
* [[2503.16031] Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content](https://arxiv.org/abs/2503.16031) 
* [[2503.13657] Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/abs/2503.13657) 
* [Commentary: Why China is suddenly flooding the market with powerful AI models - CNA](https://www.channelnewsasia.com/commentary/china-open-source-ai-model-deepseek-alibaba-compete-us-tech-5010401) 
* [VLMs as GeoGuessr Masters—Exceptional Performance, Hidden Biases, and Privacy Risks Mind the Photos You Post: AI Knows Where You Are!](https://arxiv.org/html/2502.11163v1) 
* [Superintelligence Strategy](https://www.nationalsecurity.ai/)
    * [Ex-Google CEO Says AI War Is COMING! (Superintelligence Strategy)](https://youtu.be/eMQulv3nVZk?si=HiDwhIfGleKwYa_S) 
* [North Korea launches new unit with a focus on AI hacking, per report | TechCrunch](https://techcrunch.com/2025/03/20/north-korea-launches-new-unit-with-a-focus-on-ai-hacking-per-report/) 
* [Vibe Coding is a Dangerous Fantasy | N’s Blog](https://nmn.gl/blog/vibe-coding-fantasy) 
* [OpenAI Scientists' Efforts to Make an AI Lie and Cheat Less Backfired Spectacularly](https://futurism.com/openai-stop-ai-lie-cheat-backfired) 
    * [[2503.11926] Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation](https://arxiv.org/abs/2503.11926) 
* [[2503.05710] AGI, Governments, and Free Societies](https://arxiv.org/abs/2503.05710) 
* [[2209.00626] The Alignment Problem from a Deep Learning Perspective](https://arxiv.org/abs/2209.00626) 
* [Claude Sonnet 3.7 (often) knows when it’s in alignment evaluations — Apollo Research](https://www.apolloresearch.ai/blog/claude-sonnet-37-often-knows-when-its-in-alignment-evaluations) 
* [Auditing language models for hidden objectives \ Anthropic](https://www.anthropic.com/research/auditing-hidden-objectives) 
* [RFK Says AI Nurses Are 'As Good as Any Doctor'](https://www.eweek.com/news/ai-healthcare-nurses-doctors/) 
* [[2501.11433] One Does Not Simply Meme Alone: Evaluating Co-Creativity Between LLMs and Humans in the Generation of Humor](https://arxiv.org/abs/2501.11433) 
* [Now you don’t even need code to be a programmer. But you do still need expertise | John Naughton | The Guardian](https://www.theguardian.com/technology/2025/mar/16/ai-software-coding-programmer-expertise-jobs-threat) 
* [AI project failure rates are on the rise: report | CIO Dive](https://www.ciodive.com/news/AI-project-fail-data-SPGlobal/742590/) 
* [No one knows what the hell an AI agent is | TechCrunch](https://techcrunch.com/2025/03/14/no-one-knows-what-the-hell-an-ai-agent-is/) 
* [AI Agents in Doubt: Reducing Uncertainty in Agentic Workflows - The New Stack](https://thenewstack.io/ai-agents-in-doubt-reducing-uncertainty-in-agentic-workflows/) 
* [Majority of AI Researchers Say Tech Industry Is Pouring Billions Into a Dead End](https://futurism.com/ai-researchers-tech-industry-dead-end) 
* [OWASP Dishes Out Key Ingredients for a Secure Agentic AI Future | by Idan Habler | Intuit Engineering | Mar, 2025 | Medium](https://medium.com/intuit-engineering/owasp-dishes-out-key-ingredients-for-a-secure-agentic-ai-future-be862e167d6c) 
* [Trained on buggy code, LLMs often parrot same mistakes • The Register](https://www.theregister.com/2025/03/19/llms_buggy_code/)
    * [[2503.11082] LLMs are Bug Replicators: An Empirical Study on LLMs' Capability in Completing Bug-prone Code](https://arxiv.org/abs/2503.11082) 
* [[2503.12545] PEBench: A Fictitious Dataset to Benchmark Machine Unlearning for Multimodal Large Language Models](https://arxiv.org/abs/2503.12545) 
* [How To Create the Generative AI Policy You Needed Yesterday](https://thenewstack.io/how-to-create-the-generative-ai-policy-you-needed-yesterday/) 
* [Vibe Coding Is Here — But Are You Ready for Incident Vibing? - The New Stack](https://thenewstack.io/vibe-coding-is-here-but-are-you-ready-for-incident-vibing/) 
* [Billions of Dollars Down the Drain? 76% of AI Researchers Consider AGI 'Unrealistic Goal'](https://www.eweek.com/news/news-ai-investments-agi/) 
* [AI search is starting to kill Google’s ‘ten blue links’](https://www.theverge.com/ai-artificial-intelligence/631352/ai-search-adobe-analytics-google-perplexity-openai) 
* [Marvel Directors on AI in Films: 'Artists Need to Lead the Innovation'](https://www.eweek.com/news/marvel-directors-joe-anthony-russo-ai-films/) 
* [Post-apocalyptic education - by Ethan Mollick](https://www.oneusefulthing.org/p/post-apocalyptic-education) 
* [[2503.09669] Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.09669) 
* [Virginia Tech Study Reveals Machine Learning Models Struggle to Identify Critical Health Declines](https://bioengineer.org/virginia-tech-study-reveals-machine-learning-models-struggle-to-identify-critical-health-declines/) 
* [How AI Is Reshaping CISO Priorities - The New Stack](https://thenewstack.io/how-ai-is-reshaping-ciso-priorities/) 
* [AI is Creating New Paths for Women — And Closing Doors at the Same Time](https://www.eweek.com/news/news-ai-women-tech-jobs/) 
* [My Thoughts on the Future of "AI" Nicholas Carlini](https://nicholas.carlini.com/writing/2025/thoughts-on-future-ai.html) 
* [AI vs. Developer Jobs: Anthropic Predicts Replacement, IBM Pushes Back](https://www.eweek.com/news/ai-developers-jobs-anthropic-ibm/) 
* [Trust AI or Peers More for Advice? Here’s What Execs Prefer & Why](https://www.eweek.com/news/ai-trust-executives-sap-study/) 
* [Poisoning the Well and Other Generative AI Risks - The New Stack](https://thenewstack.io/poisoning-the-well-and-other-generative-ai-risks/) 
* [[2503.09837] On the Limitations of Vision-Language Models in Understanding Image Transforms](https://arxiv.org/abs/2503.09837) 
* [[2503.09905] Quantization for OpenAI's Whisper Models: A Comparative Analysis](https://arxiv.org/abs/2503.09905) 
* [[2503.10635] A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](https://arxiv.org/abs/2503.10635) 
* [DeepSeek-R1 Uncensored, QwQ-32B Puts Reasoning in Smaller Model, and more...](https://www.deeplearning.ai/the-batch/issue-292/) 
* [Daring Fireball: Something Is Rotten in the State of Cupertino](https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino) 
* [AI running out of juice despite Microsoft's hard squeezing • The Register](https://www.theregister.com/2025/03/14/ai_running_out_of_juice/) 
* [Entering AI Autumn: Why LLMs Are Nearing Their Limit - The New Stack](https://thenewstack.io/entering-ai-autumn-why-llms-are-nearing-their-limit/) 
* [Researchers astonished by tool’s apparent success at revealing AI’s “hidden objectives” - Ars Technica](https://arstechnica.com/ai/2025/03/researchers-astonished-by-tools-apparent-success-at-revealing-ais-hidden-motives/) 
* [How ProPublica Uses AI Responsibly in Its Investigations](https://www.propublica.org/article/using-ai-responsibly-for-reporting) 
* [‘A computer’s joke, on us’: writers respond to the short story written by AI | Books | The Guardian](https://www.theguardian.com/books/2025/mar/14/writers-respond-story-written-by-ai-sam-altman-chat-gpt-tracy-chevalier-kamila-shamsie-david-baddiel) 
* [The UK government embracing AI? I’m sorry, that’s nonsense and I can prove it | Chris Stokel-Walker | The Guardian](https://www.theguardian.com/commentisfree/2025/mar/14/uk-government-artifical-intelligence-chatgpt)
* [It turns out ChatGPT o1 and DeepSeek-R1 cheat at chess if they’re losing, which makes me wonder if I should trust AI with anything | TechRadar](https://www.techradar.com/computing/artificial-intelligence/it-turns-out-chatgpt-o1-and-deepseek-r1-cheat-at-chess-if-theyre-losing-which-makes-me-wonder-if-i-should-i-should-trust-ai-with-anything) 
* [Bank CEO says 4-day week isn't progressive, and AI will make it 'bloody logical' | Fortune Europe](https://fortune.com/europe/2025/03/13/atom-bank-ceo-running-4-day-work-week-cutting-working-hours-isnt-progressive-ai-make-bloody-logical/) 
* [[2503.05856] This Is Your Doge, If It Please You: Exploring Deception and Robustness in Mixture of LLMs](https://arxiv.org/abs/2503.05856) 
* [[2503.07389] TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.07389) 
* [[2503.07595] Detection Avoidance Techniques for Large Language Models](https://arxiv.org/abs/2503.07595) 
* [Pentesters: Is AI Coming for Your Role?](https://thehackernews.com/2025/03/pentesters-is-ai-coming-for-your-role.html) 
* [What Is LLM Observability and Monitoring? - The New Stack](https://thenewstack.io/what-is-llm-observability-and-monitoring/) 
* [Can You Trust AI To Be Your Data Analyst? - The New Stack](https://thenewstack.io/can-you-trust-ai-to-be-your-data-analyst/) 
* [[2503.03704] A Practical Memory Injection Attack against LLM Agents](https://arxiv.org/abs/2503.03704) 
* [[2502.09747] The Widespread Adoption of Large Language Model-Assisted Writing Across Society](https://arxiv.org/abs/2502.09747) 
* [What’s Missing With AI-Generated Code? Refactoring - The New Stack](https://thenewstack.io/whats-missing-with-ai-generated-code-refactoring/) 
* [The State of LLM Reasoning Models](https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling) ( Great article on scaling for inference)
* [Anthropic Warns White House: Act Now on AI Security or Face Serious Risks](https://www.eweek.com/news/anthropic-white-house-ai-security/) 
*  [[2503.02191] Understanding and Predicting Derailment in Toxic Conversations on GitHub](https://arxiv.org/abs/2503.02191) 
* [[2503.04369] Lost in Literalism: How Supervised Training Shapes Translationese in LLMs](https://arxiv.org/abs/2503.04369) 
* [Freelancers Are Getting Ruined by AI](https://futurism.com/freelancers-struggling-compete-ai) 
* [[2503.02879] Wikipedia in the Era of LLMs: Evolution and Risks](https://arxiv.org/abs/2503.02879) 
* [[2503.02846] Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs](https://arxiv.org/abs/2503.02846) 
* [GitHub - lmgame-org/GamingAgent: Computer gaming agents that run on your PC and laptops.](https://github.com/lmgame-org/GamingAgent) 
* [Why AI Agents Suck So Bad - The New Stack](https://thenewstack.io/why-ai-agents-suck-so-bad/) 
* [AGI still a long way off, academics in China have calculated • The Register](https://www.theregister.com/2025/03/05/boffins_from_china_calculate_agi/) 
    * [https://github.com/jingtaozhan/IntelligenceTest](https://github.com/jingtaozhan/IntelligenceTest) 
* [How New AI Agents Will Transform Credential Stuffing Attacks](https://thehackernews.com/2025/03/how-new-ai-agents-will-transform.html?m=1) 
* [Why AI Agents Suck So Bad - The New Stack](https://thenewstack.io/why-ai-agents-suck-so-bad/) 
* [AI-Powered Lawyering: AI Reasoning Models, Retrieval Augmented Generation, and the Future of Legal Practice](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5162111) 
* [Analysts Warn That If AI Agents Succeed, the "Internet Will Go Dark"](https://futurism.com/ai-agents-dark-internet) 
* [Power Cut](https://www.wheresyoured.at/power-cut/) 
* [AI is killing some companies, yet others are thriving - let's look at the data](https://www.elenaverna.com/p/ai-is-killing-some-companies-yet) 
* [[2502.15840] Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents](https://arxiv.org/abs/2502.15840) 
* [[2502.19187] BIG-Bench Extra Hard](https://arxiv.org/abs/2502.19187) 
* [If the best defence against AI is more AI, this could be tech’s Oppenheimer moment | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/mar/02/ai-oppenheimer-moment-karp-zapiska-technological-republic) 
* [[2502.16750] Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System](https://arxiv.org/abs/2502.16750) 
* [AI killing some companies, others doing fine](https://boingboing.net/2025/03/01/ai-killing-some-companies-others-doing-fine.html) 
* [Hallucinations in code are the least dangerous form of LLM mistakes](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/) 
* [[2409.04109] Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers](https://arxiv.org/abs/2409.04109) 
* [OpenAI May Have Really Screwed Up With GPT-4.5](https://futurism.com/openai-screwed-up-gpt-4-5) 
* [Will the future of software development run on vibes?](https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/) 
* [Sergey Brin says AGI is within reach if Googlers work 60-hour weeks - Ars Technica](https://arstechnica.com/google/2025/02/sergey-brin-says-agi-is-within-reach-if-googlers-work-60-hour-weeks/) 
* [Google’s Sergey Brin Says Engineers Should Work 60-Hour Weeks in Office to Build AI That Could Replace Them](https://gizmodo.com/googles-sergey-brin-says-engineers-should-work-60-hour-weeks-in-office-to-build-ai-that-could-replace-them-2000570025) 
* [[2502.09747] The Widespread Adoption of Large Language Model-Assisted Writing Across Society](https://arxiv.org/abs/2502.09747) 
* [Disrupting a global cybercrime network abusing generative AI - Microsoft On the Issues](https://blogs.microsoft.com/on-the-issues/2025/02/27/disrupting-cybercrime-abusing-gen-ai/) 
* [How AI Takeover Might Happen in 2 Years — LessWrong](https://www.lesswrong.com/posts/KFJ2LFogYqzfGB3uX/how-ai-takeover-might-happen-in-2-years) 
* [[2502.15737] A Performance Analysis of You Only Look Once Models for Deployment on Constrained Computational Edge Devices in Drone Applications](https://arxiv.org/abs/2502.15737)
* Feb had concerns about energy & water usage that the DCs would need . Muttering about the ROI from AI after fourth quarter earnings reports. Another theme was about AI making humans lazy when it came to critical thinking . Great paper on why AI  benchmarks should be taken with a huge spoonful of salt! The Register article summarises the paper in their usual snarky way.
* [[2502.01822] Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org/abs/2502.01822) 
* [AUTOHIJACKER: AUTOMATIC INDIRECT PROMPT INJECTION AGAINST BLACK-BOX LLM AGENTS](https://openreview.net/pdf?id=2VmB01D9Ef) 
* [[2502.13172] Unveiling Privacy Risks in LLM Agent Memory](https://arxiv.org/abs/2502.13172)
* [AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways](https://dl.acm.org/doi/full/10.1145/3716628) 
* [OAuth Works for AI Agents, but Scaling Is Another Question - The New Stack](https://thenewstack.io/oauth-works-for-ai-agents-but-scaling-is-another-question/) 
    * [AI agent identity: it's just OAuth](https://mayakaczorowski.com/blogs/ai-agent-authentication) 
* [No new engineer hires this year as AI coding tools boost productivity, says Salesforce](https://www.theregister.com/2025/02/27/salesforce_misses_revenue_guidance/) 
* [U.S. Workers Are More Worried Than Hopeful About Future AI Use in the Workplace | Pew Research Center](https://www.pewresearch.org/social-trends/2025/02/25/u-s-workers-are-more-worried-than-hopeful-about-future-ai-use-in-the-workplace/) 
* [Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks](https://arxiv.org/abs/2502.13175v2) 
* [How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities](https://arxiv.org/abs/2502.18387v1) 
* [UK universities warned to ‘stress-test’ assessments as 92% of students use AI](https://www.theguardian.com/education/2025/feb/26/uk-universities-warned-to-stress-test-assessments-as-92-of-students-use-ai) 
* [[2502.17424] Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](https://arxiv.org/abs/2502.17424) 
* [Investigating LLM Jailbreaking of Popular Generative AI Web Products](https://unit42.paloaltonetworks.com/jailbreaking-generative-ai-web-products/) 
* [How to exploit top LRMs that reveal their reasoning steps • The Register](https://www.theregister.com/2025/02/25/chain_of_thought_jailbreaking/)
    * [https://github.com/dukeceicenter/jailbreak-reasoning-openai-o1o3-deepseek-r1](https://github.com/dukeceicenter/jailbreak-reasoning-openai-o1o3-deepseek-r1)  
* [[2502.14975] Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries](https://arxiv.org/abs/2502.14975) 
* [Claude's extended thinking \ Anthropic](https://www.anthropic.com/research/visible-extended-thinking) ( now this is a benchmark I find worth using !) 
* [[2502.06329] Expect the Unexpected: FailSafe Long Context QA for Finance](https://arxiv.org/abs/2502.06329) 
* [Hypocrite Elon Musk Is Criticizing OpenAI for Not Open Sourcing ChatGPT While Refusing to Do the Same With Grok](https://futurism.com/hypocrite-elon-musk-criticizing-openai-open-sourcing-chatgpt-grok) 
* [Microsoft Backing Out of Expensive New Data Centers After Its CEO Expressed Doubt About AI Value](https://futurism.com/microsoft-ceo-hesitation-ai-expensive-data-centers) 
* [The Smarter AI Gets, the More It Start Cheating When It's Losing](https://futurism.com/the-byte/ai-cheating-chess) 
* [AI-Powered Deception is a Menace to Our Societies](https://thehackernews.com/2025/02/ai-powered-deception-is-menace-to-our.html?m=1)
* [The Death of Critical Thinking Will Kill Us Long Before AI.](https://www.joanwestenberg.com/the-death-of-critical-thinking-will-kill-us-long-before-ai/) 
* [[2502.12769] How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild](https://arxiv.org/abs/2502.12769)
* [[2502.11995] Presumed Cultural Identity: How Names Shape LLM Responses](https://arxiv.org/abs/2502.11995)  
* [[2502.13946] Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://arxiv.org/abs/2502.13946) 
* [New Junior Developers Can’t Actually Code | N’s Blog](https://nmn.gl/blog/ai-and-learning) 
* [[2502.12464] SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://arxiv.org/abs/2502.12464) 
* [How Hackers Manipulate Agentic AI with Prompt Engineering - SecurityWeek](https://www.securityweek.com/how-hackers-manipulate-agentic-ai-with-prompt-engineering/) 
* [AI can fix bugs—but can’t find them: OpenAI’s study highlights limits of LLMs in software engineering | VentureBeat](https://venturebeat.com/ai/ai-can-fix-bugs-but-cant-find-them-openais-study-highlights-limits-of-llms-in-software-engineering/) 
* ['Hopeless' to potentially handy: law firm puts AI to the test](https://www.bbc.com/news/articles/c743j83d8kzo) 
* [Should ‘Open Source AI’ Mean Exposing All Training Data?](https://shujisado.org/2025/02/18/should-open-source-ai-mean-exposing-all-training-data/) 
* [[2502.04376] MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf](https://www.arxiv.org/abs/2502.04376) 
* [ChatGPT Operator: Prompt Injection Exploits & Defenses · Embrace The Red](https://embracethered.com/blog/posts/2025/chatgpt-operator-prompt-injection-exploits/) 
* [Over 40% of AI-Related Data Breaches Tied to Cross-Border AI Use by 2027](https://www.eweek.com/news/improper-cross-border-ai-use-gartner/) 
* [The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers](https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf) 
* [Hallucination is Inevitable: An Innate Limitation of Large Language Models](https://arxiv.org/pdf/2401.11817) 
* [Airbnb CEO says it's still too early for AI trip planning | TechCrunch](https://techcrunch.com/2025/02/14/airbnb-ceo-says-its-still-too-early-for-ai-trip-planning) 
* [The Emperor Has No Clothes: Security In The Age Of Deepfakes](https://www.linkedin.com/pulse/emperor-has-clothes-security-age-deepfakes-jim-liddle-bvxse) 
* [[2502.03628] The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering](https://arxiv.org/abs/2502.03628) 
* [If the AI Roundheads go to war with tech royalty, don’t bet against them | John Naughton | The Guardian](https://www.theguardian.com/technology/2025/feb/15/if-the-ai-roundheads-go-to-war-with-tech-royalty-dont-bet-against-them)
* [Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) 
* [AI-Powered Social Engineering: Ancillary Tools and Techniques](https://thehackernews.com/2025/02/ai-powered-social-engineering-ancillary.html) 
* [European boffins want AI model tests put to the test • The Register](https://www.theregister.com/2025/02/15/boffins_question_ai_model_test/) 
    * [[2502.06559] Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation](https://arxiv.org/abs/2502.06559) 
* [[2502.08680] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges](https://arxiv.org/abs/2502.08680) 
* [I met the ‘godfathers of AI’ in Paris – here’s what they told me to really worry about | Alexander Hurst | The Guardian](https://www.theguardian.com/commentisfree/2025/feb/14/ai-godfathers-paris-industry-dangers-future) 
* [As Tech Companies Keep Pouring Money Into AI, Signs May Be Pointing to Disaster](https://futurism.com/tech-investment-ai) 
* [Securing AI Supply Chain: Like Software, Only Not - Google Cloud Community](https://www.googlecloudcommunity.com/gc/Community-Blog/Securing-AI-Supply-Chain-Like-Software-Only-Not/ba-p/867409) 
* [Larry Ellison wants to put all US data in one big AI system • The Register](https://www.theregister.com/2025/02/12/larry_ellison_wants_all_data/) 
* [After Copilot trial, government staff rated Microsoft's AI less useful than expected](https://www.theregister.com/2025/02/12/australian_treasury_copilot_pilot_assessment/) 
* [4 Takeaways from the Paris AI Summit: Global Tensions, China Alliances, and Billion-Dollar Investments](https://www.eweek.com/news/paris-ai-summit-roundup/) 
* [Is AI Helping or Hurting Critical Thought?](https://www.eweek.com/news/ai-critical-thinking-impact/) 
* [EU will put over $200 billion toward AI development](https://www.engadget.com/ai/eu-will-put-over-200-billion-toward-ai-development-150036706.html) 
* [Security Is Blocking AI Adoption: Is BYOC the Answer? - The New Stack](https://thenewstack.io/security-is-blocking-ai-adoption-is-byoc-the-answer/) 
* [Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch](https://arxiv.org/abs/2501.18512v1) 
* [AI impact hits mid-to-high wage occupations like IT the most • The Register](https://www.theregister.com/2025/02/11/ai_impact_hits_midtohigh_wage_jobs/?utm_source=dlvr.it&utm_medium=bluesky) 
* [Microsoft Study Finds AI Makes Human Cognition “Atrophied and Unprepared”](https://www.404media.co/microsoft-study-finds-ai-makes-human-cognition-atrophied-and-unprepared-3/) 
* [Where AI Benchmarks Fall Short, and How To Evaluate Models Instead - The New Stack](https://thenewstack.io/where-ai-benchmarks-fall-short-and-how-to-evaluate-models-instead/) 
* [OpenAI Seems to Be Low Key Panicking](https://futurism.com/openai-low-key-panicking-deepseek) 
* [Adversarial Misuse of Generative AI | Google Cloud Blog](https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai) 
* [[2501.18636] SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model](https://arxiv.org/abs/2501.18636) 
* [[2501.14334] Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts](https://arxiv.org/abs/2501.14334)
*  [[2501.17749] Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation](https://arxiv.org/abs/2501.17749) 
* [OpenEuroLLM: Europe’s New Initiative for Open-Source AI Development - InfoQ](https://www.infoq.com/news/2025/02/open-euro-llm/) 
* [AI-Powered Social Engineering: Reinvented Threats](https://thehackernews.com/2025/02/ai-powered-social-engineering.html?m=1)
* [I tested ChatGPT’s deep research with the most misunderstood law on the internet](https://www.theverge.com/openai/607587/chatgpt-deep-research-hands-on-section-230) 
* [Elon Musk's DOGE Training an AI to Analyze Government Spending](https://futurism.com/elon-musk-doge-ai-government) 
* [Gradual Disempowerment](https://gradual-disempowerment.ai/) 
* [Call to make tech firms report data centre energy use as AI booms | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/07/call-to-make-tech-firms-report-data-centre-energy-use-as-ai-booms) 
* [Concern the UK's AI ambitions could lead to water shortages](https://www.bbc.com/news/articles/ce85wx9jjndo) 
* [How Agentic AI will be Weaponized for Social Engineering Attacks - SecurityWeek](https://www.securityweek.com/how-agentic-ai-will-be-weaponized-for-social-engineering-attacks/) 
* [Tech Billionaire’s Solution to Fixing the Internet Broken by AI? Utopia For Content Creators](https://www.eweek.com/news/cloudflare-matthew-prince-internet-utopia-ai/) 
* [Researchers trained an OpenAI rival in half an hour for less than $50 | The Verge](https://www.theverge.com/news/607341/researchers-cheaper-openai-rival-training) 
* [IT decision makers unconvinced of returns from AI investment • The Register](https://www.theregister.com/2025/02/06/lenovo_ai_report/) 
* [Amazon's Mitigating AI Hallucinations Through This Mathematical Method](https://www.eweek.com/news/amazon-automated-reasoning-generative-ai-hallucinations/) 
* [Google ending AI arms ban incredibly concerning, campaigners say](https://www.bbc.com/news/articles/cy081nqx2zjo) 
* [DeepSeek has ripped away AI’s veil of mystique. That’s the real reason the tech bros fear it | Kenan Malik | The Guardian](https://www.theguardian.com/commentisfree/2025/feb/02/deepseek-ai-veil-of-mystique-tech-bros-fear) 
* [AI systems could be ‘caused to suffer’ if consciousness achieved, says research | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/03/ai-systems-could-be-caused-to-suffer-if-consciousness-achieved-says-research) 
* [AI ‘godfather’ predicts another revolution in the tech in next five years | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/04/ai-godfather-predicts-another-revolution-in-the-tech-in-next-five-years) 
* [OpenAI says its models are more persuasive than 82 percent of Reddit users - Ars Technica](https://arstechnica.com/ai/2025/02/are-ais-getting-dangerously-good-at-persuasion-openai-says-not-yet/) 
* [Prompt Injection for Large Language Models - InfoQ](https://www.infoq.com/articles/large-language-models-prompt-injection-stealing/) 
* [Constitutional Classifiers: Defending against universal jailbreaks \ Anthropic](https://www.anthropic.com/research/constitutional-classifiers) 
    * [[2501.18837] Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming](https://arxiv.org/abs/2501.18837) 
* [How an AI-written book shows why the tech 'terrifies' creatives - BBC News](https://www.bbc.co.uk/news/articles/cp8k5gezykyo) 
* [OpenAI Staff Turn Guns on Each Other After DeepSeek Humiliation](https://futurism.com/openai-staff-turn-on-each-other-deepseek) 
* [DeepSeek, ChatGPT, Grok … which is the best AI assistant? We put them to the test | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/feb/01/deepseek-chatgpt-grok-gemini-claude-meta-ai-which-is-the-best-ai-assistant-we-put-them-to-the-test) 
* [Was this the week DeepSeek started the slow unwinding of the AI bet?](https://www.theguardian.com/technology/2025/feb/01/was-this-the-week-deepseek-started-the-slow-unwinding-of-the-ai-bet) 
* January was swamped by deepseek news but there was other news if you look hard enough 
* [How DeepSeek and next-generation AI agents could erode value of language models](https://www.cnbc.com/2025/01/31/deepseek-next-generation-ai-agents-may-erode-value-of-large-models.html) 
* [[2501.18009] Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org/abs/2501.18009) 
* [[2501.18438] o3-mini vs DeepSeek-R1: Which One is Safer?](https://arxiv.org/abs/2501.18438) 
* [OpenAI Strikes Deal With US Government to Use Its AI for Nuclear Weapon Security](https://futurism.com/openai-signs-deal-us-government-nuclear-weapon-security) 
* [The Manhattan Project Was Secret. Should America’s AI Work Be Too? - WSJ](https://www.wsj.com/tech/ai/the-manhattan-project-was-secret-should-americas-ai-work-be-too-5638be21?st=iepZkH&reflink=desktopwebshare_permalink) 
* [UC Berkeley researchers claim to replicate DeepSeek AI for just $30](https://tribune.net.ph/amp/story/2025/01/31/uc-berkeley-researchers-claim-to-replicate-deepseek-ai-for-30) 
* [DeepSeek stole our tech .... says Open AI](https://youtu.be/hpwoGjpYygI?si=2PzadCwUm1yYWw_P)
* [Microsoft is forming a new unit to study AI's impacts | TechCrunch](https://techcrunch.com/2025/01/31/microsoft-is-forming-a-new-unit-to-study-ais-impacts/) 
* [Oh, I’m sorry, tech bros – did DeepSeek copy your work? I can hardly imagine your distress | Marina Hyde | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/31/tech-bros-deepseek-china-sam-altman-openai) 
* [OpenAI Asking for Tens of Billions in New Investment to "Fund Its Money-Losing business Operations"](https://futurism.com/openai-asking-investment) 
* [The west is already losing the AI arms race | Larry Elliott | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/30/ai-arms-race-china-deepseek) 
* [Another OpenAI Researcher Quits, Calls AI "Terrifying" and a "Risky Gamble" | eWEEK](https://www.eweek.com/news/open-ai-researcher-quits-calls-ai-terrifying/) 
* [The questions the Chinese government doesn’t want DeepSeek AI to answer - Ars Technica](https://arstechnica.com/ai/2025/01/the-questions-the-chinese-government-doesnt-want-deepseek-ai-to-answer/) 
* [Deep Impact](https://www.wheresyoured.at/deep-impact/) 
* [Dario Amodei — On DeepSeek and Export Controls](https://darioamodei.com/on-deepseek-and-export-controls) 
* [OpenAI ‘reviewing’ allegations that its AI models were used to make DeepSeek](https://www.theguardian.com/technology/2025/jan/29/openai-chatgpt-deepseek-china-us-ai-models)  
* [AI and the future of national security](https://blog.google/technology/safety-security/ai-and-the-future-of-national-security/) 
* [OpenAI Furious DeepSeek Might Have Stolen All the Data OpenAI Stole From Us](https://www.404media.co/openai-furious-deepseek-might-have-stolen-all-the-data-openai-stole-from-us/) 
* [DeepSeek advances could heighten safety risk, says ‘godfather’ of AI | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/29/deepseek-artificial-intelligence-ai-safety-risk-yoshua-bengio)
* [What International AI Safety report says on jobs, climate, cyberwar and more | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/29/what-international-ai-safety-report-says-jobs-climate-cyberwar-deepfakes-extinction) 
* [Former OpenAI safety researcher brands pace of AI development ‘terrifying’ | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/28/former-openai-safety-researcher-brands-pace-of-ai-development-terrifying)
* [Is DeepSeek really sending data to China? Let’s decode | VentureBeat](https://venturebeat.com/ai/is-deepseek-really-sending-data-to-china-lets-decode/) 
* [DeepSeek R1 Exposed: Security Flaws in China’s AI Model • KELA Cyber Threat Intelligence](https://www.kelacyber.com/blog/deepseek-r1-security-flaws/) 
* [Zuckerberg Convening Huge "War Rooms" to Figure Out How a Chinese Startup Is Annihilating Meta's AI](https://futurism.com/zuckerberg-war-rooms-meta-ai-deepseek) 
* [The Short Case for Nvidia Stock | YouTube Transcript Optimizer](https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda) 
* [AI Alignment in Practice: What It Means and How to Get It - The New Stack](https://thenewstack.io/ai-alignment-in-practice-what-it-means-and-how-to-get-it/) 
* [OpenAI Developer Seethes at Success of DeepSeek](https://futurism.com/openai-developer-seethes-deepseek) 
* [Experts urge caution over use of Chinese AI DeepSeek](https://www.theguardian.com/technology/2025/jan/28/experts-urge-caution-over-use-of-chinese-ai-deepseek) 
* [DeepSeek: Trump warns of 'wake-up call' for US tech firms - BBC News](https://www.bbc.co.uk/news/articles/c4gpq01rvd4o) 
* [DeepSeek FAQ – Stratechery by Ben Thompson](https://stratechery.com/2025/deepseek-faq/) 
* [The argument against AI agents and unnecessary automation • The Register](https://www.theregister.com/2025/01/27/ai_agents_automate_argument/) 
* [[2501.13011] MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking](https://arxiv.org/abs/2501.13011) 
* [Frontier AI systems have surpassed the self-replicating red line](https://arxiv.org/html/2412.12140v1#abstract)
* [We Aren't Being Told the Real Extent of AI Datacenter Emissions](https://futurism.com/the-byte/not-being-told-datacenter-emissions) 
* [Artificial Intelligence In Health And Health Care: Priorities For Action | Health Affairs](https://goo.gle/3CoOb2y) 
* [Trading inference-time compute for adversarial robustness | OpenAI](https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness/) 
* [There's Apparently a Huge Financial Problem With Trump's Massive AI Project](https://futurism.com/huge-financial-problem-trump-ai-stargate) 
* [[2501.12206] Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model](https://arxiv.org/abs/2501.12206) 
* [More AI, More Problems for Software Developers in 2025 - The New Stack](https://thenewstack.io/more-ai-more-problems-for-software-developers-in-2025/) 
* [Cloud Deployment of AI Models Jumps, Says Data Science Study - The New Stack](https://thenewstack.io/cloud-deployment-of-ai-models-jumps-says-data-science-study/) 
* [Can AI Pass Humanity’s Ultimate Intelligence Test?](https://www.eweek.com/news/can-ai-pass-ultimate-iq-test/) 
* [What happens when we can’t build bigger datacenters anymore? • The Register](https://www.theregister.com/2025/01/24/build_bigger_ai_datacenters/) 
* [Meta's Top AI Lawyer Quits in Disgust](https://futurism.com/the-byte/meta-ai-lawyer-quits) 
* [Trump's Staff Have Had It With Elon Musk's Insubordination](https://futurism.com/the-byte/trump-staff-furious-elon-musk) 
* [Why everyone in AI is freaking out about DeepSeek | VentureBeat](https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek/) 
* [AI Hype Is Dropping Off a Cliff While Costs Soar, Experts Warn](https://futurism.com/the-byte/ai-hype-cliff-costs) 
* [Trump Revokes Biden EO Addressing AI Risks: What It Means](https://www.eweek.com/news/trump-revokes-biden-ai-eo/) 
* [Elon Musk and Sam Altman take to social media to fight over Stargate | TechCrunch](https://techcrunch.com/2025/01/22/elon-musk-and-sam-altman-take-to-social-media-to-fight-over-stargate/) 
* [Banks must keep ahead of risks and reap AI rewards • The Register](https://www.theregister.com/2025/01/21/banks_must_keep_ahead_of/) 
* [UK aims to fix government IT with help from AI Humphrey • The Register](https://www.theregister.com/2025/01/21/ai_humphrey_uk_government/) 
* [The Pentagon says AI is speeding up its 'kill chain' | TechCrunch](https://techcrunch.com/2025/01/19/the-pentagon-says-ai-is-speeding-up-its-kill-chain/)
* [What I've learned about writing AI apps so far | Seldo.com](https://seldo.com/posts/what-ive-learned-about-writing-ai-apps-so-far) 
* [Oscar-Nominated Film Editor’s AI Use Might Cost It the Academy Award](https://www.eweek.com/news/ai-use-might-cost-film-an-oscar/) 
* [AI Mistakes Are Very Different from Human Mistakes - Schneier on Security](https://www.schneier.com/blog/archives/2025/01/ai-mistakes-are-very-different-from-human-mistakes.html) 
* [Share of teens using ChatGPT for schoolwork doubled from 2023 to 2024 | Pew Research Center](https://www.pewresearch.org/short-reads/2025/01/15/about-a-quarter-of-us-teens-have-used-chatgpt-for-schoolwork-double-the-share-in-2023/) 
* [AI isn’t very good at history, new paper finds | TechCrunch](https://techcrunch.com/2025/01/19/ai-isnt-very-good-at-history-new-paper-finds/) 
* [More AI, More Problems for Software Developers in 2025 - The New Stack](https://thenewstack.io/more-ai-more-problems-for-software-developers-in-2025/) 
* [AI benchmarking organization criticized for waiting to disclose funding from OpenAI | TechCrunch](https://techcrunch.com/2025/01/19/ai-benchmarking-organization-criticized-for-waiting-to-disclose-funding-from-openai/)
* [Cringing before the tech giants is no way to make Britain an AI superpower | John Naughton | The Guardian](https://www.theguardian.com/commentisfree/2025/jan/19/cringing-before-the-tech-giants-is-no-way-to-make-britain-an-ai-superpower) 
* [Labour’s investment in AI isn’t as clever as it thinks it is | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/17/labour-investment-in-ai-isnt-as-clever-as-it-thinks-it-is) 
* [Character.AI Is Seeking Partnerships with Media Brands, Despite Still Facing Two Lawsuits over the Welfare of Minor Users](https://futurism.com/character-ai-seeking-partnerships-despite-lawsuits) 
* [Amazon Says All It Needs to Do Before Releasing an AI-Powered Alexa Is to Solve the Giant Engineering Problem That Nobody Else on Earth Has Been Able to Solve](https://futurism.com/amazon-ai-powered-alexa-hallucinations-problem) 
* [Before Apple's AI Went Haywire and Started Making Up Fake News, Its Engineers Warned of Deep Flaws With the Tech](https://futurism.com/the-byte/apple-engineers-ai-deep-flaws) 
* [Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography](https://arxiv.org/pdf/2501.08970) 
* [[2501.08365] Towards Best Practices for Open Datasets for LLM Training](https://arxiv.org/abs/2501.08365) 
* [CEO of AI Music Company Says People Don’t Like Making Music](https://www.404media.co/ceo-of-ai-music-company-says-people-dont-like-making-music/) ( it's obvious why he says this after all it's his business model)
* [[2501.05542] Infecting Generative AI With Viruses](https://arxiv.org/abs/2501.05542) 
* [Amazon races to transplant Alexa’s ‘brain’ with generative AI](https://arstechnica.com/ai/2025/01/amazon-must-solve-hallucination-problem-before-launching-ai-enabled-alexa/) 
* [Lessons from red teaming 100 generative AI products](https://airedteamwhitepapers.blob.core.windows.net/lessonswhitepaper/MS_AIRT_Lessons_eBook.pdf) 
    * [avrix paper -Lessons From Red Teaming 100 Generative AI Products](https://arxiv.org/pdf/2501.07238) 
* [AI Agents Are Here. What Now?](https://huggingface.co/blog/ethics-soc-7) 
* [PM outlines AI Opportunities Action Plan | TechMarketView](https://www.techmarketview.com/ukhotviews/archive/2025/01/13/pm-outlines-ai-opportunities-action-plan)
* [Artificial Intelligence: Plan to 'unleash AI' across UK revealed - BBC News](https://www.bbc.co.uk/news/articles/crr05jykzkxo) ( Not entirely sure when any of this would start realising a ROI )  
* [Generative AI – The Power and the Glory](https://simonwillison.net/2025/Jan/12/generative-ai-the-power-and-the-glory/) 
* [While AI Causes Climate Change, Nvidia Scientist Proposes AI-Powered Firefighting Robots](https://futurism.com/ai-climate-change-wildfires) 
* [Artificial intelligence: 41% of companies worldwide plan to reduce workforces by 2030 due to AI | CNN Business](https://edition.cnn.com/2025/01/08/business/ai-job-losses-by-2030-intl/index.html) 
* [Survey: AI Tools are Increasing Amount of Bad Code Needing to be Fixed - DevOps.com](https://devops.com/survey-ai-tools-are-increasing-amount-of-bad-code-needing-to-be-fixed/) 
* [Code Quality Becomes Even More Vital in the AI Era - The New Stack](https://thenewstack.io/code-quality-becomes-even-more-vital-in-the-ai-era/) 
* [Elon Musk says all human data for AI training ‘exhausted’ | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2025/jan/09/elon-musk-data-ai-training-artificial-intelligence) 
* [CEO Says He Hasn’t Hired Anyone in a Year as He Replaces Human Workers With AI](https://futurism.com/the-byte/klarna-ceo-ai-replacing-workers) 
* [Trolley Problem, Safety Versus Security of Generative AI - SecurityWeek](https://www.securityweek.com/trolley-problem-safety-versus-security-of-generative-ai/) 
* [AI-supported spear phishing fools more than 50% of targets | Malwarebytes](https://www.malwarebytes.com/blog/news/2025/01/ai-supported-spear-phishing-fools-more-than-50-of-targets) 
* [Not even OpenAI's $200/mo ChatGPT Pro plan can turn a profit • The Register](https://www.theregister.com/2025/01/06/altman_gpt_profits/) 
* [AI Domination: Remote Controlling ChatGPT ZombAI Instances · Embrace The Red](https://embracethered.com/blog/posts/2025/spaiware-and-chatgpt-command-and-control-via-prompt-injection-zombai/) 
* [‘Virtual employees’ could join workforce as soon as this year, OpenAI boss says | Technology sector | The Guardian](https://www.theguardian.com/business/2025/jan/06/virtual-employees-could-join-workforce-as-soon-as-this-year-openai-boss-says) 
* [Meta's AI Profiles Are Indistinguishable From Terrible Spam That Took Over Facebook](https://www.404media.co/metas-ai-profiles-are-indistinguishable-from-terrible-spam-that-took-over-facebook/)
* [Apple opts everyone into having their Photos analyzed by AI • The Register](https://www.theregister.com/2025/01/03/apple_enhanced_visual_search/) 
* [Why AI Did Not Upend the Super Year of Elections | Lawfare](https://www.lawfaremedia.org/article/why-ai-did-not-upend-the-super-year-of-elections) 
* [People Are Disgusted by Facebook’s Plan to Deploy AI-Powered “Users”](https://futurism.com/disgusted-facebook-ai-users)
