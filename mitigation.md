# Categories

[In the wild](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#in-the-wild-in-the-wild)

[Regulating AI/Advisories](https://github.com/grapesfrog/GAI-is-going-well/blob/main/regulate-ai.md#regulating-ai--advisories-regulating-ai-advisories)

[Opinions , Research & presentations ](https://github.com/grapesfrog/GAI-is-going-well/blob/main/opinion.md#opinions--research--presentations-opinions-research--presentations)

[Mitigations & tooling](https://github.com/grapesfrog/GAI-is-going-well/blob/main/mitigation.md#mitigations--tooling-mitigations--tooling)

## Mitigations & tooling {#mitigations-&-tooling}

[2024 articles](https://github.com/grapesfrog/GAI-is-going-well/blob/main/2024/mitigation.md#mitigations--tooling-mitigations--tooling)

* [Using NIM Guardrails To Keep Agentic AI From Jumping To Wrong Conclusions](https://www.nextplatform.com/2025/01/16/using-nim-guardrails-to-keep-agentic-ai-from-jumping-to-wrong-conclusions/) 
* [GitHub - vectara/hallucination-leaderboard: Leaderboard Comparing LLM Performance at Producing Hallucinations when Summarizing Short Documents](https://github.com/vectara/hallucination-leaderboard) 
* [Getting Started With CodeGate, an Intermediary for LLM Devs - The New Stack](https://thenewstack.io/getting-started-with-codegate-an-intermediary-for-llm-devs/)
* [[2403.12196] Leveraging Large Language Models to Detect npm Malicious Packages](https://arxiv.org/abs/2403.12196)