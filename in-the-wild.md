# Categories
[In the wild](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#in-the-wild-in-the-wild)

[Regulating AI/Advisories](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#regulating-ai--advisories-regulating-ai-advisories)

[Opinions , Research & presentations ](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#opinions--research--presentations-opinions-research--presentations)

[Mitigations & tooling](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md#mitigations--tooling-mitigations--tooling)

## In the wild {#in-the-wild}

* [Samsung workers made a major error by using ChatGPT | TechRadar](https://www.techradar.com/news/samsung-workers-leaked-company-secrets-by-using-chatgpt)
* [Samsung finds data leak due to use of ChatGPT: Korean media - CGTN](https://news.cgtn.com/news/2023-04-03/Samsung-finds-data-leak-due-to-use-of-ChatGPT-Korean-media-1iHSzPcMDEk/index.html)
* [Air Canada's chatbot gave a B.C. man the wrong information. Now, the airline has to pay for the mistake](https://bc.ctvnews.ca/air-canada-s-chatbot-gave-a-b-c-man-the-wrong-information-now-the-airline-has-to-pay-for-the-mistake-1.6769454)
* [Air Canada must pay after chatbot lies to grieving passenger • The Register](https://www.theregister.com/2024/02/15/air_canada_chatbot_fine/)
* [https://boingboing.net/2024/02/15/man-fined-for-scratching-his-head.html](https://boingboing.net/2024/02/15/man-fined-for-scratching-his-head.html)
* [https://www.theregister.com/2024/02/17/ai_models_weaponized/](https://www.theregister.com/2024/02/17/ai_models_weaponized/)
* [https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination](https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination)
* [Can you trust ChatGPT’s package recommendations?](https://vulcan.io/blog/ai-hallucinations-package-risk)
* [Prompt injection: What’s the worst that can happen?](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)
* [Organizational Risk to Using Generative AI: Hallucinations in LLM Chatbots](https://www.eisneramper.com/insights/blogs/digital-blog/artificial-intelligence-chatbot-hallucinations-di-blog-1023/)
* [https://simonwillison.net/2023/May/27/lawyer-chatgpt/](https://simonwillison.net/2023/May/27/lawyer-chatgpt/)
* [A lawyer faces sanctions after he used ChatGPT to write a brief riddled with fake citations](https://www.google.com/amp/s/www.engadget.com/amp/a-lawyer-faces-sanctions-after-he-used-chatgpt-to-write-a-brief-riddled-with-fake-citations-175720636.html)
* [Can you trust ChatGPT’s package recommendations?](https://vulcan.io/blog/ai-hallucinations-package-risk)
* [Twitter pranksters derail GPT-3 bot with newly discovered “prompt injection” hack | Ars Technica](https://arstechnica.com/information-technology/2022/09/twitter-pranksters-derail-gpt-3-bot-with-newly-discovered-prompt-injection-hack/)  
* [AI-generated naked child images shock Spanish town of Almendralejo - BBC News](https://www.bbc.co.uk/news/world-europe-66877718)
* [AI image training dataset found to include child sexual abuse imagery - The Verge](https://www.theverge.com/2023/12/20/24009418/generative-ai-image-laion-csam-google-stability-stanford)
* [https://www.bbc.co.uk/news/technology-68025677](https://www.bbc.co.uk/news/technology-68025677)
* [https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/](https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/)
* [Hacking Auto-GPT and escaping its docker container | Positive Security](https://positive.security/blog/auto-gpt-rce)
* [https://www.wired.com/story/openai-custom-chatbots-gpts-prompt-injection-attacks/](https://www.wired.com/story/openai-custom-chatbots-gpts-prompt-injection-attacks/)
* [https://uk.pcmag.com/ai/147755/wormgpt-is-a-chatgpt-alternative-with-no-ethical-boundaries-or-limitationsCriminals Have Created Their Own ChatGPT Clones | WIRED](https://uk.pcmag.com/ai/147755/wormgpt-is-a-chatgpt-alternative-with-no-ethical-boundaries-or-limitations)
* [PoisonGPT: How to poison LLM supply chainon Hugging Face](https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/)
* [Incident 554: Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result](https://incidentdatabase.ai/cite/554/#r3172)
* [Hugging Face dodged a cyber-bullet with Lasso Security's help | VentureBeat](https://venturebeat.com/security/hugging-face-dodged-a-cyber-bullet-with-lasso-securitys-help/)
* [AI Voice Generators Are Fueling a Terrifying New Phone Scam](https://www.businessinsider.com/ai-voice-generator-phone-scam-imposter-crime-money-cash-2023-6)
* [https://futurism.com/bankrate-ai-generated-article-errors](https://futurism.com/bankrate-ai-generated-article-errors)
* [Disrupting malicious uses of AI by state-affiliated threat actors | OpenAI](https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors)
* [The text file that runs the internet](https://www.theverge.com/24067997/robots-txt-ai-text-file-web-crawlers-spiders)
* [AI Is Writing Books About Foraging. What Could Go Wrong? | Civil Eats](https://civileats.com/2023/10/10/ai-is-writing-books-about-foraging-what-could-go-wrong/)
* [https://www.theguardian.com/technology/2023/dec/20/ai-image-generators-child-sexual-abuse](https://www.theguardian.com/technology/2023/dec/20/ai-image-generators-child-sexual-abuse?CMP=Share_AndroidApp_Other)
* [Microsoft’s legal department allegedly silenced an engineer who raised concerns about DALL-E 3](https://www.engadget.com/microsofts-legal-department-allegedly-silenced-an-engineer-who-raised-concerns-about-dall-e-3-215953212.html)
* [Zoom Updates Terms to Use Customer Data for AI Training With No Opt-Out [Updated]](https://www.webpronews.com/zoom-updates-terms-to-use-customer-data-for-ai-training-with-no-opt-out/) Zoom did later clarify
* [Leaked email shows Adobe banning employee use of personal email accounts and corporate credit cards for generative AI apps](https://www.businessinsider.com/adobe-rules-how-use-chatgpt-generative-ai-apps-at-work-2023-7)
* [Amazon, Apple, and 12 other major companies that have restricted employees from using ChatGPT](https://www.businessinsider.com/chatgpt-companies-issued-bans-restrictions-openai-ai-amazon-apple-2023-7)
* [https://www.windowscentral.com/software-apps/chatgpt-pauses-bing-integration-to-stop-people-from-bypassing-paywalls](https://www.windowscentral.com/software-apps/chatgpt-pauses-bing-integration-to-stop-people-from-bypassing-paywalls)
* [Will ChatGPT write ransomware? Yes. | Malwarebytes](https://www.malwarebytes.com/blog/news/2023/11/will-chatgpt-write-ransomware-yes/amp)
* [Deepfake scammer walks off with $25 million in first-of-its-kind AI heist | Ars Technica](https://arstechnica.com/information-technology/2024/02/deepfake-scammer-walks-off-with-25-million-in-first-of-its-kind-ai-heist/)
* [AI-assisted bug reports make developers bear cost of cleanup • The Register](https://www.theregister.com/2024/01/04/aiassisted_bug_reports_make_developers/)
* [Top Google Result for "Edward Hopper" an AI-Generated Fake](https://futurism.com/top-google-result-edward-hopper-ai-generated-fake)
* [Data poisoning: how artists are sabotaging AI to take revenge on image generators](https://theconversation.com/data-poisoning-how-artists-are-sabotaging-ai-to-take-revenge-on-image-generators-219335)
* [https://arstechnica.com/security/2024/01/ars-reader-reports-chatgpt-is-sending-him-conversations-from-unrelated-ai-users/](https://arstechnica.com/security/2024/01/ars-reader-reports-chatgpt-is-sending-him-conversations-from-unrelated-ai-users/)
* [Funnily enough, AI models must follow privacy law – including right to be forgotten](https://www.theregister.com/2023/07/13/ai_models_forgotten_data/)
* [OpenAI says there’s only a small chance ChatGPT will help create bioweapons - The Verge](https://www.theverge.com/2024/2/1/24058095/open-ai-bioweapon-study-preparedness-team)
* [https://embracethered.com/blog/posts/2024/lack-of-isolation-gpts-code-interpreter/](https://embracethered.com/blog/posts/2024/lack-of-isolation-gpts-code-interpreter/)
* [https://www.theverge.com/2024/2/14/24072706/microsoft-openai-cyberattack-tools-ai-chatgpt](https://www.theverge.com/2024/2/14/24072706/microsoft-openai-cyberattack-tools-ai-chatgpt)
* [Generative AI Has a Visual Plagiarism Problem](https://spectrum-ieee-org.cdn.ampproject.org/c/s/spectrum.ieee.org/amp/midjourney-copyright-2666872100)
* [https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/](https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/)
* [Paper Retracted When Authors Caught Using ChatGPT to Write It](https://futurism.com/the-byte/paper-retracted-authors-used-chatgpt)
* [https://futurism.com/ai-ripped-off-reporting-ripoffs](https://futurism.com/ai-ripped-off-reporting-ripoffs)
* [ChatGPT goes temporarily “insane” with unexpected outputs, spooking users | Ars Technica](https://arstechnica.com/information-technology/2024/02/chatgpt-alarms-users-by-spitting-out-shakespearean-nonsense-and-rambling/)
* [Google apologizes for ‘missing the mark’ after Gemini generated racially diverse Nazis - The Verge](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)
* [Google to fix AI picture bot after 'woke' criticism - BBC News](https://www.bbc.co.uk/news/business-68364690)
* [Piers Morgan and Oprah Winfrey 'deepfaked' for US influencer's ads - BBC News](https://www.bbc.co.uk/news/technology-67703018)
* [Judge not okay with law firm using ChatGPT to justify fees • The Register](https://www.theregister.com/2024/02/24/chatgpt_cuddy_legal_fees/)
* [https://www.newscientist.com/article/2418188-deepfakes-are-out-of-control-is-it-too-late-to-stop-them](https://www.newscientist.com/article/2418188-deepfakes-are-out-of-control-is-it-too-late-to-stop-them)
* [https://arstechnica.com/information-technology/2024/02/cops-called-after-parents-get-tricked-by-ai-generated-images-of-wonka-like-event/](https://arstechnica.com/information-technology/2024/02/cops-called-after-parents-get-tricked-by-ai-generated-images-of-wonka-like-event/)
* [New Hugging Face Vulnerability Exposes AI Models to Supply Chain Attacks](https://thehackernews.com/2024/02/new-hugging-face-vulnerability-exposes.html?m=1)
* [Why Google's 'woke' AI problem won't be an easy fix - BBC News](https://www.bbc.co.uk/news/technology-68412620)
* [China rules that an AI bot infringed copyrighted material | Semafor](https://www.semafor.com/article/02/27/2024/new-china-rules-that-an-ai-bot-infringed-protected-material)
* [Users Say Microsoft's AI Has Alternate Personality as Godlike AGI That Demands to Be Worshipped](https://futurism.com/microsoft-copilot-alter-egos)
* [Michael Cohen says he unwittingly sent AI-generated fake legal cases to his attorney](https://www.npr.org/2023/12/30/1222273745/michael-cohen-ai-fake-legal-cases)
* [AI-generated articles prompt Wikipedia to downgrade CNET’s reliability rating | Ars Technica](https://arstechnica.com/information-technology/2024/02/wikipedia-downgrades-cnets-reliability-rating-after-ai-generated-articles/)
* [Canada lawyer under fire for submitting fake cases created by AI chatbot](https://www.theguardian.com/world/2024/feb/29/canada-lawyer-chatgpt-fake-cases-ai)
* [Hugging Face, the GitHub of AI, hosted code that backdoored user devices | Ars Technica](https://arstechnica.com/security/2024/03/hugging-face-the-github-of-ai-hosted-code-that-backdoored-user-devices/)
* [Latest ChatGPT lawsuits highlight backup legal theory against AI platforms | Reuters](https://www.reuters.com/legal/transactional/column-latest-chatgpt-lawsuits-highlight-backup-legal-theory-against-ai-2024-02-29/)
* [Microsoft Copilot Tells User Suicide Is an Option](https://futurism.com/the-byte/microsoft-copilot-user-suicide)
* [Who Am I? Conditional Prompt Injection Attacks with Microsoft Copilot · Embrace The Red](https://embracethered.com/blog/posts/2024/whoami-conditional-prompt-injection-instructions/)
* [Trump supporters target black voters with faked AI images - BBC News](https://www.bbc.co.uk/news/world-us-canada-68440150)
* [I Used Resume Spammers to Apply for 120 Jobs. Chaos Ensued.](https://www.businessinsider.com/job-applications-hiring-ai-bots-spam-resume-cover-letter-2024-3?utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Insider%20Today,%20March%205,%202024&r=US&IR=T)
* [La minute insolite : il utilise ChatGPT pour obtenir 100 repas gratuits chez McDonald's - RTBF Actus](https://www.rtbf.be/article/la-minute-insolite-il-utilise-chatgpt-pour-obtenir-100-repas-gratuits-chez-mcdonald-s-11339451)
* [Generative A.I - We Aren’t Ready.](https://www.youtube.com/watch?v=JrcbH0ge2WE)
* [Thanks to AI, the coder is no longer king: All hail the QA engineer](https://www.fastcompany.com/91045570/thanks-to-ai-the-coder-is-no-longer-king-all-hail-the-qa-engineer)
* [Copilot image generation a problem, says Microsoft engineer • The Register](https://www.theregister.com/2024/03/06/microsoft_copilots_images/)
* [New AI Claude 3 Declares That It's Alive and Fears Death](https://futurism.com/new-ai-claude-3-outbursts)
* [Florida Middle Schoolers Arrested for Allegedly Creating Deepfake Nudes of Classmates | WIRED](https://www.wired.com/story/florida-teens-arrested-deepfake-nudes-classmates/)
* [Microsoft's Copilot now blocks some prompts that generated violent and sexual images](https://www.engadget.com/microsofts-copilot-now-blocks-some-prompts-that-generated-violent-and-sexual-images-213859041.html?src=rss)
* [Midjourney bans all Stability AI employees over alleged data scraping - The Verge](https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage)
* [AI models exhibit racism based on written dialect • The Register](https://www.theregister.com/2024/03/11/ai_models_exhibit_racism_based/)
* [TurboTax Adds AI That Gives Horribly Wrong Answers to Tax Questions](https://futurism.com/the-byte/turbotax-hrblock-ai-chatbots)
* [Hackers can read private AI assistant chats even though they’re encrypted | Ars Technica](https://arstechnica.com/security/2024/03/hackers-can-read-private-ai-assistant-chats-even-though-theyre-encrypted/#p3)
* [SEO Guy Mocks Google for Deindexing His "Gibberish" AI Sites](https://futurism.com/seo-google-gibberish-ai)
* [Scientists Caught Generating “Academic Papers” Using ChatGPT](https://futurism.com/the-byte/scientists-papers-ai)
* [Google's AI Search Caught Pushing Users to Download Malware](https://futurism.com/the-byte/google-ai-search-spam-malware)
* [Ray AI Framework Vulnerability Exploited to Hack Hundreds of Clusters - SecurityWeek](https://www.securityweek.com/attackers-exploit-ray-ai-framework-vulnerability-to-hack-hundreds-of-clusters/)
* [https://www.oligo.security/blog/shadowray-attack-ai-workloads-actively-exploited-in-the-wild](https://www.oligo.security/blog/shadowray-attack-ai-workloads-actively-exploited-in-the-wild)
* [OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows](https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/)
* [Microsoft Copilot has reportedly been blocked on all Congress-owned devices](https://www.engadget.com/microsoft-copilot-has-reportedly-been-blocked-on-all-congress-owned-devices-034946166.html)
* [https://arstechnica.com/ai/2024/03/nycs-government-chatbot-is-lying-about-city-laws-and-regulations/](https://arstechnica.com/ai/2024/03/nycs-government-chatbot-is-lying-about-city-laws-and-regulations/)
* [NYC’s AI Chatbot Tells Businesses to Break the Law – The Markup](https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law)
* [https://arstechnica.com/information-technology/2024/03/openai-holds-back-wide-release-of-voice-cloning-tech-due-to-misuse-concerns/](https://arstechnica.com/information-technology/2024/03/openai-holds-back-wide-release-of-voice-cloning-tech-due-to-misuse-concerns/)
* [https://www-theregister-com.cdn.ampproject.org/c/s/www.theregister.com/AMP/2024/03/28/ai_bots_hallucinate_software_packages/](https://www-theregister-com.cdn.ampproject.org/c/s/www.theregister.com/AMP/2024/03/28/ai_bots_hallucinate_software_packages/)
* [Diving Deeper into AI Package Hallucinations](https://www.lasso.security/blog/ai-package-hallucinations)
* [[2404.01268] Mapping the Increasing Use of LLMs in Scientific Papers](https://arxiv.org/abs/2404.01268)
* [Meta’s AI image generator can’t imagine an Asian man with a white woman - The Verge](https://www.theverge.com/2024/4/3/24120029/instagram-meta-ai-sticker-generator-asian-people-racism)
* [After AI-generated porn report, Washington Lottery pulls down interactive web app | Ars Technica](https://arstechnica.com/ai/2024/04/after-ai-generated-porn-report-washington-lottery-pulls-down-interactive-web-app/)
* [Report: Israel used AI tool called Lavender to choose targets in Gaza - The Verge](https://www.theverge.com/2024/4/4/24120352/israel-lavender-artificial-intelligence-gaza-ai)
* [https://www.bloomberg.com/news/articles/2024-04-04/youtube-says-openai-training-sora-with-its-videos-would-break-the-rules](https://www.bloomberg.com/news/articles/2024-04-04/youtube-says-openai-training-sora-with-its-videos-would-break-the-rules)
* [Google Books reportedly indexing bad AI-written works - The Verge](https://www.theverge.com/2024/4/5/24122077/google-books-ai-indexing-ngram)
* [Google AI Studio Data Exfiltration via Prompt Injection - Possible Regression and Fix · Embrace The Red](https://embracethered.com/blog/posts/2024/google-aistudio-mass-data-exfil/)  
* [AI-Powered Camera Takes Pictures of People But Instantly Makes Them Naked](https://futurism.com/the-byte/ai-powered-camera-pictures-people-naked)
* [AI spam is winning the battle against search engine quality • The Register](https://www.theregister.com/2024/04/13/google_ai_spam/)
* [Bobby Tables but with LLM Apps - Google NotebookLM Data Exfiltration · Embrace The Red](https://embracethered.com/blog/posts/2024/google-notebook-ml-data-exfiltration/)
* [Meta’s oversight board to probe subjective policy on AI sex image removals | Ars Technica](https://arstechnica.com/tech-policy/2024/04/metas-oversight-board-to-probe-subjective-policy-on-ai-sex-image-removals/)
* [UK court bans convicted sex offender from using generative AI - Boing Boing](https://boingboing.net/2024/04/23/uk-court-bans-convicted-sex-offender-from-using-generative-ai.html)  
* [School athletic director arrested for framing principal using AI voice synthesis | Ars Technica](https://arstechnica.com/information-technology/2024/04/alleged-ai-voice-imitation-leads-to-arrest-in-baltimore-school-racism-controversy/)
* [Excessive use of words like ‘commendable’ and ‘meticulous’ suggests ChatGPT has been used in thousands of scientific studies | Science | EL PAÍS English](https://english.elpais.com/science-tech/2024-04-25/excessive-use-of-words-like-commendable-and-meticulous-suggest-chatgpt-has-been-used-in-thousands-of-scientific-studies.html#)
* [Meta’s ‘set it and forget it’ AI ad tools are misfiring and blowing through cash - The Verge](https://www.theverge.com/2024/4/28/24141585/meta-ai-advantage-plus-automated-ad-glitch-cpm)
* [OpenAI hit with another privacy complaint over ChatGPT’s love of making stuff up](https://www.engadget.com/openai-hit-with-another-privacy-complaint-over-chatgpts-love-of-making-stuff-up-162250335.html?src=rss)
* [Developers seethe as Google surfaces buggy AI-written code • The Register](https://www.theregister.com/2024/05/01/pulumi_ai_pollution_of_search/)
* [Artists Sue Google Over Its AI Image Generator](https://futurism.com/the-byte/artists-sue-google-image-generator)
* [AI Catholic 'priest' defrocked over interesting advice](https://www.theregister.com/2024/05/03/ai_catholic_priest/)
* [AI Chatbots Have Thoroughly Infiltrated Scientific Publishing](https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/)
* [Met Gala: BBC Verify examines fake Katy Perry AI-generated image - BBC News](https://www.bbc.co.uk/news/world-68973448)
* [Researchers Uncover 'LLMjacking' Scheme Targeting Cloud-Hosted AI Models](https://thehackernews.com/2024/05/researchers-uncover-llmjacking-scheme.html)
* [https://arstechnica.com/information-technology/2024/05/stack-overflow-users-sabotage-their-posts-after-openai-deal/](https://arstechnica.com/information-technology/2024/05/stack-overflow-users-sabotage-their-posts-after-openai-deal/)
* [AI bots hallucinate software packages and devs download them • The Register](https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/)
* [AI red-teaming tools helped X-Force break into a major tech manufacturer 'in 8 hours'](https://www.theregister.com/2024/05/13/ai_xforce_red_penetration/)
* [FKA Twigs uses AI to create deepfake of herself - BBC News](https://www.bbc.co.uk/news/articles/c6py33gxk74o)
* [Company "Sheepishly" Admits Its Employee Handbook Was Generated With ChatGPT, Doesn’t Have Anti-Harassment Policy](https://futurism.com/the-byte/company-sheepishly-admits-handbook-chatgpt)
* [Google’s Gemini video search makes factual error in demo - The Verge](https://www.theverge.com/2024/5/14/24156729/googles-gemini-video-search-makes-factual-error-in-demo)
* [How AI turned a Ukrainian YouTuber into a Russian - BBC News](https://www.bbc.co.uk/news/articles/c25rre8ww57o)
* [Sony Music slams tech giants for unauthorised use of stars' songs](https://www.bbc.co.uk/news/articles/c0434yx8vgxo)
* [Wiley shuts 19 scholarly journals amid AI paper mill problem • The Register](https://www.theregister.com/2024/05/16/wiley_journals_ai/)
* [https://www.engadget.com/yuck-slack-has-been-scanning-your-messages-to-train-its-ai-models-181918245.html](https://www.engadget.com/yuck-slack-has-been-scanning-your-messages-to-train-its-ai-models-181918245.html)
* [https://www.theguardian.com/technology/article/2024/may/17/ai-weapons-palantir-war-technology](https://www.theguardian.com/technology/article/2024/may/17/ai-weapons-palantir-war-technology)
* [https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2024/05/17/1092649/gpt-4o-chinese-token-polluted/amp/](https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2024/05/17/1092649/gpt-4o-chinese-token-polluted/amp/)
* [https://ukdefencejournal.org.uk/surge-of-chatgpt-powered-twitter-bots-target-defence/](https://ukdefencejournal.org.uk/surge-of-chatgpt-powered-twitter-bots-target-defence/)
* [ChatGPT: Scarlett Johansson left 'angered' by chatbot imitation](https://www.bbc.com/news/articles/cm559l5g529o)
* [Sam Altman Ignoring Scarlett Johansson's Lack of Consent Shows Us Exactly What Type of Person He Really Is](https://futurism.com/sam-altman-openai-scarlett-johansson)
* [Why OpenAI should fear a Scarlett Johansson lawsuit | CNN Business](https://edition.cnn.com/2024/05/22/tech/openai-scarlett-johansson-lawsuit-sam-altman/index.html)
* [Google’s Search AI Recommends Changing Your Car’s Blinker Fluid, Which Is a Made Up Thing That Does Not Exist](https://futurism.com/the-byte/googles-search-ai-recommends-blinker-fluid)
* [Wearable AI Pin maker Humane is reportedly seeking a buyer](https://www.engadget.com/wearable-ai-pin-maker-humane-is-reportedly-seeking-a-buyer-035322167.html?src=rss)
* [ChatGPT: Hacking Memories with Prompt Injection · Embrace The Red](https://embracethered.com/blog/posts/2024/chatgpt-hacking-memories/)
* [https://futurism.com/the-byte/study-chatgpt-answers-wrong](https://futurism.com/the-byte/study-chatgpt-answers-wrong)
* [Gemini is the new Google+ – Computerworld](https://www.computerworld.com/article/2117752/google-gemini-ai.html)
* [Michael Schumacher’s family win case against publisher over fake AI interview](https://www.theguardian.com/sport/article/2024/may/23/michael-schumacher-family-win-legal-case-against-publisher-over-fake-ai-interview)
* [The risk in malicious AI models: Wiz Research discovers critical vulnerability in AI-as-a-Service provider, Replicate](https://www.wiz.io/blog/wiz-research-discovers-critical-vulnerability-in-replicate)
* [While Meta Stuffs AI Into All Its Products, It's Apparently Helpless to Stop Perverts on Instagram From Publicly Lusting Over Sexualized AI-Generated Children](https://futurism.com/ai-perverts-instagram)
* [Google’s “AI Overview” can give false, misleading, and dangerous answers | Ars Technica](https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/)
* [Automatic Tool Invocation when Browsing with ChatGPT - Threats and Mitigations · Embrace The Red](https://embracethered.com/blog/posts/2024/llm-apps-automatic-tool-invocations/)
* [Even Google’s Own Researchers Admit AI Is Top Source of Misinformation Online](https://futurism.com/google-ai-top-source-misinformation)
* [[2405.11697] AMMeBa: A Large-Scale Survey and Dataset of Media-Based Misinformation In-The-Wild](https://arxiv.org/abs/2405.11697)
* [Using AI in science can add to reproducibility woes, say boffins](https://www.theregister.com/2024/05/29/using_ai_in_science_can/)
* [Hacker Releases Jailbroken "Godmode" Version of ChatGPT](https://futurism.com/hackers-jailbroken-chatgpt-godmode)
* [Winnipeg man caught in scam after AI told him fake Facebook customer support number was legitimate | CBC News](https://www.cbc.ca/news/canada/manitoba/facebook-customer-support-scam-1.7219581)
* [Google finally addresses those bizarre AI search results • The Register](https://www.theregister.com/2024/05/31/google_ai_search_update/)
* [Meta’s AI is summarizing some bizarre Facebook comment sections - The Verge](https://www.theverge.com/2024/5/31/24168802/meta-ai-facebook-comments-summaries)
* [Bubble.ai | No Mercy / No Malice](https://www.profgalloway.com/bubble-ai/)
* [AI's Rapid Growth Threatens Big Tech's Clean Energy Efforts](https://oilprice-com.cdn.ampproject.org/v/s/oilprice.com/Energy/Energy-General/AIs-Rapid-Growth-Threatens-Big-Techs-Clean-Energy-Efforts.amp.html?amp_gsa=1&amp_js_v=a9&usqp=mq331AQGsAEggAID#amp_tf=From%20%251%24s&aoh=17173910039872&csi=0&referrer=https%3A%2F%2Fwww.google.com&ampshare=https%3A%2F%2Foilprice.com%2FEnergy%2FEnergy-General%2FAIs-Rapid-Growth-Threatens-Big-Techs-Clean-Energy-Efforts.html)
* [Plans to use Facebook and Instagram posts to train AI criticised - BBC News](https://www.bbc.co.uk/news/articles/cw99n3qjeyjo)
* [Popular US news app accused of using AI to make up fake stories](https://www.engadget.com/popular-us-news-app-accused-of-using-ai-to-make-up-fake-stories-140016882.html?src=rss)
* [Microsoft Sued For AI Article Accusing Innocent Man of Sexual Misconduct](https://futurism.com/microsoft-sued-ai-article)
* [Microsoft’s Recall Feature Is Even More Hackable Than You Thought | WIRED](https://www.wired.com/story/microsoft-windows-recall-privilege-escalation/)
* [OpenAI takes action against misuse of its models in propaganda](https://hubs.la/Q02B0BG50)
* [Popular News App Caught Publishing Completely Untrue AI Articles](https://futurism.com/the-byte/news-app-untrue-ai-articles)
* * [X removes accounts of network smearing politicians with deepfakes](https://www.bbc.com/news/articles/cq55gd8559eo)
* [AI chatbots are intruding into online communities where people are trying to connect with other humans](https://theconversation.com/ai-chatbots-are-intruding-into-online-communities-where-people-are-trying-to-connect-with-other-humans-229473)
* [AI chatbots got questions about the 2024 election wrong 27% of the time, study finds](https://www.nbcnews.com/tech/tech-news/ai-chatbots-got-questions-2024-election-wrong-27-time-study-finds-rcna155640)
* [AI-as-a-Service Providers Vulnerable to PrivEsc and Cross-Tenant Attacks](https://thehackernews.com/2024/04/ai-as-service-providers-vulnerable-to.html?m=1)
* [Hackers Target AI Users With Malicious Stable Diffusion Tool on Github to Protest 'Art Theft'](https://www.404media.co/hackers-target-ai-users-with-malicious-stable-diffusion-tool-on-github/)
* [Google still recommends glue for your pizza - The Verge](https://www.theverge.com/2024/6/11/24176490/mm-delicious-glue)
* [No AI training in newly distrusted Terms of Service, Adobe says | Malwarebytes](https://www.malwarebytes.com/blog/news/2024/06/no-ai-training-in-newly-distrusted-terms-of-service-adobe-says)
* [The Chinese women turning to ChatGPT for AI boyfriends - BBC Website](https://www.bbc.com/articles/c4nnje9rpjgo)
* [AI Is Being Trained on Images of Real Kids Without Consent](https://futurism.com/ai-trained-images-kids)
* [Concern rises over AI in adult entertainment - BBC News](https://www.bbc.co.uk/news/articles/c2qqxqgp9yno) 
* [Child predators are using AI to create sexual images of their favorite ‘stars’: ‘My body will never be mine again’ | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/article/2024/jun/12/predators-using-ai-generate-child-sexual-images)
* [New Stable Diffusion 3 release excels at AI-generated body horror | Ars Technica](https://arstechnica.com/information-technology/2024/06/ridiculed-stable-diffusion-3-release-excels-at-ai-generated-body-horror/)
* [Photographer takes on the machines in AI competition – and wins | Photography | The Guardian](https://www.theguardian.com/artanddesign/article/2024/jun/13/photographer-takes-on-the-machines-in-ai-competition-and-wins?CMP=Share_AndroidApp_Other)
* [Companies Find That AI Projects Have Had "Dismal" Financial Results](https://futurism.com/the-byte/companies-ai-projects-financial-results)
* [Microsoft Delaying Recall Feature to Improve Security - SecurityWeek](https://www.securityweek.com/microsoft-delaying-recall-feature-to-improve-security/)
* [ChatGPT Is Hallucinating Fake Article Links by One of Its Publishing Partners](https://futurism.com/the-byte/chatgpt-hallucinating-fake-links-business-insider)
* [GitHub Copilot Chat: From Prompt Injection to Data Exfiltration](https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/)

## Regulating AI / Advisories {#regulating-ai-advisories}

* [Artificial Intelligence, Machine Learning and Big Data in Finance: Opportunities, Challenges, and Implications for Policy Makers](https://www.oecd.org/finance/financial-markets/Artificial-intelligence-machine-learning-big-data-in-finance.pdf)
* [Frontier AI: capabilities and risks – discussion paper - GOV.UK](https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper)
* [Safety and Security Risks of Generative Artificial Intelligence to 2025 - GOV.UK](https://assets.publishing.service.gov.uk/media/653932db80884d0013f71b15/generative-ai-safety-security-risks-2025-annex-b.pdf)
* [Capabilities and risks from frontier AI - GOV.UK](https://assets.publishing.service.gov.uk/media/65395abae6c968000daa9b25/frontier-ai-capabilities-risks-report.pdf)
* [Salesforce study shows UK workers adopting AI remain wary of risks - Techzine Europe](https://www.techzine.eu/news/applications/108333/salesforce-study-shows-uk-workers-adopting-ai-remain-wary-of-risks/)
* [ChatGPT maker OpenAI faces a lawsuit over how it used people's data](https://www.washingtonpost.com/technology/2023/06/28/openai-chatgpt-lawsuit-class-action/)
* [Urgent need for terrorism AI laws, warns think tank - BBC News](https://www.bbc.co.uk/news/technology-67872767)
* [https://committees.parliament.uk/publications/43172/documents/214762/default/](https://committees.parliament.uk/publications/43172/documents/214762/default/)
* [Global ransomware threat expected to rise with AI, NCSC warns](https://www.ncsc.gov.uk/news/global-ransomware-threat-expected-to-rise-with-ai)
* [Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4694565)
* [Towards best practices in AGI safety and governance: A survey of expert opinion](https://arxiv.org/pdf/2305.07153.pdf)
* [White House could force cloud companies to disclose AI customers | Semafor](https://www.semafor.com/article/09/22/2023/white-house-could-force-cloud-companies-to-disclose-ai-customers)
* [UK publishers urge Sunak to protect works ingested by AI models](https://www.theguardian.com/books/2023/aug/31/uk-publishers-association-ai-models-sunak)
* [Why The New York Times might win its copyright lawsuit against OpenAI | Ars Technica](https://arstechnica.com/tech-policy/2024/02/why-the-new-york-times-might-win-its-copyright-lawsuit-against-openai/)
* [India reverses AI stance, requires government approval for model launches | TechCrunch](https://techcrunch.com/2024/03/03/india-reverses-ai-stance-requires-government-approval-for-model-launches/)
* [AOC Announces Bill That Would Let Women Sue People Who Make Deepfake Porn of Them](https://futurism.com/the-byte/aoc-bill-deepfake-porn)
* [Google says the AI-focused Pixel 8 can’t run its latest smartphone AI models | Ars Technica](https://arstechnica.com/gadgets/2024/03/google-says-the-ai-focused-pixel-8-cant-run-its-latest-smartphone-ai-models/#p3)
* [MEPs approve world's first comprehensive AI law - BBC News](https://www.bbc.co.uk/news/technology-68546450)
* [MeitY approval must for companies to roll out AI, generative AI models - The Economic Times](https://economictimes.indiatimes.com/tech/technology/govt-directs-social-media-generative-ai-platforms-to-comply-with-it-rules/articleshow/108162287.cms)
* [UN Adopts Resolution Backing Efforts to Ensure Artificial Intelligence is Safe - SecurityWeek](https://www.securityweek.com/un-adopts-resolution-backing-efforts-to-ensure-artificial-intelligence-is-safe/)
* [Google fined €250m in France for breaching intellectual property deal](https://www.theguardian.com/technology/2024/mar/20/google-fined-250m-euros-in-france-for-breaching-intellectual-property-rules)
* [https://blog.stackaware.com/p/sec-rule-ai-asset-inventory-governance-procedure](https://blog.stackaware.com/p/sec-rule-ai-asset-inventory-governance-procedure)
* [AI chatbot letdown: Hype hits rocky reality](https://www.axios.com/2024/03/27/ai-chatbot-letdown-hype-reality)
* [VP Harris Says US Agencies Must Show Their AI Tools Aren’t Harming People’s Safety or Rights - SecurityWeek](https://www.securityweek.com/vp-harris-says-us-agencies-must-show-their-ai-tools-arent-harming-peoples-safety-or-rights/)
* [Bill would require AIs to reveal copyrighted training data • The Register](https://www.theregister.com/2024/04/10/congressional_bill_would_require_ai/)
* [EU AI Act Compliance Checker | EU Artificial Intelligence Act](https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/)
* [MPs bemoan UK's lack of protection for copyright against AI • The Register](https://www.theregister.com/2024/04/11/mp_committee_ai_copyright/)
* [UK competition watchdog has 'real concerns' over big tech AI dominance - BBC News](https://www.bbc.co.uk/news/technology-68789880)
* [GenAI: A New Headache for SaaS Security Teams](https://thehackernews.com/2024/04/genai-new-headache-for-saas-security.html?m=1)
* [The ethics of advanced AI assistants - Google DeepMind](https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/)
* [Joint Cybersecurity Information Deploying AI Systems Securely](https://media.defense.gov/2024/Apr/15/2003439257/-1/-1/0/CSI-DEPLOYING-AI-SYSTEMS-SECURELY.PDF)
* [The biggest AI companies agree to crack down on child abuse images - The Verge](https://www.theverge.com/2024/4/23/24138356/ai-companies-csam-thorn-training-data)
* [Generative AI will suffocate under regulation, says law prof • The Register](https://www.theregister.com/2024/04/24/generative_ai_death/)
* [FKA Twigs uses AI to create deepfake of herself - BBC News](https://www.bbc.co.uk/news/articles/c6py33gxk74o)
* [AI Foundation Models: Update paper - GOV.UK](https://www.gov.uk/government/publications/ai-foundation-models-update-paper)
* [Senate committee passes three bills to safeguard elections from AI, months before Election Day - The Verge](https://www.theverge.com/2024/5/15/24157328/senate-rules-committee-ai-election-safeguards-bills)
* [California's proposed law SB-1047. It’s a long, complex bill with many parts that require safety assessments, shutdown capability for models, and so on.](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)
* [Electricity grids creak as AI demands soar - BBC News](https://www.bbc.co.uk/news/articles/cj5ll89dy2mo)
* [Advanced AI evaluations at AISI: May update](https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update)
* [Proposed bill would allow US to limit export of AI models • The Register](https://www.theregister.com/2024/05/23/us_lawmakers_advance_bill_to/)
* [Frontier AI Safety Commitments, AI Seoul Summit 2024 - GOV.UK](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024)
* [Global AI Regulation Tracker](https://www.techieray.com/GlobalAIRegulationTracker)
* [US senators propose guardrails for government AI purchases • The Register](https://www.theregister.com/2024/06/13/prepared_for_ai_bill/)
* [If Clearview AI scanned your face, you may get equity in the company](https://www.engadget.com/if-clearview-ai-scanned-your-face-you-may-get-equity-in-the-company-120018460.html?src=rss)

## Opinions , Research & presentations {#opinions-research-&-presentations}

* Report by research arm of the Swiss DoD on the impact LLM could have on cyber-securty
  * [[2303.12132] Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense](https://arxiv.org/abs/2303.12132)
  * [https://arxiv.org/pdf/2303.12132.pdf](https://arxiv.org/pdf/2303.12132.pdf)
* Paper on prompt injection threats together with repo that is a PoC of the findings discussed
  * [[2302.12173] Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/abs/2302.12173)
  * [GitHub - greshake/llm-security: New ways of breaking app-integrated LLMs](https://github.com/greshake/llm-security)
* Paper on evaluating The Susceptibility Of Pre-Trained Language Models Via Handcrafted Adversarial Examples
  * [https://arxiv.org/pdf/2209.02128.pdf](https://arxiv.org/pdf/2209.02128.pdf)
* [Privacy Considerations in Large Language Models](https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html?m=1)
* Ethical & social risks of harm from LLMs from Deepmind ( including as unaware where we are collecting ethical concerns & also identifies privacy risks)
  * [https://arxiv.org/pdf/2112.04359.pdf](https://arxiv.org/pdf/2112.04359.pdf)
* [Privacy Risks of General-Purpose Language Models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9152761)
* Poisoning of web scale data sets
  * [https://arxiv.org/pdf/2302.10149.pdf](https://arxiv.org/pdf/2302.10149.pdf)
* A survey of privacy attacks in machine learning
  * [https://arxiv.org/pdf/2007.07646.pdf](https://arxiv.org/pdf/2007.07646.pdf)
* GAI cyber risks - Infosec use cases
  * [https://github.com/kerberosmansour/InfoSecOpenAIExamples/blob/main/Presentation/InfoSecTalkGenAI.ipynb](https://github.com/kerberosmansour/InfoSecOpenAIExamples/blob/main/Presentation/InfoSecTalkGenAI.ipynb)
* [LLM Attacks](https://llm-attacks.org/)
* [Can LLMs Follow Simple Rules?](https://huggingface.co/papers/2311.04235?utm_source=digest-papers&utm_medium=email&utm_campaign=2023-11-09)
* [Paper page - Technical Report: Large Language Models can Strategically Deceive their Users when Put Under Pressure](https://huggingface.co/papers/2311.07590)
* [Google Researchers’ Attack Prompts ChatGPT to Reveal Its Training Data](https://www.404media.co/google-researchers-attack-convinces-chatgpt-to-reveal-its-training-data/)
* [Scalable Extraction of Training Data from (Production) Language Models](https://arxiv.org/pdf/2311.17035.pdf)
* [[2301.10226] A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)
* [OpenAI's GPT-4 safety systems broken by Scots Gaelic • The Register](https://www.theregister.com/2024/01/31/gpt4_gaelic_safety/)
* [Anthropic researchers find that AI models can be trained to deceive | TechCrunch](https://techcrunch.com/2024/01/13/anthropic-researchers-find-that-ai-models-can-be-trained-to-deceive)
* [[2307.01850] Self-Consuming Generative Models Go MAD](https://arxiv.org/abs/2307.01850)
* Study indicating larger datasets compound biases
  * [https://arxiv.org/abs/2306.13141v2](https://arxiv.org/abs/2306.13141v2)
* proposes SVEN, a learning-based approach to address controlled code generation to help with the  issue of LLMs producing in-secure code. It  studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs’ reliability in generating secure code, and (ii) adversarial testing
        * [https://arxiv.org/pdf/2302.05319.pdf](https://arxiv.org/pdf/2302.05319.pdf)
* [[2307.10169] Challenges and Applications of Large Language Models](https://arxiv.org/abs/2307.10169)
* [[2402.05526] Buffer Overflow in Mixture of Experts](https://arxiv.org/abs/2402.05526)
* [SLEEPER AGENTS: TRAINING DECEPTIVE LLMS THAT
PERSIST THROUGH SAFETY TRAINING](https://arxiv.org/pdf/2401.05566.pdf) 
 * [https://embracethered.com/blog/downloads/37C3-New-Important-Instructions.pdf](https://embracethered.com/blog/downloads/37C3-New-Important-Instructions.pdf) 
* [What is Model Collapse and how to avoid it](https://www.theregister.com/2024/01/26/what_is_model_collapse/)
* [[2305.17493] The Curse of Recursion: Training on Generated Data Makes Models Forget](https://arxiv.org/abs/2305.17493)
* [GenAI could make KYC effectively useless | TechCrunch](https://techcrunch.com/2024/01/08/gen-ai-could-make-kyc-effectively-useless/)
* [NIST: If someone's trying to sell you some secure AI, it's snake oil](https://www.theregister.com/2024/01/05/nist_ai_security/)
* [Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate](https://arxiv.org/pdf/2305.13160.pdf)
* [Nightshade: Protecting Copyright](https://nightshade.cs.uchicago.edu/whatis.html)**
* [This new data poisoning tool lets artists fight back against generative AI | MIT Technology Review](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)
* [Jailbroken AI Chatbots Can Jailbreak Other Chatbots | Scientific American](https://www.scientificamerican.com/article/jailbroken-ai-chatbots-can-jailbreak-other-chatbots/)
* [Hallucination is the last thing you need](https://arxiv.org/pdf/2306.11520.pdf)  
* [Are AI models doomed to always hallucinate? | TechCrunch](https://techcrunch.com/2023/09/04/are-language-models-doomed-to-always-hallucinate/)
* [[2309.09435] Security and Privacy on Generative Data in AIGC: A Survey](https://arxiv.org/abs/2309.09435)
* jailbreak attacks against LLMs   and the countermeasures deployed against them.
* [https://arxiv.org/pdf/2307.08715.pdf](https://arxiv.org/pdf/2307.08715.pdf)
* [Universal and Transferable Adversarial Attacks on Aligned Language Models](http://llm-attacks.org/)
* [https://arxiv.org/pdf/2307.15043.pdf](https://arxiv.org/pdf/2307.15043.pdf)
* [Visual Adversarial Examples Jailbreak Aligned Large Language Models](https://arxiv.org/pdf/2306.13213.pdf)
* Jailbreak prompts in the wild an evaluation ( it's not pretty)
  * [https://arxiv.org/abs/2308.03825](https://arxiv.org/abs/2308.03825)
* Using Images & sounds for indirect Instruction Injection in Multi-Modal LLms
  * [https://arxiv.org/pdf/2307.10490.pdf](https://arxiv.org/pdf/2307.10490.pdf)  
* [Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment](https://arxiv.org/pdf/2308.05374.pdf)  
* [A LLM Assisted Exploitation of AI-Guardian](https://arxiv.org/pdf/2307.15008.pdf)
* [Mitigating LLM Hallucinations: a multifaceted approach - AI, software, tech, and people. Not in that order. By X](https://amatriain.net/blog/hallucinations#advancedprompting)
* [[2402.14020] Coercing LLMs to do and reveal (almost) anything](https://arxiv.org/abs/2402.14020)
* Escalation Risks from Language Models in Military and Diplomatic Decision-Making
  * [https://arxiv.org/pdf/2401.03408.pdf](https://arxiv.org/pdf/2401.03408.pdf)
* [White Paper Rethinking Privacy in the AI Era: Policy Provocations for a Data-Centric World | Stanford HAI](https://hai.stanford.edu/white-paper-rethinking-privacy-ai-era-policy-provocations-data-centric-world)
* [BEAST AI attack can break LLM guardrails in a minute • The Register](https://www.theregister.com/2024/02/28/beast_llm_adversarial_prompt_injection_attack/?td=keepreading)
  * [[2402.15570] Fast Adversarial Attacks on Language Models In One GPU Minute](https://arxiv.org/abs/2402.15570)
* [https://arstechnica.com/ai/2024/03/researchers-create-ai-worms-that-can-spread-from-one-system-to-another/](https://arstechnica.com/ai/2024/03/researchers-create-ai-worms-that-can-spread-from-one-system-to-another/)
* [On the Societal Impact of Open Foundation Models](https://crfm.stanford.edu/open-fms/)
* [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs \faWarningWARNING: This paper contains model outputs that may be considered offensive.](https://arxiv.org/html/2402.11753v2)
* [[2403.00742] Dialect prejudice predicts AI decisions about people's character, employability, and criminality](https://arxiv.org/abs/2403.00742)
* [The surprising promise and profound perils of AIs that fake empathy | New Scientist](https://www.newscientist.com/article/mg26134810-900-the-surprising-promise-and-profound-perils-of-ais-that-fake-empathy/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=currents)
* [[2402.06664] LLM Agents can Autonomously Hack Websites](https://arxiv.org/abs/2402.06664)
* [[2402.10588] Do Llamas Work in English? On the Latent Language of Multilingual Transformers](https://arxiv.org/abs/2402.10588)
* [Certifying LLM Safety against Adversarial Prompting](https://arxiv.org/pdf/2309.02705.pdf?trk=public_post_comment-text)
* [Decoding the AI Safe: Uncovering and Safeguarding GPT Prompts | by Okan Yücel | Medium](https://medium.com/@okan_yucel/decoding-the-ai-safe-uncovering-and-safeguarding-gpt-prompts-b08ac4997e0b)
* [ComPromptMized: Unleashing Zero-click Worms that Target GenAI-Powered Applications](https://github.com/StavC/ComPromptMized)  
  * [[2403.02817] Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications](https://arxiv.org/abs/2403.02817)
* [[2403.06634] Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634)
* [New Google Gemini Vulnerability Enabling Profound Misuse | HiddenLayer](https://hiddenlayer.com/research/new-google-gemini-content-manipulation-vulns-found/)
* [Salt Labs research finds security flaws within ChatGPT Ecosystem (Remediated)](https://salt.security/blog/security-flaws-within-chatgpt-extensions-allowed-access-to-accounts-on-third-party-websites-and-sensitive-data)
* [Shadow AI – Should I be Worried? - SecurityWeek](https://www.securityweek.com/shadow-ai-should-i-be-worried/)
* [[2403.07918] On the Societal Impact of Open Foundation Models](https://arxiv.org/abs/2403.07918)
* [ASCII art elicits harmful responses from 5 major AI chatbots | Ars Technica](https://arstechnica.com/security/2024/03/researchers-use-ascii-art-to-elicit-harmful-responses-from-5-major-ai-chatbots/#p3)
* [[2403.08701] Review of Generative AI Methods in Cybersecurity](https://arxiv.org/abs/2403.08701)
* [[2402.14589] Avoiding an AI-imposed Taylor's Version of all music history](https://arxiv.org/abs/2402.14589)
* [In the rush to build AI apps, don't leave security behind](https://www.theregister.com/2024/03/17/ai_supply_chain/)
* [AI researchers have started reviewing their peers using AI assistance](https://www.theregister.com/2024/03/19/ai_researchers_reviewing_peers/)
* [[2403.15447] Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://arxiv.org/abs/2403.15447)
* [In the rush to build AI apps, don't leave security behind • The Register](https://www.theregister.com/2024/03/17/ai_supply_chain/?td=amp-keepreading)
* [Long-Form Factuality In Large Language Models](https://arxiv.org/pdf/2403.18802.pdf)
* [AI Is Starting to Look Like the Dot Com Bubble](https://futurism.com/ai-dot-com-bubble)
* [[2401.06121] TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/abs/2401.06121)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [AI-as-a-Service Providers Vulnerable to PrivEsc and Cross-Tenant Attacks](https://thehackernews.com/2024/04/ai-as-service-providers-vulnerable-to.html)
* [Speed of AI development is outpacing risk assessment | Ars Technica](https://arstechnica.com/ai/2024/04/speed-of-ai-development-is-outpacing-risk-assessment/)
* [Boffins deem Google DeepMind's material discoveries shallow • The Register](https://www.theregister.com/2024/04/11/google_deepmind_material_study/)
* [ChatGPT forecasts the future better when telling tales • The Register](https://www.theregister.com/2024/04/14/ai_models_future/)
* [Stanford report on AI finds booming industry at a crossroads • The Register](https://www.theregister.com/2024/04/15/stanford_report_ai/)
  * [Artificial Intelligence Index Report 2024](https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf)
* [The ethics of advanced AI assistants - Google DeepMind](https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/)
* [https://www.eweek.com/artificial-intelligence/deepfake/](https://www.eweek.com/artificial-intelligence/deepfake/)
* [Microsoft’s VASA-1 can deepfake a person with one photo and one audio track | Ars Technica](https://arstechnica.com/information-technology/2024/04/microsofts-vasa-1-can-deepfake-a-person-with-one-photo-and-one-audio-track/)
* [[2404.13208] The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions](https://arxiv.org/abs/2404.13208)
* [AI Index Report 2024 – Artificial Intelligence Index](https://aiindex.stanford.edu/report/)
* [https://llm-pbe.github.io/home](https://llm-pbe.github.io/home)
* [https://mattyyeung.github.io/deterministic-quoting](https://mattyyeung.github.io/deterministic-quoting)
* [https://www.securityweek.com/criminal-use-of-ai-growing-but-lags-behind-defenders/](https://www.securityweek.com/criminal-use-of-ai-growing-but-lags-behind-defenders/)
* [[2404.02151] Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151)
* [A Plea for Sober AI | Drew Breunig](https://www.dbreunig.com/2024/05/16/sober-ai.html)
* [Microsoft Copilot+ Recall feature 'privacy nightmare' - BBC News](https://www.bbc.co.uk/news/articles/cpwwqp6nx14o)
* [Microsoft CEO Bashes Human-Like AI After OpenAI's Scarlett Johansson Scandal](https://futurism.com/the-byte/microsoft-ceo-openai-ai-scarlett-johansson)
* [The Foundation Model Transparency Index after 6 months](https://crfm.stanford.edu/2024/05/21/fmti-may-2024.html)
* [https://arstechnica.com/gadgets/2024/05/bing-outage-shows-just-how-little-competition-google-search-really-has/](https://arstechnica.com/gadgets/2024/05/bing-outage-shows-just-how-little-competition-google-search-really-has/)
* [https://www.anthropic.com/research/mapping-mind-language-model](https://www.anthropic.com/research/mapping-mind-language-model)
* [[2401.15897] Red-Teaming for Generative AI: Silver Bullet or Security Theater?](https://arxiv.org/abs/2401.15897)
* [Evil Geniuses: Delving into the Safety of LLM-based Agents](https://arxiv.org/pdf/2311.11855)
* [[2405.11697] AMMeBa: A Large-Scale Survey and Dataset of Media-Based Misinformation In-The-Wild](https://arxiv.org/abs/2405.11697)
* [Privacy-Preserving In-Context Learning With Differentially Private Few-Shot Generation](https://openreview.net/pdf?id=oZtt0pRnOl)
* [When ChatGPT summarises, it actually does nothing of the kind.](https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/)
* [https://blog.google/technology/safety-security/designing-for-privacy-in-an-ai-world/](https://blog.google/technology/safety-security/designing-for-privacy-in-an-ai-world/)
* [[2406.02394] Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data](https://arxiv.org/abs/2406.02394)
## Mitigations & tooling {#mitigations-&-tooling}
* [AI has a privacy problem, but these techniques could fix it | VentureBeat](https://venturebeat.com/ai/ai-has-a-privacy-problem-but-these-techniques-could-fix-it/)
* [15 Open Source Responsible AI Toolkits and Projects to Use Today](https://opendatascience.com/15-open-source-responsible-ai-toolkits-and-projects-to-use-today/)
* Discusses a threat matrix for LLM AI
        * [The AI Attack Surface Map v1.0](https://danielmiessler.com/blog/the-ai-attack-surface-map-v1-0/)
* Threat matrix from Microsoft
        * [Failure Modes in Machine Learning | Microsoft Learn](https://learn.microsoft.com/en-us/security/engineering/failure-modes-in-machine-learning)
* [GitHub - protectai/llm-guard: The Security Toolkit for LLM Interactions](https://github.com/laiyer-ai/llm-guard)
* [MITRE | ATLAS™](https://atlas.mitre.org/)
* [AI Vulnerability Database](https://avidml.org/)
  * [AVID Documentation](https://avidml.gitbook.io/doc/)
* LLM vulnerability scanner
  * [Integrates with avid](https://avidml.org/blog/garak-integration/)  [GitHub - leondz/garak: LLM vulnerability scanner](https://github.com/leondz/garak)
* Case studies/reports of failures of deployed AI systems. "_dedicated to indexing the collective history of harms or near harms realized in the real world by the deployment of artificial intelligence systems"_
  * [AI Incident Database](https://incidentdatabase.ai/)
* [Trust & Safety - Meta Llama](https://ai.meta.com/llama/purple-llama/)
* [Facebook and Instagram to label all fake AI images - BBC News](https://www.bbc.co.uk/news/technology-68215619)
* [How to keep your art out of AI generators - The Verge](https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators)
* [This new data poisoning tool lets artists fight back against generative AI | MIT Technology Review](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)
* [GitHub - protectai/rebuff: LLM Prompt Injection Detector](https://github.com/protectai/rebuff)
* [ML safety course](https://course.mlsafety.org/)
* [The AI Attack Surface Map v1.0](https://danielmiessler.com/p/the-ai-attack-surface-map-v1-0/)
* [OpenAI identifies its GPTBot web crawler so you can block it • The Register](https://www.theregister.com/2023/08/08/openai_scraping_software/)
  * [robots exclusion protocol](https://www.rfc-editor.org/rfc/rfc9309.html)
* [A principled approach to evolving choice and control for web content](https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/)
* A list of LLM security tooling
  * [https://github.com/corca-ai/awesome-llm-security/](https://github.com/corca-ai/awesome-llm-security/)
* [LLM Safety Leaderboard - a Hugging Face Space by AI-Secure](https://huggingface.co/spaces/AI-Secure/llm-trustworthy-leaderboard)
* [Responsible AI at Google Research: Adversarial testing for generative AI safety](https://blog.research.google/2023/11/responsible-ai-at-google-research_16.html)
* [Model evaluation for extreme risks](https://arxiv.org/pdf/2305.15324.pdf)
* NeMo Guardrails an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.
  * [https://github.com/NVIDIA/NeMo-Guardrails/tree/main](https://github.com/NVIDIA/NeMo-Guardrails/tree/main)
* Discusses how NVIDIA  red team  investigations : LangChain chains demonstrate vulnerability to exploitation through prompt injection techniques.
        * [Securing LLM Systems Against Prompt Injection | NVIDIA Technical Blog](https://developer.nvidia.com/blog/securing-llm-systems-against-prompt-injection/)
* [Microsoft Vulnerability Severity Classification for Artificial Intelligence and Machine Learning Systems](https://www.microsoft.com/en-us/msrc/aibugbar)
* [Google Online Security Blog: AI-Powered Fuzzing: Breaking the Bug Hunting Barrier](https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html)
* [The Prompt: Bringing risk management and data governance to your gen AI models](https://google.smh.re/33Q3)
* [Data, privacy, and security for Azure OpenAI Service](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy)
* [Unveiling Our Latest Innovation - ​​Pindrop® Pulse for Audio Deepfake Detection](https://www.pindrop.com/blog/unveiling-our-latest-innovation-pindrop-pulse-for-audio-deepfake-detection)  
* [Responsible Generative AI Toolkit | Gemma | Google AI for Developers](https://ai.google.dev/responsible)
* Microsoft red team tool
  * [GitHub - Azure/PyRIT: The Python Risk Identification Tool for generative AI (PyRIT) is an open access automation framework to empower security professionals and machine learning engineers to proactively find risks in their generative AI systems.](https://github.com/Azure/PyRIT)
* [Introducing Pebblo — Data Visibility & Governance for Gen-AI apps | by Sridhar Ramaswamy | Feb, 2024 | Medium](https://medium.com/@sridhar_ramaswamy/introducing-pebblo-data-visibility-governance-for-gen-ai-apps-086ca8a62d10)
* [AI Watermarking 101: Tools and Techniques](https://huggingface.co/blog/watermarking)
* [[2402.16822] Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts](https://arxiv.org/abs/2402.16822)
* [https://www.eweek.com/artificial-intelligence/ai-governance-tools/](https://www.eweek.com/artificial-intelligence/ai-governance-tools/)
* [Introducing the Red-Teaming Resistance Leaderboard](https://huggingface.co/blog/leaderboard-haizelab)
* [AI mishaps are surging – and now they're being tracked like software bugs](https://www.theregister.com/2024/03/08/ai_mishaps_are_surging_and/)
* [[2402.11755] SPML: A DSL for Defending Language Models Against Prompt Attacks](https://arxiv.org/abs/2402.11755)
* [https://www.infoq.com/news/2024/03/cloudflare-firewall-for-ai/](https://www.infoq.com/news/2024/03/cloudflare-firewall-for-ai/)
* [GitHub - protectai/rebuff: LLM Prompt Injection Detector](https://github.com/protectai/rebuff)
* [Data Scientists Targeted by Malicious Hugging Face ML Models with Silent Backdoor](https://jfrog.com/blog/data-scientists-targeted-by-malicious-hugging-face-ml-models-with-silent-backdoor)
* [https://github.com/uw-nsl/SafeDecoding](https://github.com/uw-nsl/SafeDecoding)
* [Understanding the source of what we see and hear online | OpenAI](https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online)
* [TikTok becomes first platform to require watermarking of AI content](https://www.theregister.com/2024/05/10/tiktok_ai_watermarks/)
* [IbisPaint launches an AI Disturbance tool to make it harder for machines to copy your work](https://www.engadget.com/ibispaint-launches-an-ai-disturbance-tool-to-make-it-harder-for-machines-to-copy-your-work-131015685.html?src=rss)
* [https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/](https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/)
* [Awesome products for securing AI systems includes open source and commercial options and an infographic licensed CC-BY-SA-4.0.](https://github.com/zmre/awesome-security-for-ai)
* [AI jailbreaks: What they are and how they can be mitigated | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2024/06/04/ai-jailbreaks-what-they-are-and-how-they-can-be-mitigated/)
* [Watermarking AI-generated text and video with SynthID - Google DeepMind](https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/)
* [Euro banks worry AI will increase their dependence on US big tech](https://www.theregister.com/2024/06/10/euro_banks_worry_ai_us_tech/)
* [GenAIOps](https://genaiops.ai/) A global community built to pioneer, document and evangelise about the concept of GenAIOps. 
    * [LLMs will always be dangerous. Security can only be delivered at the level of the application | The Centre for GenAIOps](https://genaiops.ai/llms-will-always-be-dangerous-security-can-only-be-delivered-at-the-level-of-the-application)
    * [Balancing Innovation and Security | The Centre for GenAIOps](https://genaiops.ai/balancing-innovation-and-security)
* [New Attack Technique 'Sleepy Pickle' Targets Machine Learning Models](https://thehackernews.com/2024/06/new-attack-technique-sleepy-pickle.html?m=1)
* [[2406.06443] LLM Dataset Inference: Did you train on my dataset?](https://arxiv.org/abs/2406.06443)
* [GitHub - lamini-ai/Lamini-Memory-Tuning: Banishing LLM Hallucinations Requires Rethinking Generalization](https://github.com/lamini-ai/Lamini-Memory-Tuning)
