# GAI-is-going-well
This is a  [curated collection](https://github.com/grapesfrog/GAI-is-going-well/blob/main/in-the-wild.md) of articles and  research  papers related to  the unexpected  or unwanted outcomes , security &amp; privacy  risks associated with using LLMs/GAI. 

It’s been a never ending series of reports about the on going adverse outcomes related to the use of GAI whether deliberate attacks or just unfortunate side effects. Since I wrote GAI Is Going Well I’ve continued to indulge in my hobby of collecting articles related to the adverse effects of working with LLMs/GAI .
There are 4 categories
Adverse effects that result from deliberate attacks or just unfortunate outcomes
Articles on or related to  regulating AI, advisories and 
Research articles , opinions  and presentations  mostly on how to jailbreak & craft dubious prompts. However not all of the articles are published after responsible disclose so that the issues can be fixed ( if they even can in some cases) before publication.
Mitigations & tooling
Some articles are difficult to put into a single category as some research articles are exploitable in the wild 

Last updated : 8 Jun 2024
